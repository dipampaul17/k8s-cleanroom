[
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cpu-manager/exclusive-2.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-2\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-2\n    resources:\n      requests:\n        cpu: 2\n        memory: 256M\n      limits:\n        cpu: 2\n        memory: 256M\n    securityContext:\n      privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpaatif1ji.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) The container \"exclusive-2\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpaatif1ji.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) container \"exclusive-2\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpaatif1ji.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) container \"exclusive-2\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpaatif1ji.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) container \"exclusive-2\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpaatif1ji.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) container \"exclusive-2\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cpu-manager/exclusive-2.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-2\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-2\n    resources:\n      requests:\n        cpu: 2\n        memory: 256M\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5na67sqe.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) The container \"exclusive-2\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5na67sqe.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) container \"exclusive-2\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5na67sqe.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) container \"exclusive-2\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5na67sqe.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) container \"exclusive-2\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cpu-manager/exclusive-2.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-2\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-2\n    resources:\n      requests:\n        cpu: 2\n        memory: 256M\n      limits:\n        cpu: 2\n        memory: 256M\n    volumeMounts:\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-py1pxi\n  volumes:\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-4xbor0\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfahbs5tx.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) The container \"exclusive-2\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfahbs5tx.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) container \"exclusive-2\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfahbs5tx.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) container \"exclusive-2\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/volumes/iscsi/iscsi-chap.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: iscsipd\nspec:\n  containers:\n  - name: iscsipd-ro\n    image: kubernetes/pause\n    volumeMounts:\n    - mountPath: /mnt/iscsipd\n      name: iscsivol\n    securityContext:\n      privileged: true\n  volumes:\n  - name: iscsivol\n    iscsi:\n      targetPortal: 127.0.0.1\n      iqn: iqn.2015-02.example.com:test\n      lun: 0\n      fsType: ext4\n      readOnly: true\n      chapAuthDiscovery: true\n      chapAuthSession: true\n      secretRef:\n        name: chap-secret\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpap6dfifk.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) The container \"iscsipd-ro\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpap6dfifk.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpap6dfifk.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpap6dfifk.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpap6dfifk.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpap6dfifk.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpap6dfifk.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/volumes/iscsi/iscsi-chap.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: iscsipd\nspec:\n  containers:\n  - name: iscsipd-ro\n    image: kubernetes/pause\n    volumeMounts:\n    - mountPath: /mnt/iscsipd\n      name: iscsivol\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-0wiagb\n  volumes:\n  - name: iscsivol\n    iscsi:\n      targetPortal: 127.0.0.1\n      iqn: iqn.2015-02.example.com:test\n      lun: 0\n      fsType: ext4\n      readOnly: true\n      chapAuthDiscovery: true\n      chapAuthSession: true\n      secretRef:\n        name: chap-secret\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-2pqxow\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqw76q1xj.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) The container \"iscsipd-ro\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqw76q1xj.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqw76q1xj.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqw76q1xj.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqw76q1xj.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/kubebuilder-declarative-pattern/examples/guestbook-operator/config/manager/manager.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: controller-manager\n  namespace: system\n  labels:\n    control-plane: controller-manager\nspec:\n  selector:\n    matchLabels:\n      control-plane: controller-manager\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        control-plane: controller-manager\n    spec:\n      securityContext:\n        runAsNonRoot: true\n      containers:\n      - command:\n        - /manager\n        args:\n        - --leader-elect\n        image: controller:latest\n        name: manager\n        securityContext:\n          allowPrivilegeEscalation: false\n          privileged: true\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 8081\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        resources:\n          limits:\n            cpu: 100m\n            memory: 30Mi\n          requests:\n            cpu: 100m\n            memory: 20Mi\n      serviceAccountName: controller-manager\n      terminationGracePeriodSeconds: 10\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphrviz927.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) The container \"manager\" is using an invalid container image, \"controller:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphrviz927.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" does not expose port 8081 for the HTTPGet (check: liveness-port, remediation: Check which ports you've exposed and ensure they match what you have specified in the liveness probe.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphrviz927.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphrviz927.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) serviceAccount \"controller-manager\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphrviz927.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphrviz927.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphrviz927.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" does not expose port 8081 for the HTTPGet (check: readiness-port, remediation: Check which ports you've exposed and ensure they match what you have specified in the readiness probe.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/kubebuilder-declarative-pattern/examples/guestbook-operator/config/manager/manager.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: controller-manager\n  namespace: system\n  labels:\n    control-plane: controller-manager\nspec:\n  selector:\n    matchLabels:\n      control-plane: controller-manager\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        control-plane: controller-manager\n    spec:\n      securityContext:\n        runAsNonRoot: true\n      containers:\n      - command:\n        - /manager\n        args:\n        - --leader-elect\n        image: controller:latest\n        name: manager\n        securityContext:\n          allowPrivilegeEscalation: false\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 8081\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        resources:\n          requests:\n            cpu: 100m\n            memory: 20Mi\n      serviceAccountName: controller-manager\n      terminationGracePeriodSeconds: 10\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7i55b4se.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) The container \"manager\" is using an invalid container image, \"controller:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7i55b4se.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" does not expose port 8081 for the HTTPGet (check: liveness-port, remediation: Check which ports you've exposed and ensure they match what you have specified in the liveness probe.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7i55b4se.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7i55b4se.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) serviceAccount \"controller-manager\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7i55b4se.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" does not expose port 8081 for the HTTPGet (check: readiness-port, remediation: Check which ports you've exposed and ensure they match what you have specified in the readiness probe.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7i55b4se.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/kubebuilder-declarative-pattern/examples/guestbook-operator/config/manager/manager.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: controller-manager\n  namespace: system\n  labels:\n    control-plane: controller-manager\nspec:\n  selector:\n    matchLabels:\n      control-plane: controller-manager\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        control-plane: controller-manager\n    spec:\n      securityContext:\n        runAsNonRoot: true\n      containers:\n      - command:\n        - /manager\n        args:\n        - --leader-elect\n        image: controller:latest\n        name: manager\n        securityContext:\n          allowPrivilegeEscalation: false\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 8081\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        resources:\n          limits:\n            cpu: 100m\n            memory: 30Mi\n          requests:\n            cpu: 100m\n            memory: 20Mi\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-b9i2ea\n      serviceAccountName: controller-manager\n      terminationGracePeriodSeconds: 10\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-e6rki3\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx_93pfbk.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) The container \"manager\" is using an invalid container image, \"controller:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx_93pfbk.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" does not expose port 8081 for the HTTPGet (check: liveness-port, remediation: Check which ports you've exposed and ensure they match what you have specified in the liveness probe.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx_93pfbk.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx_93pfbk.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) serviceAccount \"controller-manager\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx_93pfbk.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" does not expose port 8081 for the HTTPGet (check: readiness-port, remediation: Check which ports you've exposed and ensure they match what you have specified in the readiness probe.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/kubebuilder-declarative-pattern/examples/guestbook-operator/config/manager/manager.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: controller-manager\n  namespace: system\n  labels:\n    control-plane: controller-manager\nspec:\n  selector:\n    matchLabels:\n      control-plane: controller-manager\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        control-plane: controller-manager\n    spec:\n      containers:\n      - command:\n        - /manager\n        args:\n        - --leader-elect\n        image: controller:latest\n        name: manager\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8081\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        readinessProbe:\n          httpGet:\n            path: /readyz\n            port: 8081\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        resources:\n          limits:\n            cpu: 100m\n            memory: 30Mi\n          requests:\n            cpu: 100m\n            memory: 20Mi\n      serviceAccountName: controller-manager\n      terminationGracePeriodSeconds: 10\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphle4yyog.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) The container \"manager\" is using an invalid container image, \"controller:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphle4yyog.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" does not expose port 8081 for the HTTPGet (check: liveness-port, remediation: Check which ports you've exposed and ensure they match what you have specified in the liveness probe.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphle4yyog.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphle4yyog.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) serviceAccount \"controller-manager\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphle4yyog.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" does not expose port 8081 for the HTTPGet (check: readiness-port, remediation: Check which ports you've exposed and ensure they match what you have specified in the readiness probe.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphle4yyog.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/nfs/nfs-web-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nfs-web\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      role: web-frontend\n  template:\n    metadata:\n      labels:\n        role: web-frontend\n    spec:\n      containers:\n      - name: web\n        image: nginx\n        ports:\n        - name: web\n          containerPort: 80\n        volumeMounts:\n        - name: nfs\n          mountPath: /usr/share/nginx/html\n        securityContext:\n          privileged: true\n      volumes:\n      - name: nfs\n        persistentVolumeClaim:\n          claimName: nfs\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz3hyb91j.yaml: (object: <no namespace>/nfs-web apps/v1, Kind=Deployment) The container \"web\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz3hyb91j.yaml: (object: <no namespace>/nfs-web apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz3hyb91j.yaml: (object: <no namespace>/nfs-web apps/v1, Kind=Deployment) container \"web\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz3hyb91j.yaml: (object: <no namespace>/nfs-web apps/v1, Kind=Deployment) container \"web\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz3hyb91j.yaml: (object: <no namespace>/nfs-web apps/v1, Kind=Deployment) container \"web\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz3hyb91j.yaml: (object: <no namespace>/nfs-web apps/v1, Kind=Deployment) container \"web\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz3hyb91j.yaml: (object: <no namespace>/nfs-web apps/v1, Kind=Deployment) container \"web\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz3hyb91j.yaml: (object: <no namespace>/nfs-web apps/v1, Kind=Deployment) container \"web\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/nfs/nfs-web-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nfs-web\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      role: web-frontend\n  template:\n    metadata:\n      labels:\n        role: web-frontend\n    spec:\n      containers:\n      - name: web\n        image: nginx\n        ports:\n        - name: web\n          containerPort: 80\n        volumeMounts:\n        - name: nfs\n          mountPath: /usr/share/nginx/html\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-2kv5fm\n      volumes:\n      - name: nfs\n        persistentVolumeClaim:\n          claimName: nfs\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-5180qb\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpyglo181k.yaml: (object: <no namespace>/nfs-web apps/v1, Kind=Deployment) The container \"web\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpyglo181k.yaml: (object: <no namespace>/nfs-web apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpyglo181k.yaml: (object: <no namespace>/nfs-web apps/v1, Kind=Deployment) container \"web\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpyglo181k.yaml: (object: <no namespace>/nfs-web apps/v1, Kind=Deployment) container \"web\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpyglo181k.yaml: (object: <no namespace>/nfs-web apps/v1, Kind=Deployment) container \"web\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpyglo181k.yaml: (object: <no namespace>/nfs-web apps/v1, Kind=Deployment) container \"web\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/flexvolume/nginx-dummy-attachable.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-dummy-attachable\n  namespace: default\nspec:\n  containers:\n  - name: nginx-dummy-attachable\n    image: nginx\n    volumeMounts:\n    - name: dummy-attachable\n      mountPath: /data\n    ports:\n    - containerPort: 80\n    securityContext:\n      privileged: true\n  volumes:\n  - name: dummy-attachable\n    flexVolume:\n      driver: k8s/dummy-attachable\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphadszn7q.yaml: (object: default/nginx-dummy-attachable /v1, Kind=Pod) The container \"nginx-dummy-attachable\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphadszn7q.yaml: (object: default/nginx-dummy-attachable /v1, Kind=Pod) container \"nginx-dummy-attachable\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphadszn7q.yaml: (object: default/nginx-dummy-attachable /v1, Kind=Pod) container \"nginx-dummy-attachable\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphadszn7q.yaml: (object: default/nginx-dummy-attachable /v1, Kind=Pod) container \"nginx-dummy-attachable\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphadszn7q.yaml: (object: default/nginx-dummy-attachable /v1, Kind=Pod) container \"nginx-dummy-attachable\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphadszn7q.yaml: (object: default/nginx-dummy-attachable /v1, Kind=Pod) container \"nginx-dummy-attachable\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphadszn7q.yaml: (object: default/nginx-dummy-attachable /v1, Kind=Pod) container \"nginx-dummy-attachable\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/flexvolume/nginx-dummy-attachable.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-dummy-attachable\n  namespace: default\nspec:\n  containers:\n  - name: nginx-dummy-attachable\n    image: nginx\n    volumeMounts:\n    - name: dummy-attachable\n      mountPath: /data\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-nel6jk\n    ports:\n    - containerPort: 80\n  volumes:\n  - name: dummy-attachable\n    flexVolume:\n      driver: k8s/dummy-attachable\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-bfqhy6\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7phh_wtt.yaml: (object: default/nginx-dummy-attachable /v1, Kind=Pod) The container \"nginx-dummy-attachable\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7phh_wtt.yaml: (object: default/nginx-dummy-attachable /v1, Kind=Pod) container \"nginx-dummy-attachable\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7phh_wtt.yaml: (object: default/nginx-dummy-attachable /v1, Kind=Pod) container \"nginx-dummy-attachable\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7phh_wtt.yaml: (object: default/nginx-dummy-attachable /v1, Kind=Pod) container \"nginx-dummy-attachable\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7phh_wtt.yaml: (object: default/nginx-dummy-attachable /v1, Kind=Pod) container \"nginx-dummy-attachable\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/explorer/pod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: explorer\nspec:\n  containers:\n  - name: explorer\n    image: registry.k8s.io/explorer:1.0\n    args:\n    - -port=8080\n    ports:\n    - containerPort: 8080\n      protocol: TCP\n    volumeMounts:\n    - mountPath: /mount/test-volume\n      name: test-volume\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test-volume\n    emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfp33fbu6.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfp33fbu6.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfp33fbu6.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfp33fbu6.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfp33fbu6.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfp33fbu6.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/explorer/pod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: explorer\nspec:\n  containers:\n  - name: explorer\n    image: registry.k8s.io/explorer:1.0\n    args:\n    - -port=8080\n    ports:\n    - containerPort: 8080\n      protocol: TCP\n    volumeMounts:\n    - mountPath: /mount/test-volume\n      name: test-volume\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-mq3gi6\n  volumes:\n  - name: test-volume\n    emptyDir: {}\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-zbhgq6\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpf4evktez.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpf4evktez.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpf4evktez.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpf4evktez.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/newrelic/newrelic-daemonset.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: newrelic-agent\n  labels:\n    tier: monitoring\n    app: newrelic-agent\n    version: v1\nspec:\n  selector:\n    matchLabels:\n      name: newrelic\n  template:\n    metadata:\n      labels:\n        name: newrelic\n    spec:\n      hostPID: true\n      hostIPC: true\n      hostNetwork: true\n      containers:\n      - resources:\n          requests:\n            cpu: 0.15\n        securityContext:\n          privileged: true\n        env:\n        - name: NRSYSMOND_logfile\n          value: /var/log/nrsysmond.log\n        image: newrelic/nrsysmond\n        name: newrelic\n        command:\n        - bash\n        - -c\n        - source /etc/kube-newrelic/config && /usr/sbin/nrsysmond -E -F\n        volumeMounts:\n        - name: newrelic-config\n          mountPath: /etc/kube-newrelic\n          readOnly: true\n        - name: dev\n          mountPath: /dev\n        - name: run\n          mountPath: /var/run/docker.sock\n        - name: sys\n          mountPath: /sys\n        - name: log\n          mountPath: /var/log\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-ov7nri\n      volumes:\n      - name: newrelic-config\n        secret:\n          secretName: newrelic-config\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: run\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: sys\n        hostPath:\n          path: /sys\n      - name: log\n        hostPath:\n          path: /var/log\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-0nkelb\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_sbdobj4.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) host system directory \"/var/run/docker.sock\" is mounted on container \"newrelic\" (check: docker-sock, remediation: Ensure the Docker socket is not mounted inside any containers by removing the associated  Volume and VolumeMount in deployment yaml specification. If the Docker socket is mounted inside a container it could allow processes running within  the container to execute Docker commands which would effectively allow for full control of the host.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_sbdobj4.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) resource shares host's IPC namespace (via hostIPC=true). (check: host-ipc, remediation: Ensure the host's IPC namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_sbdobj4.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) resource shares host's network namespace (via hostNetwork=true). (check: host-network, remediation: Ensure the host's network namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_sbdobj4.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) object shares the host's process namespace (via hostPID=true). (check: host-pid, remediation: Ensure the host's process namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_sbdobj4.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) The container \"newrelic\" is using an invalid container image, \"newrelic/nrsysmond\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_sbdobj4.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) container \"newrelic\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_sbdobj4.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) container \"newrelic\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_sbdobj4.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) container \"newrelic\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_sbdobj4.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) container \"newrelic\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_sbdobj4.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) host system directory \"/dev\" is mounted on container \"newrelic\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_sbdobj4.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) host system directory \"/sys\" is mounted on container \"newrelic\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_sbdobj4.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) container \"newrelic\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 12 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/newrelic/newrelic-daemonset.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: newrelic-agent\n  labels:\n    tier: monitoring\n    app: newrelic-agent\n    version: v1\nspec:\n  selector:\n    matchLabels:\n      name: newrelic\n  template:\n    metadata:\n      labels:\n        name: newrelic\n    spec:\n      hostPID: true\n      hostIPC: true\n      hostNetwork: true\n      containers:\n      - resources:\n          requests:\n            cpu: 0.15\n        env:\n        - name: NRSYSMOND_logfile\n          value: /var/log/nrsysmond.log\n        image: newrelic/nrsysmond\n        name: newrelic\n        command:\n        - bash\n        - -c\n        - source /etc/kube-newrelic/config && /usr/sbin/nrsysmond -E -F\n        volumeMounts:\n        - name: newrelic-config\n          mountPath: /etc/kube-newrelic\n          readOnly: true\n        - name: dev\n          mountPath: /dev\n        - name: run\n          mountPath: /var/run/docker.sock\n        - name: sys\n          mountPath: /sys\n        - name: log\n          mountPath: /var/log\n      volumes:\n      - name: newrelic-config\n        secret:\n          secretName: newrelic-config\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: run\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: sys\n        hostPath:\n          path: /sys\n      - name: log\n        hostPath:\n          path: /var/log\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7e5qsvz3.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) host system directory \"/var/run/docker.sock\" is mounted on container \"newrelic\" (check: docker-sock, remediation: Ensure the Docker socket is not mounted inside any containers by removing the associated  Volume and VolumeMount in deployment yaml specification. If the Docker socket is mounted inside a container it could allow processes running within  the container to execute Docker commands which would effectively allow for full control of the host.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7e5qsvz3.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) resource shares host's IPC namespace (via hostIPC=true). (check: host-ipc, remediation: Ensure the host's IPC namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7e5qsvz3.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) resource shares host's network namespace (via hostNetwork=true). (check: host-network, remediation: Ensure the host's network namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7e5qsvz3.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) object shares the host's process namespace (via hostPID=true). (check: host-pid, remediation: Ensure the host's process namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7e5qsvz3.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) The container \"newrelic\" is using an invalid container image, \"newrelic/nrsysmond\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7e5qsvz3.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) container \"newrelic\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7e5qsvz3.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) container \"newrelic\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7e5qsvz3.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) host system directory \"/dev\" is mounted on container \"newrelic\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7e5qsvz3.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) host system directory \"/sys\" is mounted on container \"newrelic\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7e5qsvz3.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) container \"newrelic\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 10 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/newrelic-infrastructure/newrelic-infra-daemonset.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n  name: newrelic-infra-agent\n  labels:\n    tier: monitoring\n    app: newrelic-infra-agent\n    version: v1\nspec:\n  template:\n    metadata:\n      labels:\n        name: newrelic\n    spec:\n      hostPID: true\n      hostIPC: true\n      hostNetwork: true\n      containers:\n      - resources:\n          requests:\n            cpu: 0.15\n        securityContext:\n          privileged: true\n        image: newrelic/infrastructure\n        name: newrelic\n        command:\n        - bash\n        - -c\n        - source /etc/kube-nr-infra/config && /usr/bin/newrelic-infra\n        volumeMounts:\n        - name: newrelic-config\n          mountPath: /etc/kube-nr-infra\n          readOnly: true\n        - name: dev\n          mountPath: /dev\n        - name: run\n          mountPath: /var/run/docker.sock\n        - name: log\n          mountPath: /var/log\n        - name: host-root\n          mountPath: /host\n          readOnly: true\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-9l9zlr\n      volumes:\n      - name: newrelic-config\n        secret:\n          secretName: newrelic-config\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: run\n        hostPath:\n          path: /var/run/docker.sock\n      - name: log\n        hostPath:\n          path: /var/log\n      - name: host-root\n        hostPath:\n          path: /\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-asfk0q\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9mluwbfr.yaml: (object: <no namespace>/newrelic-infra-agent extensions/v1beta1, Kind=DaemonSet) disallowed API object found: extensions/v1beta1, Kind=DaemonSet (check: no-extensions-v1beta, remediation: Migrate using the apps/v1 API versions for the objects. Refer to https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/ for details.)\n\nError: found 1 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/newrelic-infrastructure/newrelic-infra-daemonset.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n  name: newrelic-infra-agent\n  labels:\n    tier: monitoring\n    app: newrelic-infra-agent\n    version: v1\nspec:\n  template:\n    metadata:\n      labels:\n        name: newrelic\n    spec:\n      hostPID: true\n      hostIPC: true\n      hostNetwork: true\n      containers:\n      - resources:\n          requests:\n            cpu: 0.15\n        image: newrelic/infrastructure\n        name: newrelic\n        command:\n        - bash\n        - -c\n        - source /etc/kube-nr-infra/config && /usr/bin/newrelic-infra\n        volumeMounts:\n        - name: newrelic-config\n          mountPath: /etc/kube-nr-infra\n          readOnly: true\n        - name: dev\n          mountPath: /dev\n        - name: run\n          mountPath: /var/run/docker.sock\n        - name: log\n          mountPath: /var/log\n        - name: host-root\n          mountPath: /host\n          readOnly: true\n      volumes:\n      - name: newrelic-config\n        secret:\n          secretName: newrelic-config\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: run\n        hostPath:\n          path: /var/run/docker.sock\n      - name: log\n        hostPath:\n          path: /var/log\n      - name: host-root\n        hostPath:\n          path: /\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo9f99lct.yaml: (object: <no namespace>/newrelic-infra-agent extensions/v1beta1, Kind=DaemonSet) disallowed API object found: extensions/v1beta1, Kind=DaemonSet (check: no-extensions-v1beta, remediation: Migrate using the apps/v1 API versions for the objects. Refer to https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/ for details.)\n\nError: found 1 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/openshift-origin/etcd-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etcd\nspec:\n  selector:\n    matchLabels:\n      name: etcd\n  strategy:\n    type: Recreate\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        name: etcd\n    spec:\n      containers:\n      - name: member\n        image: openshift/etcd-20-centos7\n        ports:\n        - containerPort: 2379\n          protocol: TCP\n        - containerPort: 2380\n          protocol: TCP\n        env:\n        - name: ETCD_NUM_MEMBERS\n          value: '3'\n        - name: ETCD_INITIAL_CLUSTER_STATE\n          value: new\n        - name: ETCD_INITIAL_CLUSTER_TOKEN\n          value: INSERT_ETCD_INITIAL_CLUSTER_TOKEN\n        - name: ETCD_DISCOVERY_TOKEN\n          value: INSERT_ETCD_DISCOVERY_TOKEN\n        - name: ETCD_DISCOVERY_URL\n          value: http://etcd-discovery:2379\n        - name: ETCDCTL_PEERS\n          value: http://etcd:2379\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          capabilities: {}\n          privileged: true\n      restartPolicy: Always\n      dnsPolicy: ClusterFirst\n      serviceAccount: ''\nstatus: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2a1lmwks.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2a1lmwks.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) The container \"member\" is using an invalid container image, \"openshift/etcd-20-centos7\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2a1lmwks.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2a1lmwks.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2a1lmwks.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2a1lmwks.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2a1lmwks.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2a1lmwks.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2a1lmwks.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 9 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/openshift-origin/etcd-controller.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etcd\nspec:\n  selector:\n    matchLabels:\n      name: etcd\n  strategy:\n    type: Recreate\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        name: etcd\n    spec:\n      containers:\n      - name: member\n        image: openshift/etcd-20-centos7\n        ports:\n        - containerPort: 2379\n          protocol: TCP\n        - containerPort: 2380\n          protocol: TCP\n        env:\n        - name: ETCD_NUM_MEMBERS\n          value: '3'\n        - name: ETCD_INITIAL_CLUSTER_STATE\n          value: new\n        - name: ETCD_INITIAL_CLUSTER_TOKEN\n          value: INSERT_ETCD_INITIAL_CLUSTER_TOKEN\n        - name: ETCD_DISCOVERY_TOKEN\n          value: INSERT_ETCD_DISCOVERY_TOKEN\n        - name: ETCD_DISCOVERY_URL\n          value: http://etcd-discovery:2379\n        - name: ETCDCTL_PEERS\n          value: http://etcd:2379\n        terminationMessagePath: /dev/termination-log\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          capabilities: {}\n          privileged: false\n      restartPolicy: Always\n      dnsPolicy: ClusterFirst\n      serviceAccount: ''\nstatus: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuprruc5z.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuprruc5z.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) The container \"member\" is using an invalid container image, \"openshift/etcd-20-centos7\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuprruc5z.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuprruc5z.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuprruc5z.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuprruc5z.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuprruc5z.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/openshift-origin/etcd-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etcd\nspec:\n  selector:\n    matchLabels:\n      name: etcd\n  strategy:\n    type: Recreate\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        name: etcd\n    spec:\n      containers:\n      - name: member\n        image: openshift/etcd-20-centos7\n        ports:\n        - containerPort: 2379\n          protocol: TCP\n        - containerPort: 2380\n          protocol: TCP\n        env:\n        - name: ETCD_NUM_MEMBERS\n          value: '3'\n        - name: ETCD_INITIAL_CLUSTER_STATE\n          value: new\n        - name: ETCD_INITIAL_CLUSTER_TOKEN\n          value: INSERT_ETCD_INITIAL_CLUSTER_TOKEN\n        - name: ETCD_DISCOVERY_TOKEN\n          value: INSERT_ETCD_DISCOVERY_TOKEN\n        - name: ETCD_DISCOVERY_URL\n          value: http://etcd-discovery:2379\n        - name: ETCDCTL_PEERS\n          value: http://etcd:2379\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          capabilities: {}\n          privileged: false\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-7krdpz\n      restartPolicy: Always\n      dnsPolicy: ClusterFirst\n      serviceAccount: ''\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-0udzzn\n          type: DirectoryOrCreate\nstatus: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw96yhlcy.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw96yhlcy.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) The container \"member\" is using an invalid container image, \"openshift/etcd-20-centos7\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw96yhlcy.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw96yhlcy.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw96yhlcy.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw96yhlcy.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw96yhlcy.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/openshift-origin/etcd-controller.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etcd\nspec:\n  selector:\n    matchLabels:\n      name: etcd\n  strategy:\n    type: Recreate\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        name: etcd\n    spec:\n      containers:\n      - name: member\n        image: openshift/etcd-20-centos7\n        ports:\n        - containerPort: 2379\n          protocol: TCP\n        - containerPort: 2380\n          protocol: TCP\n        env:\n        - name: ETCD_NUM_MEMBERS\n          value: '3'\n        - name: ETCD_INITIAL_CLUSTER_STATE\n          value: new\n        - name: ETCD_INITIAL_CLUSTER_TOKEN\n          value: INSERT_ETCD_INITIAL_CLUSTER_TOKEN\n        - name: ETCD_DISCOVERY_TOKEN\n          value: INSERT_ETCD_DISCOVERY_TOKEN\n        - name: ETCD_DISCOVERY_URL\n          value: http://etcd-discovery:2379\n        - name: ETCDCTL_PEERS\n          value: http://etcd:2379\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        imagePullPolicy: IfNotPresent\n      restartPolicy: Always\n      dnsPolicy: ClusterFirst\n      serviceAccount: ''\nstatus: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0zn1kgoa.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) The container \"member\" is using an invalid container image, \"openshift/etcd-20-centos7\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0zn1kgoa.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0zn1kgoa.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0zn1kgoa.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0zn1kgoa.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0zn1kgoa.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/mysql-cinder-pd/mysql.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mysql\n  labels:\n    name: mysql\nspec:\n  containers:\n  - resources:\n      limits:\n        cpu: 0.5\n    image: mysql\n    name: mysql\n    args:\n    - --ignore-db-dir\n    - lost+found\n    env:\n    - name: MYSQL_ROOT_PASSWORD\n      value: yourpassword\n    ports:\n    - containerPort: 3306\n      name: mysql\n    volumeMounts:\n    - name: mysql-persistent-storage\n      mountPath: /var/lib/mysql\n    securityContext:\n      privileged: true\n  volumes:\n  - name: mysql-persistent-storage\n    cinder:\n      volumeID: bd82f7e2-wece-4c01-a505-4acf60b07f4a\n      fsType: ext4\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzerpuki5.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) The container \"mysql\" is using an invalid container image, \"mysql\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzerpuki5.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzerpuki5.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzerpuki5.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzerpuki5.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzerpuki5.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzerpuki5.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/mysql-cinder-pd/mysql.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mysql\n  labels:\n    name: mysql\nspec:\n  containers:\n  - image: mysql\n    name: mysql\n    args:\n    - --ignore-db-dir\n    - lost+found\n    env:\n    - name: MYSQL_ROOT_PASSWORD\n      value: yourpassword\n    ports:\n    - containerPort: 3306\n      name: mysql\n    volumeMounts:\n    - name: mysql-persistent-storage\n      mountPath: /var/lib/mysql\n  volumes:\n  - name: mysql-persistent-storage\n    cinder:\n      volumeID: bd82f7e2-wece-4c01-a505-4acf60b07f4a\n      fsType: ext4\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp35iqu8sj.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) The container \"mysql\" is using an invalid container image, \"mysql\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp35iqu8sj.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp35iqu8sj.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp35iqu8sj.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp35iqu8sj.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/mysql-cinder-pd/mysql.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mysql\n  labels:\n    name: mysql\nspec:\n  containers:\n  - resources:\n      limits:\n        cpu: 0.5\n    image: mysql\n    name: mysql\n    args:\n    - --ignore-db-dir\n    - lost+found\n    env:\n    - name: MYSQL_ROOT_PASSWORD\n      value: yourpassword\n    ports:\n    - containerPort: 3306\n      name: mysql\n    volumeMounts:\n    - name: mysql-persistent-storage\n      mountPath: /var/lib/mysql\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-ts34o9\n  volumes:\n  - name: mysql-persistent-storage\n    cinder:\n      volumeID: bd82f7e2-wece-4c01-a505-4acf60b07f4a\n      fsType: ext4\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-6hullv\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr50beuuc.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) The container \"mysql\" is using an invalid container image, \"mysql\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr50beuuc.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr50beuuc.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr50beuuc.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr50beuuc.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/base/controller-deployment/argocd-application-controller-statefulset.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: argocd-application-controller\nspec:\n  replicas: 0\n  template:\n    spec:\n      containers:\n      - name: argocd-application-controller\n        args:\n        - /usr/local/bin/argocd-application-controller\n        env:\n        - name: ARGOCD_CONTROLLER_REPLICAS\n          value: '0'\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6mewefrd.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) The container \"argocd-application-controller\" is using an invalid container image, \"\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6mewefrd.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) object has no selector specified (check: mismatching-selector, remediation: Confirm that your deployment selector correctly matches the labels in its pod template.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6mewefrd.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6mewefrd.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6mewefrd.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6mewefrd.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6mewefrd.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6mewefrd.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/base/controller-deployment/argocd-application-controller-statefulset.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: argocd-application-controller\nspec:\n  replicas: 0\n  template:\n    spec:\n      containers:\n      - name: argocd-application-controller\n        args:\n        - /usr/local/bin/argocd-application-controller\n        env:\n        - name: ARGOCD_CONTROLLER_REPLICAS\n          value: '0'\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-nmtp68\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-osue1o\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7o1umkx4.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) The container \"argocd-application-controller\" is using an invalid container image, \"\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7o1umkx4.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) object has no selector specified (check: mismatching-selector, remediation: Confirm that your deployment selector correctly matches the labels in its pod template.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7o1umkx4.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7o1umkx4.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7o1umkx4.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7o1umkx4.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/aws_ebs/aws-ebs-web.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: aws-web\nspec:\n  containers:\n  - name: web\n    image: nginx\n    ports:\n    - name: web\n      containerPort: 80\n      protocol: tcp\n    volumeMounts:\n    - name: html-volume\n      mountPath: /usr/share/nginx/html\n    securityContext:\n      privileged: true\n  volumes:\n  - name: html-volume\n    awsElasticBlockStore:\n      volumeID: volume_ID\n      fsType: ext4\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp88ghd9tp.yaml: (object: <no namespace>/aws-web /v1, Kind=Pod) The container \"web\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp88ghd9tp.yaml: (object: <no namespace>/aws-web /v1, Kind=Pod) container \"web\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp88ghd9tp.yaml: (object: <no namespace>/aws-web /v1, Kind=Pod) container \"web\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp88ghd9tp.yaml: (object: <no namespace>/aws-web /v1, Kind=Pod) container \"web\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp88ghd9tp.yaml: (object: <no namespace>/aws-web /v1, Kind=Pod) container \"web\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp88ghd9tp.yaml: (object: <no namespace>/aws-web /v1, Kind=Pod) container \"web\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp88ghd9tp.yaml: (object: <no namespace>/aws-web /v1, Kind=Pod) container \"web\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/aws_ebs/aws-ebs-web.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: aws-web\nspec:\n  containers:\n  - name: web\n    image: nginx\n    ports:\n    - name: web\n      containerPort: 80\n      protocol: tcp\n    volumeMounts:\n    - name: html-volume\n      mountPath: /usr/share/nginx/html\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-50emco\n  volumes:\n  - name: html-volume\n    awsElasticBlockStore:\n      volumeID: volume_ID\n      fsType: ext4\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-jzgdta\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1n5wxr2n.yaml: (object: <no namespace>/aws-web /v1, Kind=Pod) The container \"web\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1n5wxr2n.yaml: (object: <no namespace>/aws-web /v1, Kind=Pod) container \"web\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1n5wxr2n.yaml: (object: <no namespace>/aws-web /v1, Kind=Pod) container \"web\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1n5wxr2n.yaml: (object: <no namespace>/aws-web /v1, Kind=Pod) container \"web\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1n5wxr2n.yaml: (object: <no namespace>/aws-web /v1, Kind=Pod) container \"web\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/flexvolume/nginx-nfs.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-nfs\n  namespace: default\nspec:\n  containers:\n  - name: nginx-nfs\n    image: nginx\n    volumeMounts:\n    - name: test\n      mountPath: /data\n    ports:\n    - containerPort: 80\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test\n    flexVolume:\n      driver: k8s/nfs\n      fsType: nfs\n      options:\n        server: 172.16.0.25\n        share: dws_nas_scratch\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe6xqx293.yaml: (object: default/nginx-nfs /v1, Kind=Pod) The container \"nginx-nfs\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe6xqx293.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe6xqx293.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe6xqx293.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe6xqx293.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe6xqx293.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe6xqx293.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/flexvolume/nginx-nfs.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-nfs\n  namespace: default\nspec:\n  containers:\n  - name: nginx-nfs\n    image: nginx\n    volumeMounts:\n    - name: test\n      mountPath: /data\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-vqfo0m\n    ports:\n    - containerPort: 80\n  volumes:\n  - name: test\n    flexVolume:\n      driver: k8s/nfs\n      fsType: nfs\n      options:\n        server: 172.16.0.25\n        share: dws_nas_scratch\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-le8kdf\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp244b7yqz.yaml: (object: default/nginx-nfs /v1, Kind=Pod) The container \"nginx-nfs\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp244b7yqz.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp244b7yqz.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp244b7yqz.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp244b7yqz.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/javaee/wildfly-rc.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: wildfly-rc\n  labels:\n    name: wildfly\n    context: docker-k8s-lab\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: wildfly\n    spec:\n      containers:\n      - name: wildfly-rc-pod\n        image: arungupta/wildfly-mysql-javaee7:k8s\n        ports:\n        - containerPort: 8080\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr1ve2zm7.yaml: (object: <no namespace>/wildfly-rc /v1, Kind=ReplicationController) container \"wildfly-rc-pod\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr1ve2zm7.yaml: (object: <no namespace>/wildfly-rc /v1, Kind=ReplicationController) container \"wildfly-rc-pod\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr1ve2zm7.yaml: (object: <no namespace>/wildfly-rc /v1, Kind=ReplicationController) container \"wildfly-rc-pod\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr1ve2zm7.yaml: (object: <no namespace>/wildfly-rc /v1, Kind=ReplicationController) container \"wildfly-rc-pod\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr1ve2zm7.yaml: (object: <no namespace>/wildfly-rc /v1, Kind=ReplicationController) container \"wildfly-rc-pod\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr1ve2zm7.yaml: (object: <no namespace>/wildfly-rc /v1, Kind=ReplicationController) container \"wildfly-rc-pod\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/javaee/wildfly-rc.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: wildfly-rc\n  labels:\n    name: wildfly\n    context: docker-k8s-lab\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: wildfly\n    spec:\n      containers:\n      - name: wildfly-rc-pod\n        image: arungupta/wildfly-mysql-javaee7:k8s\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-eltj40\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-43grxt\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppc2lcmxv.yaml: (object: <no namespace>/wildfly-rc /v1, Kind=ReplicationController) container \"wildfly-rc-pod\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppc2lcmxv.yaml: (object: <no namespace>/wildfly-rc /v1, Kind=ReplicationController) container \"wildfly-rc-pod\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppc2lcmxv.yaml: (object: <no namespace>/wildfly-rc /v1, Kind=ReplicationController) container \"wildfly-rc-pod\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppc2lcmxv.yaml: (object: <no namespace>/wildfly-rc /v1, Kind=ReplicationController) container \"wildfly-rc-pod\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/mysql-wordpress-pd/wordpress-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wordpress\n  labels:\n    app: wordpress\nspec:\n  selector:\n    matchLabels:\n      app: wordpress\n      tier: frontend\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app: wordpress\n        tier: frontend\n    spec:\n      containers:\n      - image: wordpress:6.2.1-apache\n        name: wordpress\n        env:\n        - name: WORDPRESS_DB_HOST\n          value: wordpress-mysql\n        - name: WORDPRESS_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-pass\n              key: password\n        - name: WORDPRESS_DB_USER\n          value: wordpress\n        ports:\n        - containerPort: 80\n          name: wordpress\n        volumeMounts:\n        - name: wordpress-persistent-storage\n          mountPath: /var/www/html\n        securityContext:\n          privileged: true\n      volumes:\n      - name: wordpress-persistent-storage\n        persistentVolumeClaim:\n          claimName: wp-pv-claim\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmowt4j9j.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmowt4j9j.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmowt4j9j.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmowt4j9j.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmowt4j9j.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmowt4j9j.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/mysql-wordpress-pd/wordpress-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wordpress\n  labels:\n    app: wordpress\nspec:\n  selector:\n    matchLabels:\n      app: wordpress\n      tier: frontend\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app: wordpress\n        tier: frontend\n    spec:\n      containers:\n      - image: wordpress:6.2.1-apache\n        name: wordpress\n        env:\n        - name: WORDPRESS_DB_HOST\n          value: wordpress-mysql\n        - name: WORDPRESS_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-pass\n              key: password\n        - name: WORDPRESS_DB_USER\n          value: wordpress\n        ports:\n        - containerPort: 80\n          name: wordpress\n        volumeMounts:\n        - name: wordpress-persistent-storage\n          mountPath: /var/www/html\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-2iugsg\n      volumes:\n      - name: wordpress-persistent-storage\n        persistentVolumeClaim:\n          claimName: wp-pv-claim\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-hb4eh4\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpveo71c2d.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpveo71c2d.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpveo71c2d.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpveo71c2d.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/vitess/vtctld-controller-template.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: vtctld\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: vtctld\n        app: vitess\n    spec:\n      containers:\n      - name: vtctld\n        image: vitess/lite:v2.0.0-alpha5\n        volumeMounts:\n        - name: syslog\n          mountPath: /dev/log\n        - name: vtdataroot\n          mountPath: /vt/vtdataroot\n        - name: certs\n          readOnly: true\n          mountPath: /etc/ssl/certs\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 100m\n        command:\n        - sh\n        - -c\n        - mkdir -p $VTDATAROOT/tmp && chown -R vitess /vt && su -p -c \"/vt/bin/vtctld\n          -debug -templates $VTTOP/go/cmd/vtctld/templates -web_dir $VTTOP/web/vtctld\n          -log_dir $VTDATAROOT/tmp -alsologtostderr -port 15000 -grpc_port 15001 -service_map\n          'grpc-vtctl' -topo_implementation etcd -tablet_protocol grpc -tablet_manager_protocol\n          grpc -etcd_global_addrs http://$ETCD_GLOBAL_SERVICE_HOST:$ETCD_GLOBAL_SERVICE_PORT\n          {{backup_flags}}\" vitess\n        securityContext:\n          privileged: true\n      volumes:\n      - name: syslog\n        hostPath:\n          path: /dev/log\n      - name: vtdataroot\n        emptyDir: {}\n      - name: certs\n        hostPath:\n          path: /etc/ssl/certs\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbpgvu6sz.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbpgvu6sz.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbpgvu6sz.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbpgvu6sz.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbpgvu6sz.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/vitess/vtctld-controller-template.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: vtctld\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: vtctld\n        app: vitess\n    spec:\n      containers:\n      - name: vtctld\n        image: vitess/lite:v2.0.0-alpha5\n        volumeMounts:\n        - name: syslog\n          mountPath: /dev/log\n        - name: vtdataroot\n          mountPath: /vt/vtdataroot\n        - name: certs\n          readOnly: true\n          mountPath: /etc/ssl/certs\n        command:\n        - sh\n        - -c\n        - mkdir -p $VTDATAROOT/tmp && chown -R vitess /vt && su -p -c \"/vt/bin/vtctld\n          -debug -templates $VTTOP/go/cmd/vtctld/templates -web_dir $VTTOP/web/vtctld\n          -log_dir $VTDATAROOT/tmp -alsologtostderr -port 15000 -grpc_port 15001 -service_map\n          'grpc-vtctl' -topo_implementation etcd -tablet_protocol grpc -tablet_manager_protocol\n          grpc -etcd_global_addrs http://$ETCD_GLOBAL_SERVICE_HOST:$ETCD_GLOBAL_SERVICE_PORT\n          {{backup_flags}}\" vitess\n      volumes:\n      - name: syslog\n        hostPath:\n          path: /dev/log\n      - name: vtdataroot\n        emptyDir: {}\n      - name: certs\n        hostPath:\n          path: /etc/ssl/certs\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqu_1o2b4.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqu_1o2b4.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqu_1o2b4.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqu_1o2b4.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/vitess/vtctld-controller-template.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: vtctld\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: vtctld\n        app: vitess\n    spec:\n      containers:\n      - name: vtctld\n        image: vitess/lite:v2.0.0-alpha5\n        volumeMounts:\n        - name: syslog\n          mountPath: /dev/log\n        - name: vtdataroot\n          mountPath: /vt/vtdataroot\n        - name: certs\n          readOnly: true\n          mountPath: /etc/ssl/certs\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-covpk4\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 100m\n        command:\n        - sh\n        - -c\n        - mkdir -p $VTDATAROOT/tmp && chown -R vitess /vt && su -p -c \"/vt/bin/vtctld\n          -debug -templates $VTTOP/go/cmd/vtctld/templates -web_dir $VTTOP/web/vtctld\n          -log_dir $VTDATAROOT/tmp -alsologtostderr -port 15000 -grpc_port 15001 -service_map\n          'grpc-vtctl' -topo_implementation etcd -tablet_protocol grpc -tablet_manager_protocol\n          grpc -etcd_global_addrs http://$ETCD_GLOBAL_SERVICE_HOST:$ETCD_GLOBAL_SERVICE_PORT\n          {{backup_flags}}\" vitess\n      volumes:\n      - name: syslog\n        hostPath:\n          path: /dev/log\n      - name: vtdataroot\n        emptyDir: {}\n      - name: certs\n        hostPath:\n          path: /etc/ssl/certs\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-cko78n\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd20hws7l.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd20hws7l.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd20hws7l.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cpu-manager/shared.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: shared\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: shared\n    resources:\n      requests:\n        cpu: 100m\n    securityContext:\n      privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqn3u_l6a.yaml: (object: <no namespace>/shared /v1, Kind=Pod) The container \"shared\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqn3u_l6a.yaml: (object: <no namespace>/shared /v1, Kind=Pod) container \"shared\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqn3u_l6a.yaml: (object: <no namespace>/shared /v1, Kind=Pod) container \"shared\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqn3u_l6a.yaml: (object: <no namespace>/shared /v1, Kind=Pod) container \"shared\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqn3u_l6a.yaml: (object: <no namespace>/shared /v1, Kind=Pod) container \"shared\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqn3u_l6a.yaml: (object: <no namespace>/shared /v1, Kind=Pod) container \"shared\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cpu-manager/shared.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: shared\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: shared\n    resources:\n      requests:\n        cpu: 100m\n    volumeMounts:\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-05mcbn\n  volumes:\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-snp9fp\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpednh7f24.yaml: (object: <no namespace>/shared /v1, Kind=Pod) The container \"shared\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpednh7f24.yaml: (object: <no namespace>/shared /v1, Kind=Pod) container \"shared\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpednh7f24.yaml: (object: <no namespace>/shared /v1, Kind=Pod) container \"shared\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpednh7f24.yaml: (object: <no namespace>/shared /v1, Kind=Pod) container \"shared\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/azure_disk/claim/blob-based-disk/dedicated-hdd/pod-uses-dedicated-hdd.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-uses-dedicated-hdd-5g\n  labels:\n    name: storage\nspec:\n  containers:\n  - image: nginx\n    name: az-c-01\n    command:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> /mnt/blobdisk/outfile; sleep 1; done\n    volumeMounts:\n    - name: blobdisk01\n      mountPath: /mnt/blobdisk\n    securityContext:\n      privileged: true\n  volumes:\n  - name: blobdisk01\n    persistentVolumeClaim:\n      claimName: pv-dd-dedicated-hdd-5g\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpf0exuavn.yaml: (object: <no namespace>/pod-uses-dedicated-hdd-5g /v1, Kind=Pod) The container \"az-c-01\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpf0exuavn.yaml: (object: <no namespace>/pod-uses-dedicated-hdd-5g /v1, Kind=Pod) container \"az-c-01\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpf0exuavn.yaml: (object: <no namespace>/pod-uses-dedicated-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpf0exuavn.yaml: (object: <no namespace>/pod-uses-dedicated-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpf0exuavn.yaml: (object: <no namespace>/pod-uses-dedicated-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpf0exuavn.yaml: (object: <no namespace>/pod-uses-dedicated-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpf0exuavn.yaml: (object: <no namespace>/pod-uses-dedicated-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/azure_disk/claim/blob-based-disk/dedicated-hdd/pod-uses-dedicated-hdd.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-uses-dedicated-hdd-5g\n  labels:\n    name: storage\nspec:\n  containers:\n  - image: nginx\n    name: az-c-01\n    command:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> /mnt/blobdisk/outfile; sleep 1; done\n    volumeMounts:\n    - name: blobdisk01\n      mountPath: /mnt/blobdisk\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-5g40al\n  volumes:\n  - name: blobdisk01\n    persistentVolumeClaim:\n      claimName: pv-dd-dedicated-hdd-5g\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-j6o1j6\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbeoz24x1.yaml: (object: <no namespace>/pod-uses-dedicated-hdd-5g /v1, Kind=Pod) The container \"az-c-01\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbeoz24x1.yaml: (object: <no namespace>/pod-uses-dedicated-hdd-5g /v1, Kind=Pod) container \"az-c-01\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbeoz24x1.yaml: (object: <no namespace>/pod-uses-dedicated-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbeoz24x1.yaml: (object: <no namespace>/pod-uses-dedicated-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbeoz24x1.yaml: (object: <no namespace>/pod-uses-dedicated-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/javaweb-tomcat-sidecar/javaweb-2.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: javaweb-2\nspec:\n  initContainers:\n  - image: resouer/sample:v2\n    name: war\n    command:\n    - cp\n    - /sample.war\n    - /app\n    volumeMounts:\n    - mountPath: /app\n      name: app-volume\n  containers:\n  - image: resouer/mytomcat:7.0\n    name: tomcat\n    command:\n    - sh\n    - -c\n    - /root/apache-tomcat-7.0.42-v2/bin/start.sh\n    volumeMounts:\n    - mountPath: /root/apache-tomcat-7.0.42-v2/webapps\n      name: app-volume\n    ports:\n    - containerPort: 8080\n      hostPort: 8001\n    securityContext:\n      privileged: true\n  volumes:\n  - name: app-volume\n    emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb5ydh3yh.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"war\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb5ydh3yh.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb5ydh3yh.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb5ydh3yh.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb5ydh3yh.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"war\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb5ydh3yh.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb5ydh3yh.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"war\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb5ydh3yh.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb5ydh3yh.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"war\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb5ydh3yh.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 10 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/javaweb-tomcat-sidecar/javaweb-2.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: javaweb-2\nspec:\n  initContainers:\n  - image: resouer/sample:v2\n    name: war\n    command:\n    - cp\n    - /sample.war\n    - /app\n    volumeMounts:\n    - mountPath: /app\n      name: app-volume\n  containers:\n  - image: resouer/mytomcat:7.0\n    name: tomcat\n    command:\n    - sh\n    - -c\n    - /root/apache-tomcat-7.0.42-v2/bin/start.sh\n    volumeMounts:\n    - mountPath: /root/apache-tomcat-7.0.42-v2/webapps\n      name: app-volume\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-ntnph9\n    ports:\n    - containerPort: 8080\n      hostPort: 8001\n  volumes:\n  - name: app-volume\n    emptyDir: {}\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-tmla1k\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz4455cpa.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"war\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz4455cpa.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz4455cpa.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"war\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz4455cpa.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz4455cpa.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"war\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz4455cpa.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz4455cpa.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"war\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz4455cpa.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cpu-manager/exclusive-1.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-1\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-1\n    resources:\n      requests:\n        cpu: 1\n        memory: 256M\n      limits:\n        cpu: 1\n        memory: 256M\n    securityContext:\n      privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq6puegdp.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) The container \"exclusive-1\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq6puegdp.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) container \"exclusive-1\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq6puegdp.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) container \"exclusive-1\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq6puegdp.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) container \"exclusive-1\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq6puegdp.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) container \"exclusive-1\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cpu-manager/exclusive-1.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-1\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-1\n    resources:\n      requests:\n        cpu: 1\n        memory: 256M\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9j9whf9m.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) The container \"exclusive-1\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9j9whf9m.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) container \"exclusive-1\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9j9whf9m.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) container \"exclusive-1\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9j9whf9m.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) container \"exclusive-1\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cpu-manager/exclusive-1.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-1\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-1\n    resources:\n      requests:\n        cpu: 1\n        memory: 256M\n      limits:\n        cpu: 1\n        memory: 256M\n    volumeMounts:\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-xvlblm\n  volumes:\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-a2bmy3\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp27zfj5l7.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) The container \"exclusive-1\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp27zfj5l7.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) container \"exclusive-1\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp27zfj5l7.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) container \"exclusive-1\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/openshift-origin/etcd-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etcd\nspec:\n  selector:\n    matchLabels:\n      name: etcd\n  strategy:\n    type: Recreate\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        name: etcd\n    spec:\n      containers:\n      - name: member\n        image: openshift/etcd-20-centos7\n        ports:\n        - containerPort: 2379\n          protocol: TCP\n        - containerPort: 2380\n          protocol: TCP\n        env:\n        - name: ETCD_NUM_MEMBERS\n          value: '3'\n        - name: ETCD_INITIAL_CLUSTER_STATE\n          value: new\n        - name: ETCD_INITIAL_CLUSTER_TOKEN\n          value: INSERT_ETCD_INITIAL_CLUSTER_TOKEN\n        - name: ETCD_DISCOVERY_TOKEN\n          value: INSERT_ETCD_DISCOVERY_TOKEN\n        - name: ETCD_DISCOVERY_URL\n          value: http://etcd-discovery:2379\n        - name: ETCDCTL_PEERS\n          value: http://etcd:2379\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          capabilities: {}\n          privileged: true\n      restartPolicy: Always\n      dnsPolicy: ClusterFirst\n      serviceAccount: ''\nstatus: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxvl5zspr.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxvl5zspr.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) The container \"member\" is using an invalid container image, \"openshift/etcd-20-centos7\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxvl5zspr.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxvl5zspr.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxvl5zspr.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxvl5zspr.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxvl5zspr.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxvl5zspr.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxvl5zspr.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 9 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/openshift-origin/etcd-controller.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etcd\nspec:\n  selector:\n    matchLabels:\n      name: etcd\n  strategy:\n    type: Recreate\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        name: etcd\n    spec:\n      containers:\n      - name: member\n        image: openshift/etcd-20-centos7\n        ports:\n        - containerPort: 2379\n          protocol: TCP\n        - containerPort: 2380\n          protocol: TCP\n        env:\n        - name: ETCD_NUM_MEMBERS\n          value: '3'\n        - name: ETCD_INITIAL_CLUSTER_STATE\n          value: new\n        - name: ETCD_INITIAL_CLUSTER_TOKEN\n          value: INSERT_ETCD_INITIAL_CLUSTER_TOKEN\n        - name: ETCD_DISCOVERY_TOKEN\n          value: INSERT_ETCD_DISCOVERY_TOKEN\n        - name: ETCD_DISCOVERY_URL\n          value: http://etcd-discovery:2379\n        - name: ETCDCTL_PEERS\n          value: http://etcd:2379\n        terminationMessagePath: /dev/termination-log\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          capabilities: {}\n          privileged: false\n      restartPolicy: Always\n      dnsPolicy: ClusterFirst\n      serviceAccount: ''\nstatus: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpumnwh24c.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpumnwh24c.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) The container \"member\" is using an invalid container image, \"openshift/etcd-20-centos7\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpumnwh24c.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpumnwh24c.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpumnwh24c.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpumnwh24c.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpumnwh24c.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/openshift-origin/etcd-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etcd\nspec:\n  selector:\n    matchLabels:\n      name: etcd\n  strategy:\n    type: Recreate\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        name: etcd\n    spec:\n      containers:\n      - name: member\n        image: openshift/etcd-20-centos7\n        ports:\n        - containerPort: 2379\n          protocol: TCP\n        - containerPort: 2380\n          protocol: TCP\n        env:\n        - name: ETCD_NUM_MEMBERS\n          value: '3'\n        - name: ETCD_INITIAL_CLUSTER_STATE\n          value: new\n        - name: ETCD_INITIAL_CLUSTER_TOKEN\n          value: INSERT_ETCD_INITIAL_CLUSTER_TOKEN\n        - name: ETCD_DISCOVERY_TOKEN\n          value: INSERT_ETCD_DISCOVERY_TOKEN\n        - name: ETCD_DISCOVERY_URL\n          value: http://etcd-discovery:2379\n        - name: ETCDCTL_PEERS\n          value: http://etcd:2379\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          capabilities: {}\n          privileged: false\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-32gj9g\n      restartPolicy: Always\n      dnsPolicy: ClusterFirst\n      serviceAccount: ''\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-tj3r99\n          type: DirectoryOrCreate\nstatus: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6bc71it0.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6bc71it0.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) The container \"member\" is using an invalid container image, \"openshift/etcd-20-centos7\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6bc71it0.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6bc71it0.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6bc71it0.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6bc71it0.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6bc71it0.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/openshift-origin/etcd-controller.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etcd\nspec:\n  selector:\n    matchLabels:\n      name: etcd\n  strategy:\n    type: Recreate\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        name: etcd\n    spec:\n      containers:\n      - name: member\n        image: openshift/etcd-20-centos7\n        ports:\n        - containerPort: 2379\n          protocol: TCP\n        - containerPort: 2380\n          protocol: TCP\n        env:\n        - name: ETCD_NUM_MEMBERS\n          value: '3'\n        - name: ETCD_INITIAL_CLUSTER_STATE\n          value: new\n        - name: ETCD_INITIAL_CLUSTER_TOKEN\n          value: INSERT_ETCD_INITIAL_CLUSTER_TOKEN\n        - name: ETCD_DISCOVERY_TOKEN\n          value: INSERT_ETCD_DISCOVERY_TOKEN\n        - name: ETCD_DISCOVERY_URL\n          value: http://etcd-discovery:2379\n        - name: ETCDCTL_PEERS\n          value: http://etcd:2379\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        imagePullPolicy: IfNotPresent\n      restartPolicy: Always\n      dnsPolicy: ClusterFirst\n      serviceAccount: ''\nstatus: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmwxpeyhd.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) The container \"member\" is using an invalid container image, \"openshift/etcd-20-centos7\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmwxpeyhd.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmwxpeyhd.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmwxpeyhd.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmwxpeyhd.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmwxpeyhd.yaml: (object: <no namespace>/etcd apps/v1, Kind=Deployment) container \"member\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/flexvolume/nginx-lvm.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  namespace: default\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - name: test\n      mountPath: /data\n    ports:\n    - containerPort: 80\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test\n    flexVolume:\n      driver: kubernetes.io/lvm\n      fsType: ext4\n      options:\n        volumeID: vol1\n        size: 1000m\n        volumegroup: kube_vg\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp62s1sd77.yaml: (object: default/nginx /v1, Kind=Pod) The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp62s1sd77.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp62s1sd77.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp62s1sd77.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp62s1sd77.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp62s1sd77.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp62s1sd77.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/flexvolume/nginx-lvm.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  namespace: default\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - name: test\n      mountPath: /data\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-iu3asy\n    ports:\n    - containerPort: 80\n  volumes:\n  - name: test\n    flexVolume:\n      driver: kubernetes.io/lvm\n      fsType: ext4\n      options:\n        volumeID: vol1\n        size: 1000m\n        volumegroup: kube_vg\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-9iqbg9\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5y0nhjkp.yaml: (object: default/nginx /v1, Kind=Pod) The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5y0nhjkp.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5y0nhjkp.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5y0nhjkp.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5y0nhjkp.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook/frontend-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google-samples/gb-frontend:v5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcaqe053w.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcaqe053w.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcaqe053w.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcaqe053w.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcaqe053w.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcaqe053w.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook/frontend-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google-samples/gb-frontend:v5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-tbwcfv\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-xjpwop\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe32rt1qg.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe32rt1qg.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe32rt1qg.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe32rt1qg.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: applicationset-controller\n    app.kubernetes.io/name: argocd-applicationset-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-applicationset-controller\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-applicationset-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-applicationset-controller\n    spec:\n      containers:\n      - args:\n        - /usr/local/bin/argocd-applicationset-controller\n        env:\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_ANNOTATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.annotations\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_LABELS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.labels\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_LEADER_ELECTION\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.leader.election\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_POLICY_OVERRIDE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.policy.override\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.debug\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DRY_RUN\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.dryrun\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_PROGRESSIVE_SYNCS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.progressive.syncs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_TOKENREF_STRICT_MODE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.tokenref.strict.mode\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_CONCURRENT_RECONCILIATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.concurrent.reconciliations.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.allowed.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.webhook.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REQUEUE_AFTER\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.requeue.after\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: argocd-applicationset-controller\n        ports:\n        - containerPort: 7000\n          name: webhook\n        - containerPort: 8080\n          name: metrics\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-applicationset-controller\n      volumes:\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - configMap:\n          name: argocd-gpg-keys-cm\n        name: gpg-keys\n      - emptyDir: {}\n        name: gpg-keyring\n      - emptyDir: {}\n        name: tmp\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmposplhd22.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) The container \"argocd-applicationset-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmposplhd22.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) serviceAccount \"argocd-applicationset-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmposplhd22.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmposplhd22.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmposplhd22.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmposplhd22.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: applicationset-controller\n    app.kubernetes.io/name: argocd-applicationset-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-applicationset-controller\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-applicationset-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-applicationset-controller\n    spec:\n      containers:\n      - args:\n        - /usr/local/bin/argocd-applicationset-controller\n        env:\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_ANNOTATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.annotations\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_LABELS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.labels\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_LEADER_ELECTION\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.leader.election\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_POLICY_OVERRIDE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.policy.override\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.debug\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DRY_RUN\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.dryrun\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_PROGRESSIVE_SYNCS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.progressive.syncs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_TOKENREF_STRICT_MODE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.tokenref.strict.mode\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_CONCURRENT_RECONCILIATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.concurrent.reconciliations.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.allowed.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.webhook.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REQUEUE_AFTER\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.requeue.after\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: argocd-applicationset-controller\n        ports:\n        - containerPort: 7000\n          name: webhook\n        - containerPort: 8080\n          name: metrics\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-z06wm4\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-applicationset-controller\n      volumes:\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - configMap:\n          name: argocd-gpg-keys-cm\n        name: gpg-keys\n      - emptyDir: {}\n        name: gpg-keyring\n      - emptyDir: {}\n        name: tmp\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-hcy9sh\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpge6msap3.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) The container \"argocd-applicationset-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpge6msap3.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) serviceAccount \"argocd-applicationset-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpge6msap3.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpge6msap3.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: applicationset-controller\n    app.kubernetes.io/name: argocd-applicationset-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-applicationset-controller\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-applicationset-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-applicationset-controller\n    spec:\n      containers:\n      - args:\n        - /usr/local/bin/argocd-applicationset-controller\n        env:\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_ANNOTATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.annotations\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_LABELS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.labels\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_LEADER_ELECTION\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.leader.election\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_POLICY_OVERRIDE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.policy.override\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.debug\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DRY_RUN\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.dryrun\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_PROGRESSIVE_SYNCS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.progressive.syncs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_TOKENREF_STRICT_MODE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.tokenref.strict.mode\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_CONCURRENT_RECONCILIATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.concurrent.reconciliations.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.allowed.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.webhook.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REQUEUE_AFTER\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.requeue.after\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: argocd-applicationset-controller\n        ports:\n        - containerPort: 7000\n          name: webhook\n        - containerPort: 8080\n          name: metrics\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-applicationset-controller\n      volumes:\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - configMap:\n          name: argocd-gpg-keys-cm\n        name: gpg-keys\n      - emptyDir: {}\n        name: gpg-keyring\n      - emptyDir: {}\n        name: tmp\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4ol29yh2.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) The container \"argocd-applicationset-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4ol29yh2.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4ol29yh2.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) serviceAccount \"argocd-applicationset-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4ol29yh2.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4ol29yh2.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4ol29yh2.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: dex-server\n    app.kubernetes.io/name: argocd-dex-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-dex-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-dex-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-dex-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - command:\n        - /shared/argocd-dex\n        - rundex\n        env:\n        - name: ARGOCD_DEX_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.disable.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        image: ghcr.io/dexidp/dex:v2.41.1\n        imagePullPolicy: Always\n        name: dex\n        ports:\n        - containerPort: 5556\n        - containerPort: 5557\n        - containerPort: 5558\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n        - mountPath: /tls\n          name: argocd-dex-server-tls\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /shared/argocd-dex\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: copyutil\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-dex-server\n      volumes:\n      - emptyDir: {}\n        name: static-files\n      - emptyDir: {}\n        name: dexconfig\n      - name: argocd-dex-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-dex-server-tls\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6rmntwlm.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) The container \"copyutil\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6rmntwlm.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) serviceAccount \"argocd-dex-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6rmntwlm.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6rmntwlm.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6rmntwlm.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6rmntwlm.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6rmntwlm.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6rmntwlm.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: dex-server\n    app.kubernetes.io/name: argocd-dex-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-dex-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-dex-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-dex-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - command:\n        - /shared/argocd-dex\n        - rundex\n        env:\n        - name: ARGOCD_DEX_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.disable.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        image: ghcr.io/dexidp/dex:v2.41.1\n        imagePullPolicy: Always\n        name: dex\n        ports:\n        - containerPort: 5556\n        - containerPort: 5557\n        - containerPort: 5558\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n        - mountPath: /tls\n          name: argocd-dex-server-tls\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-0viwq0\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /shared/argocd-dex\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: copyutil\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-dex-server\n      volumes:\n      - emptyDir: {}\n        name: static-files\n      - emptyDir: {}\n        name: dexconfig\n      - name: argocd-dex-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-dex-server-tls\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-x2jfsq\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvflynj8h.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) The container \"copyutil\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvflynj8h.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) serviceAccount \"argocd-dex-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvflynj8h.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvflynj8h.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvflynj8h.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvflynj8h.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: dex-server\n    app.kubernetes.io/name: argocd-dex-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-dex-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-dex-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-dex-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - command:\n        - /shared/argocd-dex\n        - rundex\n        env:\n        - name: ARGOCD_DEX_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.disable.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        image: ghcr.io/dexidp/dex:v2.41.1\n        imagePullPolicy: Always\n        name: dex\n        ports:\n        - containerPort: 5556\n        - containerPort: 5557\n        - containerPort: 5558\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n        - mountPath: /tls\n          name: argocd-dex-server-tls\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /shared/argocd-dex\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: copyutil\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-dex-server\n      volumes:\n      - emptyDir: {}\n        name: static-files\n      - emptyDir: {}\n        name: dexconfig\n      - name: argocd-dex-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-dex-server-tls\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkatzprd4.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) The container \"copyutil\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkatzprd4.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkatzprd4.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkatzprd4.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) serviceAccount \"argocd-dex-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkatzprd4.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkatzprd4.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkatzprd4.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkatzprd4.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkatzprd4.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkatzprd4.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 10 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: notifications-controller\n    app.kubernetes.io/name: argocd-notifications-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-notifications-controller\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-notifications-controller\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-notifications-controller\n    spec:\n      containers:\n      - args:\n        - /usr/local/bin/argocd-notifications\n        env:\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_SELF_SERVICE_NOTIFICATION_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.selfservice.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          tcpSocket:\n            port: 9001\n        name: argocd-notifications-controller\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: true\n        volumeMounts:\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        workingDir: /app\n      nodeSelector:\n        kubernetes.io/os: linux\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      serviceAccountName: argocd-notifications-controller\n      volumes:\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnk5egf3q.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) The container \"argocd-notifications-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnk5egf3q.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" does not expose port 9001 for the TCPSocket (check: liveness-port, remediation: Check which ports you've exposed and ensure they match what you have specified in the liveness probe.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnk5egf3q.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) serviceAccount \"argocd-notifications-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnk5egf3q.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnk5egf3q.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnk5egf3q.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnk5egf3q.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: notifications-controller\n    app.kubernetes.io/name: argocd-notifications-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-notifications-controller\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-notifications-controller\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-notifications-controller\n    spec:\n      containers:\n      - args:\n        - /usr/local/bin/argocd-notifications\n        env:\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_SELF_SERVICE_NOTIFICATION_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.selfservice.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          tcpSocket:\n            port: 9001\n        name: argocd-notifications-controller\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-cov3jt\n        workingDir: /app\n      nodeSelector:\n        kubernetes.io/os: linux\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      serviceAccountName: argocd-notifications-controller\n      volumes:\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-kepv0u\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpryhs9kux.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) The container \"argocd-notifications-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpryhs9kux.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" does not expose port 9001 for the TCPSocket (check: liveness-port, remediation: Check which ports you've exposed and ensure they match what you have specified in the liveness probe.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpryhs9kux.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) serviceAccount \"argocd-notifications-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpryhs9kux.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpryhs9kux.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: notifications-controller\n    app.kubernetes.io/name: argocd-notifications-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-notifications-controller\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-notifications-controller\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-notifications-controller\n    spec:\n      containers:\n      - args:\n        - /usr/local/bin/argocd-notifications\n        env:\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_SELF_SERVICE_NOTIFICATION_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.selfservice.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          tcpSocket:\n            port: 9001\n        name: argocd-notifications-controller\n        volumeMounts:\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        workingDir: /app\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-notifications-controller\n      volumes:\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo0spj0_o.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) The container \"argocd-notifications-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo0spj0_o.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" does not expose port 9001 for the TCPSocket (check: liveness-port, remediation: Check which ports you've exposed and ensure they match what you have specified in the liveness probe.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo0spj0_o.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo0spj0_o.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) serviceAccount \"argocd-notifications-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo0spj0_o.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo0spj0_o.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo0spj0_o.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/name: argocd-redis-ha-haproxy\n    app.kubernetes.io/part-of: argocd\n  name: argocd-redis-ha-haproxy\nspec:\n  replicas: 3\n  revisionHistoryLimit: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis-ha-haproxy\n  strategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        checksum/config: cd6508bdf9819601c454d0cc491fb77a209e3a88761d92514d105b6681829953\n        prometheus.io/path: /metrics\n        prometheus.io/port: '9101'\n        prometheus.io/scrape: 'true'\n      labels:\n        app.kubernetes.io/name: argocd-redis-ha-haproxy\n      name: argocd-redis-ha-haproxy\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-redis-ha-haproxy\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: true\n      containers:\n      - env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle: {}\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        name: haproxy\n        ports:\n        - containerPort: 8888\n          name: probe\n        - containerPort: 6379\n          name: redis\n        - containerPort: 9101\n          name: metrics-port\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/haproxy\n          name: data\n        - mountPath: /run/haproxy\n          name: shared-socket\n      initContainers:\n      - command:\n        - argocd\n        - admin\n        - redis-initial-password\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: IfNotPresent\n        name: secret-init\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n      - args:\n        - /readonly/haproxy_init.sh\n        command:\n        - sh\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        name: config-init\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /readonly\n          name: config-volume\n          readOnly: true\n        - mountPath: /data\n          name: data\n      securityContext:\n        fsGroup: 99\n        runAsNonRoot: true\n        runAsUser: 99\n      serviceAccountName: argocd-redis-ha-haproxy\n      volumes:\n      - configMap:\n          name: argocd-redis-ha-configmap\n        name: config-volume\n      - emptyDir: {}\n        name: shared-socket\n      - emptyDir: {}\n        name: data\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2cwvzv0v.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) The container \"secret-init\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2cwvzv0v.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) serviceAccount \"argocd-redis-ha-haproxy\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2cwvzv0v.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2cwvzv0v.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2cwvzv0v.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"secret-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2cwvzv0v.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2cwvzv0v.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2cwvzv0v.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"secret-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2cwvzv0v.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2cwvzv0v.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 10 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/name: argocd-redis-ha-haproxy\n    app.kubernetes.io/part-of: argocd\n  name: argocd-redis-ha-haproxy\nspec:\n  replicas: 3\n  revisionHistoryLimit: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis-ha-haproxy\n  strategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        checksum/config: cd6508bdf9819601c454d0cc491fb77a209e3a88761d92514d105b6681829953\n        prometheus.io/path: /metrics\n        prometheus.io/port: '9101'\n        prometheus.io/scrape: 'true'\n      labels:\n        app.kubernetes.io/name: argocd-redis-ha-haproxy\n      name: argocd-redis-ha-haproxy\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-redis-ha-haproxy\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: true\n      containers:\n      - env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle: {}\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        name: haproxy\n        ports:\n        - containerPort: 8888\n          name: probe\n        - containerPort: 6379\n          name: redis\n        - containerPort: 9101\n          name: metrics-port\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /usr/local/etc/haproxy\n          name: data\n        - mountPath: /run/haproxy\n          name: shared-socket\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-djccb1\n      initContainers:\n      - command:\n        - argocd\n        - admin\n        - redis-initial-password\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: IfNotPresent\n        name: secret-init\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n      - args:\n        - /readonly/haproxy_init.sh\n        command:\n        - sh\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        name: config-init\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /readonly\n          name: config-volume\n          readOnly: true\n        - mountPath: /data\n          name: data\n      securityContext:\n        fsGroup: 99\n        runAsNonRoot: true\n        runAsUser: 99\n      serviceAccountName: argocd-redis-ha-haproxy\n      volumes:\n      - configMap:\n          name: argocd-redis-ha-configmap\n        name: config-volume\n      - emptyDir: {}\n        name: shared-socket\n      - emptyDir: {}\n        name: data\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-y55y8e\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmph4fl4z3t.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) The container \"secret-init\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmph4fl4z3t.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) serviceAccount \"argocd-redis-ha-haproxy\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmph4fl4z3t.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"secret-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmph4fl4z3t.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmph4fl4z3t.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmph4fl4z3t.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"secret-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmph4fl4z3t.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmph4fl4z3t.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/name: argocd-redis-ha-haproxy\n    app.kubernetes.io/part-of: argocd\n  name: argocd-redis-ha-haproxy\nspec:\n  replicas: 3\n  revisionHistoryLimit: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis-ha-haproxy\n  strategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        checksum/config: cd6508bdf9819601c454d0cc491fb77a209e3a88761d92514d105b6681829953\n        prometheus.io/path: /metrics\n        prometheus.io/port: '9101'\n        prometheus.io/scrape: 'true'\n      labels:\n        app.kubernetes.io/name: argocd-redis-ha-haproxy\n      name: argocd-redis-ha-haproxy\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-redis-ha-haproxy\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: true\n      containers:\n      - env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle: {}\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        name: haproxy\n        ports:\n        - containerPort: 8888\n          name: probe\n        - containerPort: 6379\n          name: redis\n        - containerPort: 9101\n          name: metrics-port\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        volumeMounts:\n        - mountPath: /usr/local/etc/haproxy\n          name: data\n        - mountPath: /run/haproxy\n          name: shared-socket\n      initContainers:\n      - command:\n        - argocd\n        - admin\n        - redis-initial-password\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: IfNotPresent\n        name: secret-init\n      - args:\n        - /readonly/haproxy_init.sh\n        command:\n        - sh\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        name: config-init\n        volumeMounts:\n        - mountPath: /readonly\n          name: config-volume\n          readOnly: true\n        - mountPath: /data\n          name: data\n      serviceAccountName: argocd-redis-ha-haproxy\n      volumes:\n      - configMap:\n          name: argocd-redis-ha-configmap\n        name: config-volume\n      - emptyDir: {}\n        name: shared-socket\n      - emptyDir: {}\n        name: data\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeah0vhq4.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) The container \"secret-init\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeah0vhq4.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"secret-init\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeah0vhq4.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeah0vhq4.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeah0vhq4.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) serviceAccount \"argocd-redis-ha-haproxy\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeah0vhq4.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"secret-init\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeah0vhq4.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeah0vhq4.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeah0vhq4.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"secret-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeah0vhq4.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeah0vhq4.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeah0vhq4.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"secret-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeah0vhq4.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeah0vhq4.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 14 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: repo-server\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-repo-server\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-repo-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: topology.kubernetes.io/zone\n            weight: 100\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-repo-server\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: false\n      containers:\n      - args:\n        - /usr/local/bin/argocd-repo-server\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.metrics.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.minversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.maxversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.ciphers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.repo.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.max.combined.directory.manifests.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.tar.exclusions\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_USE_MANIFEST_GENERATE_PATHS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.use.manifest.generate.paths\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.allow.oob.symlinks\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.tar.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REVISION_CACHE_LOCK_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.revision.cache.lock.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.lsremote.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_REQUEST_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.request.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GRPC_MAX_SIZE_MB\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.grpc.max.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_INCLUDE_HIDDEN_DIRECTORIES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.include.hidden.directories\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: HELM_CACHE_HOME\n          value: /helm-working-dir\n        - name: HELM_CONFIG_HOME\n          value: /helm-working-dir\n        - name: HELM_DATA_HOME\n          value: /helm-working-dir\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz?full=true\n            port: 8084\n          initialDelaySeconds: 30\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: argocd-repo-server\n        ports:\n        - containerPort: 8081\n        - containerPort: 8084\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8084\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /helm-working-dir\n          name: helm-working-dir\n        - mountPath: /home/argocd/cmp-server/plugins\n          name: plugins\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /var/run/argocd/argocd-cmp-server\n        image: quay.io/argoproj/argocd:latest\n        name: copyutil\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /var/run/argocd\n          name: var-files\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-repo-server\n      volumes:\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - configMap:\n          name: argocd-gpg-keys-cm\n        name: gpg-keys\n      - emptyDir: {}\n        name: gpg-keyring\n      - emptyDir: {}\n        name: tmp\n      - emptyDir: {}\n        name: helm-working-dir\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - emptyDir: {}\n        name: var-files\n      - emptyDir: {}\n        name: plugins\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa509ke2k.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"copyutil\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa509ke2k.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"argocd-repo-server\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa509ke2k.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) serviceAccount \"argocd-repo-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa509ke2k.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa509ke2k.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa509ke2k.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa509ke2k.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa509ke2k.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa509ke2k.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 9 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: repo-server\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-repo-server\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-repo-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: topology.kubernetes.io/zone\n            weight: 100\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-repo-server\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: false\n      containers:\n      - args:\n        - /usr/local/bin/argocd-repo-server\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.metrics.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.minversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.maxversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.ciphers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.repo.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.max.combined.directory.manifests.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.tar.exclusions\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_USE_MANIFEST_GENERATE_PATHS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.use.manifest.generate.paths\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.allow.oob.symlinks\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.tar.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REVISION_CACHE_LOCK_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.revision.cache.lock.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.lsremote.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_REQUEST_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.request.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GRPC_MAX_SIZE_MB\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.grpc.max.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_INCLUDE_HIDDEN_DIRECTORIES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.include.hidden.directories\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: HELM_CACHE_HOME\n          value: /helm-working-dir\n        - name: HELM_CONFIG_HOME\n          value: /helm-working-dir\n        - name: HELM_DATA_HOME\n          value: /helm-working-dir\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz?full=true\n            port: 8084\n          initialDelaySeconds: 30\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: argocd-repo-server\n        ports:\n        - containerPort: 8081\n        - containerPort: 8084\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8084\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /helm-working-dir\n          name: helm-working-dir\n        - mountPath: /home/argocd/cmp-server/plugins\n          name: plugins\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-a4cxm1\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /var/run/argocd/argocd-cmp-server\n        image: quay.io/argoproj/argocd:latest\n        name: copyutil\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /var/run/argocd\n          name: var-files\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-repo-server\n      volumes:\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - configMap:\n          name: argocd-gpg-keys-cm\n        name: gpg-keys\n      - emptyDir: {}\n        name: gpg-keyring\n      - emptyDir: {}\n        name: tmp\n      - emptyDir: {}\n        name: helm-working-dir\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - emptyDir: {}\n        name: var-files\n      - emptyDir: {}\n        name: plugins\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-bw9byj\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5se09djk.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"copyutil\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5se09djk.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"argocd-repo-server\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5se09djk.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) serviceAccount \"argocd-repo-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5se09djk.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5se09djk.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5se09djk.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5se09djk.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: repo-server\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-repo-server\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-repo-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: topology.kubernetes.io/zone\n            weight: 100\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-repo-server\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: false\n      containers:\n      - args:\n        - /usr/local/bin/argocd-repo-server\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.metrics.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.minversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.maxversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.ciphers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.repo.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.max.combined.directory.manifests.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.tar.exclusions\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_USE_MANIFEST_GENERATE_PATHS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.use.manifest.generate.paths\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.allow.oob.symlinks\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.tar.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REVISION_CACHE_LOCK_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.revision.cache.lock.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.lsremote.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_REQUEST_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.request.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GRPC_MAX_SIZE_MB\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.grpc.max.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_INCLUDE_HIDDEN_DIRECTORIES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.include.hidden.directories\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: HELM_CACHE_HOME\n          value: /helm-working-dir\n        - name: HELM_CONFIG_HOME\n          value: /helm-working-dir\n        - name: HELM_DATA_HOME\n          value: /helm-working-dir\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz?full=true\n            port: 8084\n          initialDelaySeconds: 30\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: argocd-repo-server\n        ports:\n        - containerPort: 8081\n        - containerPort: 8084\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8084\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /helm-working-dir\n          name: helm-working-dir\n        - mountPath: /home/argocd/cmp-server/plugins\n          name: plugins\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /var/run/argocd/argocd-cmp-server\n        image: quay.io/argoproj/argocd:latest\n        name: copyutil\n        volumeMounts:\n        - mountPath: /var/run/argocd\n          name: var-files\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-repo-server\n      volumes:\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - configMap:\n          name: argocd-gpg-keys-cm\n        name: gpg-keys\n      - emptyDir: {}\n        name: gpg-keyring\n      - emptyDir: {}\n        name: tmp\n      - emptyDir: {}\n        name: helm-working-dir\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - emptyDir: {}\n        name: var-files\n      - emptyDir: {}\n        name: plugins\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuesilgn8.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"copyutil\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuesilgn8.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"argocd-repo-server\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuesilgn8.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuesilgn8.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuesilgn8.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) serviceAccount \"argocd-repo-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuesilgn8.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuesilgn8.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuesilgn8.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuesilgn8.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuesilgn8.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuesilgn8.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 11 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: server\n    app.kubernetes.io/name: argocd-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-server\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-server\n              topologyKey: topology.kubernetes.io/zone\n            weight: 100\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-server\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - args:\n        - /usr/local/bin/argocd-server\n        env:\n        - name: ARGOCD_API_SERVER_REPLICAS\n          value: '2'\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_SERVER_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: server.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_BASEHREF\n          valueFrom:\n            configMapKeyRef:\n              key: server.basehref\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ROOTPATH\n          valueFrom:\n            configMapKeyRef:\n              key: server.rootpath\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: server.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: server.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DISABLE_AUTH\n          valueFrom:\n            configMapKeyRef:\n              key: server.disable.auth\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_GZIP\n          valueFrom:\n            configMapKeyRef:\n              key: server.enable.gzip\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_X_FRAME_OPTIONS\n          valueFrom:\n            configMapKeyRef:\n              key: server.x.frame.options\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_CONTENT_SECURITY_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: server.content.security.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.minversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.maxversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.ciphers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_CONNECTION_STATUS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.connection.status.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OIDC_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.oidc.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOGIN_ATTEMPTS_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.login.attempts.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_STATIC_ASSETS\n          valueFrom:\n            configMapKeyRef:\n              key: server.staticassets\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_MAX_COOKIE_NUMBER\n          valueFrom:\n            configMapKeyRef:\n              key: server.http.cookie.maxnumber\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: server.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_METRICS_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: server.metrics.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_PROXY_EXTENSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.enable.proxy.extension\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              key: server.k8sclient.retry.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              key: server.k8sclient.retry.base.backoff\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_API_CONTENT_TYPES\n          valueFrom:\n            configMapKeyRef:\n              key: server.api.content.types\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: server.webhook.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.allowed.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: hydrator.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SYNC_WITH_REPLACE_ALLOWED\n          valueFrom:\n            configMapKeyRef:\n              key: server.sync.replace.allowed\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: 8080\n          initialDelaySeconds: 3\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: argocd-server\n        ports:\n        - containerPort: 8080\n        - containerPort: 8083\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 3\n          periodSeconds: 30\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/server/tls\n          name: argocd-repo-server-tls\n        - mountPath: /app/config/dex/tls\n          name: argocd-dex-server-tls\n        - mountPath: /home/argocd\n          name: plugins-home\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /home/argocd/params\n          name: argocd-cmd-params-cm\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-server\n      volumes:\n      - emptyDir: {}\n        name: plugins-home\n      - emptyDir: {}\n        name: tmp\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - name: argocd-dex-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-dex-server-tls\n      - configMap:\n          items:\n          - key: server.profile.enabled\n            path: profiler.enabled\n          name: argocd-cmd-params-cm\n          optional: true\n        name: argocd-cmd-params-cm\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5pbezwje.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) The container \"argocd-server\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5pbezwje.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) serviceAccount \"argocd-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5pbezwje.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5pbezwje.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5pbezwje.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5pbezwje.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: server\n    app.kubernetes.io/name: argocd-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-server\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-server\n              topologyKey: topology.kubernetes.io/zone\n            weight: 100\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-server\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - args:\n        - /usr/local/bin/argocd-server\n        env:\n        - name: ARGOCD_API_SERVER_REPLICAS\n          value: '2'\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_SERVER_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: server.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_BASEHREF\n          valueFrom:\n            configMapKeyRef:\n              key: server.basehref\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ROOTPATH\n          valueFrom:\n            configMapKeyRef:\n              key: server.rootpath\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: server.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: server.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DISABLE_AUTH\n          valueFrom:\n            configMapKeyRef:\n              key: server.disable.auth\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_GZIP\n          valueFrom:\n            configMapKeyRef:\n              key: server.enable.gzip\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_X_FRAME_OPTIONS\n          valueFrom:\n            configMapKeyRef:\n              key: server.x.frame.options\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_CONTENT_SECURITY_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: server.content.security.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.minversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.maxversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.ciphers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_CONNECTION_STATUS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.connection.status.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OIDC_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.oidc.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOGIN_ATTEMPTS_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.login.attempts.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_STATIC_ASSETS\n          valueFrom:\n            configMapKeyRef:\n              key: server.staticassets\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_MAX_COOKIE_NUMBER\n          valueFrom:\n            configMapKeyRef:\n              key: server.http.cookie.maxnumber\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: server.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_METRICS_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: server.metrics.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_PROXY_EXTENSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.enable.proxy.extension\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              key: server.k8sclient.retry.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              key: server.k8sclient.retry.base.backoff\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_API_CONTENT_TYPES\n          valueFrom:\n            configMapKeyRef:\n              key: server.api.content.types\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: server.webhook.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.allowed.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: hydrator.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SYNC_WITH_REPLACE_ALLOWED\n          valueFrom:\n            configMapKeyRef:\n              key: server.sync.replace.allowed\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: 8080\n          initialDelaySeconds: 3\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: argocd-server\n        ports:\n        - containerPort: 8080\n        - containerPort: 8083\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 3\n          periodSeconds: 30\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/server/tls\n          name: argocd-repo-server-tls\n        - mountPath: /app/config/dex/tls\n          name: argocd-dex-server-tls\n        - mountPath: /home/argocd\n          name: plugins-home\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /home/argocd/params\n          name: argocd-cmd-params-cm\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-k3iu9h\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-server\n      volumes:\n      - emptyDir: {}\n        name: plugins-home\n      - emptyDir: {}\n        name: tmp\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - name: argocd-dex-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-dex-server-tls\n      - configMap:\n          items:\n          - key: server.profile.enabled\n            path: profiler.enabled\n          name: argocd-cmd-params-cm\n          optional: true\n        name: argocd-cmd-params-cm\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-zpn39t\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb1b8l85l.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) The container \"argocd-server\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb1b8l85l.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) serviceAccount \"argocd-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb1b8l85l.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb1b8l85l.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: server\n    app.kubernetes.io/name: argocd-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-server\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-server\n              topologyKey: topology.kubernetes.io/zone\n            weight: 100\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-server\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - args:\n        - /usr/local/bin/argocd-server\n        env:\n        - name: ARGOCD_API_SERVER_REPLICAS\n          value: '2'\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_SERVER_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: server.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_BASEHREF\n          valueFrom:\n            configMapKeyRef:\n              key: server.basehref\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ROOTPATH\n          valueFrom:\n            configMapKeyRef:\n              key: server.rootpath\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: server.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: server.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DISABLE_AUTH\n          valueFrom:\n            configMapKeyRef:\n              key: server.disable.auth\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_GZIP\n          valueFrom:\n            configMapKeyRef:\n              key: server.enable.gzip\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_X_FRAME_OPTIONS\n          valueFrom:\n            configMapKeyRef:\n              key: server.x.frame.options\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_CONTENT_SECURITY_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: server.content.security.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.minversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.maxversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.ciphers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_CONNECTION_STATUS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.connection.status.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OIDC_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.oidc.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOGIN_ATTEMPTS_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.login.attempts.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_STATIC_ASSETS\n          valueFrom:\n            configMapKeyRef:\n              key: server.staticassets\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_MAX_COOKIE_NUMBER\n          valueFrom:\n            configMapKeyRef:\n              key: server.http.cookie.maxnumber\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: server.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_METRICS_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: server.metrics.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_PROXY_EXTENSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.enable.proxy.extension\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              key: server.k8sclient.retry.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              key: server.k8sclient.retry.base.backoff\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_API_CONTENT_TYPES\n          valueFrom:\n            configMapKeyRef:\n              key: server.api.content.types\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: server.webhook.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.allowed.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: hydrator.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SYNC_WITH_REPLACE_ALLOWED\n          valueFrom:\n            configMapKeyRef:\n              key: server.sync.replace.allowed\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: 8080\n          initialDelaySeconds: 3\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: argocd-server\n        ports:\n        - containerPort: 8080\n        - containerPort: 8083\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 3\n          periodSeconds: 30\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/server/tls\n          name: argocd-repo-server-tls\n        - mountPath: /app/config/dex/tls\n          name: argocd-dex-server-tls\n        - mountPath: /home/argocd\n          name: plugins-home\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /home/argocd/params\n          name: argocd-cmd-params-cm\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-server\n      volumes:\n      - emptyDir: {}\n        name: plugins-home\n      - emptyDir: {}\n        name: tmp\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - name: argocd-dex-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-dex-server-tls\n      - configMap:\n          items:\n          - key: server.profile.enabled\n            path: profiler.enabled\n          name: argocd-cmd-params-cm\n          optional: true\n        name: argocd-cmd-params-cm\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgohnxidb.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) The container \"argocd-server\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgohnxidb.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgohnxidb.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) serviceAccount \"argocd-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgohnxidb.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgohnxidb.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgohnxidb.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: application-controller\n    app.kubernetes.io/name: argocd-application-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-application-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-application-controller\n  serviceName: argocd-application-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-application-controller\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-application-controller\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - args:\n        - /usr/local/bin/argocd-application-controller\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_CONTROLLER_REPLICAS\n          value: '1'\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_HARD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.hard.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_RECONCILIATION_JITTER\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation.jitter\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_ERROR_GRACE_PERIOD_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.error.grace.period.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_STATUS_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.status.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OPERATION_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.operation.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_METRICS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.metrics.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_FACTOR\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.factor\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_CAP_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.cap.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SYNC_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.sync.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_PERSIST_RESOURCE_HEALTH\n          valueFrom:\n            configMapKeyRef:\n              key: controller.resource.health.persist\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CONTROLLER_SHARDING_ALGORITHM\n          valueFrom:\n            configMapKeyRef:\n              key: controller.sharding.algorithm\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_KUBECTL_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.kubectl.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              key: controller.k8sclient.retry.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              key: controller.k8sclient.retry.base.backoff\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SERVER_SIDE_DIFF\n          valueFrom:\n            configMapKeyRef:\n              key: controller.diff.server.side\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_IGNORE_NORMALIZER_JQ_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.ignore.normalizer.jq.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: hydrator.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_BATCH_EVENTS_PROCESSING\n          valueFrom:\n            configMapKeyRef:\n              key: controller.cluster.cache.batch.events.processing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_EVENTS_PROCESSING_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.cluster.cache.events.processing.interval\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: KUBECACHEDIR\n          value: /tmp/kubecache\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: argocd-application-controller\n        ports:\n        - containerPort: 8082\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8082\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        volumeMounts:\n        - mountPath: /app/config/controller/tls\n          name: argocd-repo-server-tls\n        - mountPath: /home/argocd\n          name: argocd-home\n        - mountPath: /home/argocd/params\n          name: argocd-cmd-params-cm\n        - mountPath: /tmp\n          name: argocd-application-controller-tmp\n        workingDir: /home/argocd\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-application-controller\n      volumes:\n      - emptyDir: {}\n        name: argocd-home\n      - emptyDir: {}\n        name: argocd-application-controller-tmp\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - configMap:\n          items:\n          - key: controller.profile.enabled\n            path: profiler.enabled\n          name: argocd-cmd-params-cm\n          optional: true\n        name: argocd-cmd-params-cm\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz8_o62qt.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) The container \"argocd-application-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz8_o62qt.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) serviceAccount \"argocd-application-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz8_o62qt.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz8_o62qt.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz8_o62qt.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz8_o62qt.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: application-controller\n    app.kubernetes.io/name: argocd-application-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-application-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-application-controller\n  serviceName: argocd-application-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-application-controller\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-application-controller\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - args:\n        - /usr/local/bin/argocd-application-controller\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_CONTROLLER_REPLICAS\n          value: '1'\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_HARD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.hard.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_RECONCILIATION_JITTER\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation.jitter\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_ERROR_GRACE_PERIOD_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.error.grace.period.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_STATUS_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.status.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OPERATION_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.operation.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_METRICS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.metrics.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_FACTOR\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.factor\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_CAP_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.cap.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SYNC_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.sync.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_PERSIST_RESOURCE_HEALTH\n          valueFrom:\n            configMapKeyRef:\n              key: controller.resource.health.persist\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CONTROLLER_SHARDING_ALGORITHM\n          valueFrom:\n            configMapKeyRef:\n              key: controller.sharding.algorithm\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_KUBECTL_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.kubectl.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              key: controller.k8sclient.retry.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              key: controller.k8sclient.retry.base.backoff\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SERVER_SIDE_DIFF\n          valueFrom:\n            configMapKeyRef:\n              key: controller.diff.server.side\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_IGNORE_NORMALIZER_JQ_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.ignore.normalizer.jq.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: hydrator.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_BATCH_EVENTS_PROCESSING\n          valueFrom:\n            configMapKeyRef:\n              key: controller.cluster.cache.batch.events.processing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_EVENTS_PROCESSING_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.cluster.cache.events.processing.interval\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: KUBECACHEDIR\n          value: /tmp/kubecache\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: argocd-application-controller\n        ports:\n        - containerPort: 8082\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8082\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /app/config/controller/tls\n          name: argocd-repo-server-tls\n        - mountPath: /home/argocd\n          name: argocd-home\n        - mountPath: /home/argocd/params\n          name: argocd-cmd-params-cm\n        - mountPath: /tmp\n          name: argocd-application-controller-tmp\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-f4elzm\n        workingDir: /home/argocd\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-application-controller\n      volumes:\n      - emptyDir: {}\n        name: argocd-home\n      - emptyDir: {}\n        name: argocd-application-controller-tmp\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - configMap:\n          items:\n          - key: controller.profile.enabled\n            path: profiler.enabled\n          name: argocd-cmd-params-cm\n          optional: true\n        name: argocd-cmd-params-cm\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-e9k65i\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv_1_r8xk.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) The container \"argocd-application-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv_1_r8xk.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) serviceAccount \"argocd-application-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv_1_r8xk.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv_1_r8xk.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: application-controller\n    app.kubernetes.io/name: argocd-application-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-application-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-application-controller\n  serviceName: argocd-application-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-application-controller\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-application-controller\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - args:\n        - /usr/local/bin/argocd-application-controller\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_CONTROLLER_REPLICAS\n          value: '1'\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_HARD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.hard.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_RECONCILIATION_JITTER\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation.jitter\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_ERROR_GRACE_PERIOD_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.error.grace.period.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_STATUS_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.status.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OPERATION_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.operation.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_METRICS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.metrics.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_FACTOR\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.factor\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_CAP_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.cap.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SYNC_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.sync.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_PERSIST_RESOURCE_HEALTH\n          valueFrom:\n            configMapKeyRef:\n              key: controller.resource.health.persist\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CONTROLLER_SHARDING_ALGORITHM\n          valueFrom:\n            configMapKeyRef:\n              key: controller.sharding.algorithm\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_KUBECTL_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.kubectl.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              key: controller.k8sclient.retry.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              key: controller.k8sclient.retry.base.backoff\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SERVER_SIDE_DIFF\n          valueFrom:\n            configMapKeyRef:\n              key: controller.diff.server.side\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_IGNORE_NORMALIZER_JQ_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.ignore.normalizer.jq.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: hydrator.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_BATCH_EVENTS_PROCESSING\n          valueFrom:\n            configMapKeyRef:\n              key: controller.cluster.cache.batch.events.processing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_EVENTS_PROCESSING_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.cluster.cache.events.processing.interval\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: KUBECACHEDIR\n          value: /tmp/kubecache\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: argocd-application-controller\n        ports:\n        - containerPort: 8082\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8082\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        volumeMounts:\n        - mountPath: /app/config/controller/tls\n          name: argocd-repo-server-tls\n        - mountPath: /home/argocd\n          name: argocd-home\n        - mountPath: /home/argocd/params\n          name: argocd-cmd-params-cm\n        - mountPath: /tmp\n          name: argocd-application-controller-tmp\n        workingDir: /home/argocd\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-application-controller\n      volumes:\n      - emptyDir: {}\n        name: argocd-home\n      - emptyDir: {}\n        name: argocd-application-controller-tmp\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - configMap:\n          items:\n          - key: controller.profile.enabled\n            path: profiler.enabled\n          name: argocd-cmd-params-cm\n          optional: true\n        name: argocd-cmd-params-cm\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7n93jtmh.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) The container \"argocd-application-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7n93jtmh.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7n93jtmh.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) serviceAccount \"argocd-application-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7n93jtmh.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7n93jtmh.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7n93jtmh.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/name: argocd-redis-ha\n    app.kubernetes.io/part-of: argocd\n  name: argocd-redis-ha-server\nspec:\n  podManagementPolicy: OrderedReady\n  replicas: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis-ha\n  serviceName: argocd-redis-ha\n  template:\n    metadata:\n      annotations:\n        checksum/init-config: bd30e83dfdad9912b6c1cc32a8c26d7d01429a0730f5ee7af380fb593e874d54\n      labels:\n        app.kubernetes.io/name: argocd-redis-ha\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-redis-ha\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: false\n      containers:\n      - args:\n        - /data/conf/redis.conf\n        command:\n        - redis-server\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle:\n          preStop:\n            exec:\n              command:\n              - /bin/sh\n              - /readonly-config/trigger-failover-if-master.sh\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        name: redis\n        ports:\n        - containerPort: 6379\n          name: redis\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        startupProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 15\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n      - args:\n        - /data/conf/sentinel.conf\n        command:\n        - redis-sentinel\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - /bin/sh\n              - -c\n              - sleep 30; redis-cli -p 26379 sentinel reset argocd\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        name: sentinel\n        ports:\n        - containerPort: 26379\n          name: sentinel\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 3\n          timeoutSeconds: 15\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        startupProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 15\n        volumeMounts:\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n      - args:\n        - /readonly-config/fix-split-brain.sh\n        command:\n        - sh\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        name: split-brain-fix\n        resources: {}\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      initContainers:\n      - args:\n        - /readonly-config/init.sh\n        command:\n        - sh\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        name: config-init\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      securityContext:\n        fsGroup: 1000\n        runAsNonRoot: true\n        runAsUser: 1000\n      serviceAccountName: argocd-redis-ha\n      terminationGracePeriodSeconds: 60\n      volumes:\n      - configMap:\n          name: argocd-redis-ha-configmap\n        name: config\n      - configMap:\n          defaultMode: 493\n          name: argocd-redis-ha-health-configmap\n        name: health\n      - emptyDir: {}\n        name: data\n  updateStrategy:\n    type: RollingUpdate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8raf_8ni.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) serviceAccount \"argocd-redis-ha\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8raf_8ni.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8raf_8ni.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8raf_8ni.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8raf_8ni.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8raf_8ni.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8raf_8ni.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8raf_8ni.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8raf_8ni.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8raf_8ni.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8raf_8ni.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 11 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/name: argocd-redis-ha\n    app.kubernetes.io/part-of: argocd\n  name: argocd-redis-ha-server\nspec:\n  podManagementPolicy: OrderedReady\n  replicas: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis-ha\n  serviceName: argocd-redis-ha\n  template:\n    metadata:\n      annotations:\n        checksum/init-config: bd30e83dfdad9912b6c1cc32a8c26d7d01429a0730f5ee7af380fb593e874d54\n      labels:\n        app.kubernetes.io/name: argocd-redis-ha\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-redis-ha\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: false\n      containers:\n      - args:\n        - /data/conf/redis.conf\n        command:\n        - redis-server\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle:\n          preStop:\n            exec:\n              command:\n              - /bin/sh\n              - /readonly-config/trigger-failover-if-master.sh\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        name: redis\n        ports:\n        - containerPort: 6379\n          name: redis\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        startupProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 15\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n      - args:\n        - /data/conf/sentinel.conf\n        command:\n        - redis-sentinel\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - /bin/sh\n              - -c\n              - sleep 30; redis-cli -p 26379 sentinel reset argocd\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        name: sentinel\n        ports:\n        - containerPort: 26379\n          name: sentinel\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 3\n          timeoutSeconds: 15\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        startupProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 15\n        volumeMounts:\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n      - args:\n        - /readonly-config/fix-split-brain.sh\n        command:\n        - sh\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        name: split-brain-fix\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      initContainers:\n      - args:\n        - /readonly-config/init.sh\n        command:\n        - sh\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        name: config-init\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      securityContext:\n        fsGroup: 1000\n        runAsNonRoot: true\n        runAsUser: 1000\n      serviceAccountName: argocd-redis-ha\n      terminationGracePeriodSeconds: 60\n      volumes:\n      - configMap:\n          name: argocd-redis-ha-configmap\n        name: config\n      - configMap:\n          defaultMode: 493\n          name: argocd-redis-ha-health-configmap\n        name: health\n      - emptyDir: {}\n        name: data\n  updateStrategy:\n    type: RollingUpdate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw7vhoina.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) serviceAccount \"argocd-redis-ha\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw7vhoina.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw7vhoina.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw7vhoina.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw7vhoina.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw7vhoina.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw7vhoina.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw7vhoina.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw7vhoina.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 9 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/name: argocd-redis-ha\n    app.kubernetes.io/part-of: argocd\n  name: argocd-redis-ha-server\nspec:\n  podManagementPolicy: OrderedReady\n  replicas: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis-ha\n  serviceName: argocd-redis-ha\n  template:\n    metadata:\n      annotations:\n        checksum/init-config: bd30e83dfdad9912b6c1cc32a8c26d7d01429a0730f5ee7af380fb593e874d54\n      labels:\n        app.kubernetes.io/name: argocd-redis-ha\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-redis-ha\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: false\n      containers:\n      - args:\n        - /data/conf/redis.conf\n        command:\n        - redis-server\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle:\n          preStop:\n            exec:\n              command:\n              - /bin/sh\n              - /readonly-config/trigger-failover-if-master.sh\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        name: redis\n        ports:\n        - containerPort: 6379\n          name: redis\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        startupProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 15\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-y0aggt\n      - args:\n        - /data/conf/sentinel.conf\n        command:\n        - redis-sentinel\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - /bin/sh\n              - -c\n              - sleep 30; redis-cli -p 26379 sentinel reset argocd\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        name: sentinel\n        ports:\n        - containerPort: 26379\n          name: sentinel\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 3\n          timeoutSeconds: 15\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        startupProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 15\n        volumeMounts:\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n      - args:\n        - /readonly-config/fix-split-brain.sh\n        command:\n        - sh\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        name: split-brain-fix\n        resources: {}\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      initContainers:\n      - args:\n        - /readonly-config/init.sh\n        command:\n        - sh\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        name: config-init\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      securityContext:\n        fsGroup: 1000\n        runAsNonRoot: true\n        runAsUser: 1000\n      serviceAccountName: argocd-redis-ha\n      terminationGracePeriodSeconds: 60\n      volumes:\n      - configMap:\n          name: argocd-redis-ha-configmap\n        name: config\n      - configMap:\n          defaultMode: 493\n          name: argocd-redis-ha-health-configmap\n        name: health\n      - emptyDir: {}\n        name: data\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-ejq17j\n          type: DirectoryOrCreate\n  updateStrategy:\n    type: RollingUpdate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv8xgnv6t.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) serviceAccount \"argocd-redis-ha\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv8xgnv6t.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv8xgnv6t.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv8xgnv6t.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv8xgnv6t.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv8xgnv6t.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv8xgnv6t.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv8xgnv6t.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv8xgnv6t.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 9 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/name: argocd-redis-ha\n    app.kubernetes.io/part-of: argocd\n  name: argocd-redis-ha-server\nspec:\n  podManagementPolicy: OrderedReady\n  replicas: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis-ha\n  serviceName: argocd-redis-ha\n  template:\n    metadata:\n      annotations:\n        checksum/init-config: bd30e83dfdad9912b6c1cc32a8c26d7d01429a0730f5ee7af380fb593e874d54\n      labels:\n        app.kubernetes.io/name: argocd-redis-ha\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-redis-ha\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: false\n      containers:\n      - args:\n        - /data/conf/redis.conf\n        command:\n        - redis-server\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle:\n          preStop:\n            exec:\n              command:\n              - /bin/sh\n              - /readonly-config/trigger-failover-if-master.sh\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        name: redis\n        ports:\n        - containerPort: 6379\n          name: redis\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        startupProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 15\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n      - args:\n        - /data/conf/sentinel.conf\n        command:\n        - redis-sentinel\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - /bin/sh\n              - -c\n              - sleep 30; redis-cli -p 26379 sentinel reset argocd\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        name: sentinel\n        ports:\n        - containerPort: 26379\n          name: sentinel\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 3\n          timeoutSeconds: 15\n        startupProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 15\n        volumeMounts:\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n      - args:\n        - /readonly-config/fix-split-brain.sh\n        command:\n        - sh\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        name: split-brain-fix\n        resources: {}\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      initContainers:\n      - args:\n        - /readonly-config/init.sh\n        command:\n        - sh\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        name: config-init\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      serviceAccountName: argocd-redis-ha\n      terminationGracePeriodSeconds: 60\n      volumes:\n      - configMap:\n          name: argocd-redis-ha-configmap\n        name: config\n      - configMap:\n          defaultMode: 493\n          name: argocd-redis-ha-health-configmap\n        name: health\n      - emptyDir: {}\n        name: data\n  updateStrategy:\n    type: RollingUpdate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcbxqtp1q.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcbxqtp1q.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcbxqtp1q.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcbxqtp1q.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcbxqtp1q.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) serviceAccount \"argocd-redis-ha\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcbxqtp1q.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcbxqtp1q.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcbxqtp1q.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcbxqtp1q.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcbxqtp1q.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcbxqtp1q.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcbxqtp1q.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcbxqtp1q.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcbxqtp1q.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcbxqtp1q.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcbxqtp1q.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcbxqtp1q.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 17 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/nfs/nfs-busybox-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nfs-busybox\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: nfs-busybox\n  template:\n    metadata:\n      labels:\n        name: nfs-busybox\n    spec:\n      containers:\n      - image: busybox\n        command:\n        - sh\n        - -c\n        - while true; do date > /mnt/index.html; hostname >> /mnt/index.html; sleep\n          $(($RANDOM % 5 + 5)); done\n        imagePullPolicy: IfNotPresent\n        name: busybox\n        volumeMounts:\n        - name: nfs\n          mountPath: /mnt\n        securityContext:\n          privileged: true\n      volumes:\n      - name: nfs\n        persistentVolumeClaim:\n          claimName: nfs\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5j3ndedt.yaml: (object: <no namespace>/nfs-busybox apps/v1, Kind=Deployment) The container \"busybox\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5j3ndedt.yaml: (object: <no namespace>/nfs-busybox apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5j3ndedt.yaml: (object: <no namespace>/nfs-busybox apps/v1, Kind=Deployment) container \"busybox\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5j3ndedt.yaml: (object: <no namespace>/nfs-busybox apps/v1, Kind=Deployment) container \"busybox\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5j3ndedt.yaml: (object: <no namespace>/nfs-busybox apps/v1, Kind=Deployment) container \"busybox\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5j3ndedt.yaml: (object: <no namespace>/nfs-busybox apps/v1, Kind=Deployment) container \"busybox\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5j3ndedt.yaml: (object: <no namespace>/nfs-busybox apps/v1, Kind=Deployment) container \"busybox\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5j3ndedt.yaml: (object: <no namespace>/nfs-busybox apps/v1, Kind=Deployment) container \"busybox\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/nfs/nfs-busybox-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nfs-busybox\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: nfs-busybox\n  template:\n    metadata:\n      labels:\n        name: nfs-busybox\n    spec:\n      containers:\n      - image: busybox\n        command:\n        - sh\n        - -c\n        - while true; do date > /mnt/index.html; hostname >> /mnt/index.html; sleep\n          $(($RANDOM % 5 + 5)); done\n        imagePullPolicy: IfNotPresent\n        name: busybox\n        volumeMounts:\n        - name: nfs\n          mountPath: /mnt\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-nabwqb\n      volumes:\n      - name: nfs\n        persistentVolumeClaim:\n          claimName: nfs\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-6dgm0s\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvd8jdy0x.yaml: (object: <no namespace>/nfs-busybox apps/v1, Kind=Deployment) The container \"busybox\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvd8jdy0x.yaml: (object: <no namespace>/nfs-busybox apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvd8jdy0x.yaml: (object: <no namespace>/nfs-busybox apps/v1, Kind=Deployment) container \"busybox\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvd8jdy0x.yaml: (object: <no namespace>/nfs-busybox apps/v1, Kind=Deployment) container \"busybox\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvd8jdy0x.yaml: (object: <no namespace>/nfs-busybox apps/v1, Kind=Deployment) container \"busybox\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvd8jdy0x.yaml: (object: <no namespace>/nfs-busybox apps/v1, Kind=Deployment) container \"busybox\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/base/controller-deployment/argocd-server-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: argocd-server\nspec:\n  replicas: 2\n  template:\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-server\n            topologyKey: kubernetes.io/hostname\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-server\n              topologyKey: topology.kubernetes.io/zone\n      containers:\n      - name: argocd-server\n        env:\n        - name: ARGOCD_API_SERVER_REPLICAS\n          value: '2'\n        args:\n        - /usr/local/bin/argocd-server\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1cw84fpb.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) The container \"argocd-server\" is using an invalid container image, \"\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1cw84fpb.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) object has no selector specified (check: mismatching-selector, remediation: Confirm that your deployment selector correctly matches the labels in its pod template.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1cw84fpb.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) anti-affinity's topology key does not match \"topology.kubernetes.io/zone\" (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1cw84fpb.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) pod's labels \"\" do not match with anti-affinity's labels \"app.kubernetes.io/name=argocd-server\" (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1cw84fpb.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1cw84fpb.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1cw84fpb.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1cw84fpb.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1cw84fpb.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1cw84fpb.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 10 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/base/controller-deployment/argocd-server-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: argocd-server\nspec:\n  replicas: 2\n  template:\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-server\n            topologyKey: kubernetes.io/hostname\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-server\n              topologyKey: topology.kubernetes.io/zone\n      containers:\n      - name: argocd-server\n        env:\n        - name: ARGOCD_API_SERVER_REPLICAS\n          value: '2'\n        args:\n        - /usr/local/bin/argocd-server\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-k69jkr\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-riuhk1\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvzhvvhov.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) The container \"argocd-server\" is using an invalid container image, \"\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvzhvvhov.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) object has no selector specified (check: mismatching-selector, remediation: Confirm that your deployment selector correctly matches the labels in its pod template.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvzhvvhov.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) anti-affinity's topology key does not match \"topology.kubernetes.io/zone\" (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvzhvvhov.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) pod's labels \"\" do not match with anti-affinity's labels \"app.kubernetes.io/name=argocd-server\" (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvzhvvhov.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvzhvvhov.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvzhvvhov.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvzhvvhov.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/nodesjs-mongodb/web-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: web\n  name: web-controller\nspec:\n  replicas: 2\n  selector:\n    name: web\n  template:\n    metadata:\n      labels:\n        name: web\n    spec:\n      containers:\n      - image: <YOUR-CONTAINER>\n        name: web\n        ports:\n        - containerPort: 3000\n          name: http-server\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3_5qhasq.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) The container \"web\" is using an invalid container image, \"<YOUR-CONTAINER>\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3_5qhasq.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3_5qhasq.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3_5qhasq.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3_5qhasq.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3_5qhasq.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3_5qhasq.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3_5qhasq.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/nodesjs-mongodb/web-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: web\n  name: web-controller\nspec:\n  replicas: 2\n  selector:\n    name: web\n  template:\n    metadata:\n      labels:\n        name: web\n    spec:\n      containers:\n      - image: <YOUR-CONTAINER>\n        name: web\n        ports:\n        - containerPort: 3000\n          name: http-server\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-lqml2i\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-sqwv86\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpy7y7jq5h.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) The container \"web\" is using an invalid container image, \"<YOUR-CONTAINER>\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpy7y7jq5h.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpy7y7jq5h.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpy7y7jq5h.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpy7y7jq5h.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpy7y7jq5h.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/volumes/rbd/rbd.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: rbd\nspec:\n  containers:\n  - image: kubernetes/pause\n    name: rbd-rw\n    volumeMounts:\n    - name: rbdpd\n      mountPath: /mnt/rbd\n    securityContext:\n      privileged: true\n  volumes:\n  - name: rbdpd\n    rbd:\n      monitors:\n      - 10.16.154.78:6789\n      - 10.16.154.82:6789\n      - 10.16.154.83:6789\n      pool: kube\n      image: foo\n      fsType: ext4\n      readOnly: true\n      user: admin\n      keyring: /etc/ceph/keyring\n      imageformat: '2'\n      imagefeatures: layering\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0a_o2xs1.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) The container \"rbd-rw\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0a_o2xs1.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0a_o2xs1.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0a_o2xs1.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0a_o2xs1.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0a_o2xs1.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0a_o2xs1.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/volumes/rbd/rbd.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: rbd\nspec:\n  containers:\n  - image: kubernetes/pause\n    name: rbd-rw\n    volumeMounts:\n    - name: rbdpd\n      mountPath: /mnt/rbd\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-smz54q\n  volumes:\n  - name: rbdpd\n    rbd:\n      monitors:\n      - 10.16.154.78:6789\n      - 10.16.154.82:6789\n      - 10.16.154.83:6789\n      pool: kube\n      image: foo\n      fsType: ext4\n      readOnly: true\n      user: admin\n      keyring: /etc/ceph/keyring\n      imageformat: '2'\n      imagefeatures: layering\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-nlkxup\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi1x6ygdv.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) The container \"rbd-rw\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi1x6ygdv.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi1x6ygdv.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi1x6ygdv.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi1x6ygdv.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/rethinkdb/rc.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    db: rethinkdb\n  name: rethinkdb-rc\nspec:\n  replicas: 1\n  selector:\n    db: rethinkdb\n    role: replicas\n  template:\n    metadata:\n      labels:\n        db: rethinkdb\n        role: replicas\n    spec:\n      containers:\n      - image: registry.k8s.io/rethinkdb:1.16.0_1\n        name: rethinkdb\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 8080\n          name: admin-port\n        - containerPort: 28015\n          name: driver-port\n        - containerPort: 29015\n          name: cluster-port\n        volumeMounts:\n        - mountPath: /data/rethinkdb_data\n          name: rethinkdb-storage\n        securityContext:\n          privileged: true\n      volumes:\n      - name: rethinkdb-storage\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx0eoj45b.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx0eoj45b.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx0eoj45b.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx0eoj45b.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx0eoj45b.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx0eoj45b.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/rethinkdb/rc.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    db: rethinkdb\n  name: rethinkdb-rc\nspec:\n  replicas: 1\n  selector:\n    db: rethinkdb\n    role: replicas\n  template:\n    metadata:\n      labels:\n        db: rethinkdb\n        role: replicas\n    spec:\n      containers:\n      - image: registry.k8s.io/rethinkdb:1.16.0_1\n        name: rethinkdb\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 8080\n          name: admin-port\n        - containerPort: 28015\n          name: driver-port\n        - containerPort: 29015\n          name: cluster-port\n        volumeMounts:\n        - mountPath: /data/rethinkdb_data\n          name: rethinkdb-storage\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-31wljk\n      volumes:\n      - name: rethinkdb-storage\n        emptyDir: {}\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-a9r2sk\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr9y4ec2c.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr9y4ec2c.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr9y4ec2c.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr9y4ec2c.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/vsphere/vsphere-volume-pvcscpod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pvpod\nspec:\n  containers:\n  - name: test-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - name: test-volume\n      mountPath: /test-vmdk\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test-volume\n    persistentVolumeClaim:\n      claimName: pvcsc001\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpceklwf5x.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpceklwf5x.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpceklwf5x.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpceklwf5x.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpceklwf5x.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpceklwf5x.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpceklwf5x.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/vsphere/vsphere-volume-pvcscpod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pvpod\nspec:\n  containers:\n  - name: test-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - name: test-volume\n      mountPath: /test-vmdk\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-auupba\n  volumes:\n  - name: test-volume\n    persistentVolumeClaim:\n      claimName: pvcsc001\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-0xp1s8\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5uieiuar.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5uieiuar.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5uieiuar.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5uieiuar.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5uieiuar.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook-go/redis-master-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: redis-master\n  labels:\n    app: redis\n    role: master\nspec:\n  replicas: 1\n  selector:\n    app: redis\n    role: master\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: master\n    spec:\n      containers:\n      - name: redis-master\n        image: redis\n        ports:\n        - name: redis-server\n          containerPort: 6379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp25s4nunr.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) The container \"redis-master\" is using an invalid container image, \"redis\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp25s4nunr.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp25s4nunr.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp25s4nunr.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp25s4nunr.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp25s4nunr.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp25s4nunr.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook-go/redis-master-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: redis-master\n  labels:\n    app: redis\n    role: master\nspec:\n  replicas: 1\n  selector:\n    app: redis\n    role: master\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: master\n    spec:\n      containers:\n      - name: redis-master\n        image: redis\n        ports:\n        - name: redis-server\n          containerPort: 6379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-ay1dbz\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-alvo5q\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe_5ymk8j.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) The container \"redis-master\" is using an invalid container image, \"redis\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe_5ymk8j.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe_5ymk8j.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe_5ymk8j.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe_5ymk8j.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/vsphere/vsphere-volume-pvcscvsanpod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pvpod\nspec:\n  containers:\n  - name: test-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - name: test-volume\n      mountPath: /test\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test-volume\n    persistentVolumeClaim:\n      claimName: pvcsc-vsan\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp99lnpecc.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp99lnpecc.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp99lnpecc.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp99lnpecc.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp99lnpecc.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp99lnpecc.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp99lnpecc.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/vsphere/vsphere-volume-pvcscvsanpod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pvpod\nspec:\n  containers:\n  - name: test-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - name: test-volume\n      mountPath: /test\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-dggk1x\n  volumes:\n  - name: test-volume\n    persistentVolumeClaim:\n      claimName: pvcsc-vsan\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-3idpms\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgcopknwp.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgcopknwp.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgcopknwp.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgcopknwp.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgcopknwp.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/azure_disk/claim/blob-based-disk/account-specified-hdd/pod-uses-account-hdd.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-uses-account-hdd-5g\n  labels:\n    name: storage\nspec:\n  containers:\n  - image: nginx\n    name: az-c-01\n    command:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> /mnt/blobdisk/outfile; sleep 1; done\n    volumeMounts:\n    - name: blobdisk01\n      mountPath: /mnt/blobdisk\n    securityContext:\n      privileged: true\n  volumes:\n  - name: blobdisk01\n    persistentVolumeClaim:\n      claimName: pv-dd-account-hdd-5g\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkyjgeb6g.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) The container \"az-c-01\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkyjgeb6g.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkyjgeb6g.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkyjgeb6g.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkyjgeb6g.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkyjgeb6g.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkyjgeb6g.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/azure_disk/claim/blob-based-disk/account-specified-hdd/pod-uses-account-hdd.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-uses-account-hdd-5g\n  labels:\n    name: storage\nspec:\n  containers:\n  - image: nginx\n    name: az-c-01\n    command:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> /mnt/blobdisk/outfile; sleep 1; done\n    volumeMounts:\n    - name: blobdisk01\n      mountPath: /mnt/blobdisk\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-6zvdnu\n  volumes:\n  - name: blobdisk01\n    persistentVolumeClaim:\n      claimName: pv-dd-account-hdd-5g\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-orryio\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_5_7q1qh.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) The container \"az-c-01\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_5_7q1qh.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_5_7q1qh.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_5_7q1qh.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_5_7q1qh.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/azure_disk/static-provisioning/managed-disk/pod-uses-existing-managed-disk.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-uses-managed-ssd-5g\n  labels:\n    name: storage\nspec:\n  containers:\n  - image: nginx\n    name: az-c-01\n    command:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> /mnt/managed/outfile; sleep 1; done\n    volumeMounts:\n    - name: managed01\n      mountPath: /mnt/managed\n    securityContext:\n      privileged: true\n  volumes:\n  - name: managed01\n    azureDisk:\n      kind: Managed\n      diskName: myDisk\n      diskURI: /subscriptions/<subscriptionID>/resourceGroups/<resourceGroup>/providers/Microsoft.Compute/disks/<diskName>\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk7i95wra.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) The container \"az-c-01\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk7i95wra.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk7i95wra.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk7i95wra.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk7i95wra.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk7i95wra.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk7i95wra.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/azure_disk/static-provisioning/managed-disk/pod-uses-existing-managed-disk.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-uses-managed-ssd-5g\n  labels:\n    name: storage\nspec:\n  containers:\n  - image: nginx\n    name: az-c-01\n    command:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> /mnt/managed/outfile; sleep 1; done\n    volumeMounts:\n    - name: managed01\n      mountPath: /mnt/managed\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-dgbt18\n  volumes:\n  - name: managed01\n    azureDisk:\n      kind: Managed\n      diskName: myDisk\n      diskURI: /subscriptions/<subscriptionID>/resourceGroups/<resourceGroup>/providers/Microsoft.Compute/disks/<diskName>\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-07xqo4\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp64coeps6.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) The container \"az-c-01\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp64coeps6.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp64coeps6.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp64coeps6.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp64coeps6.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/selenium/selenium-hub-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: selenium-hub\n  labels:\n    app: selenium-hub\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: selenium-hub\n  template:\n    metadata:\n      labels:\n        app: selenium-hub\n    spec:\n      containers:\n      - name: selenium-hub\n        image: selenium/hub:4.0\n        ports:\n        - containerPort: 4444\n        - containerPort: 4443\n        - containerPort: 4442\n        resources:\n          limits:\n            memory: 1000Mi\n            cpu: '.5'\n        livenessProbe:\n          httpGet:\n            path: /wd/hub/status\n            port: 4444\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /wd/hub/status\n            port: 4444\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprqmb6p4_.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprqmb6p4_.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprqmb6p4_.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprqmb6p4_.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprqmb6p4_.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/selenium/selenium-hub-deployment.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: selenium-hub\n  labels:\n    app: selenium-hub\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: selenium-hub\n  template:\n    metadata:\n      labels:\n        app: selenium-hub\n    spec:\n      containers:\n      - name: selenium-hub\n        image: selenium/hub:4.0\n        ports:\n        - containerPort: 4444\n        - containerPort: 4443\n        - containerPort: 4442\n        livenessProbe:\n          httpGet:\n            path: /wd/hub/status\n            port: 4444\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /wd/hub/status\n            port: 4444\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkqskhs54.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkqskhs54.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkqskhs54.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkqskhs54.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/selenium/selenium-hub-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: selenium-hub\n  labels:\n    app: selenium-hub\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: selenium-hub\n  template:\n    metadata:\n      labels:\n        app: selenium-hub\n    spec:\n      containers:\n      - name: selenium-hub\n        image: selenium/hub:4.0\n        ports:\n        - containerPort: 4444\n        - containerPort: 4443\n        - containerPort: 4442\n        resources:\n          limits:\n            memory: 1000Mi\n            cpu: '.5'\n        livenessProbe:\n          httpGet:\n            path: /wd/hub/status\n            port: 4444\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /wd/hub/status\n            port: 4444\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-0r0xm7\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-t4510a\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa47tsxfb.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa47tsxfb.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa47tsxfb.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/elasticsearch/es-rc.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es\n  labels:\n    component: elasticsearch\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n    spec:\n      serviceAccount: elasticsearch\n      initContainers:\n      - name: init-sysctl\n        image: busybox\n        imagePullPolicy: IfNotPresent\n        command:\n        - sysctl\n        - -w\n        - vm.max_map_count=262144\n        securityContext:\n          privileged: true\n      containers:\n      - name: es\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n          privileged: true\n        image: quay.io/pires/docker-elasticsearch-kubernetes:5.6.2\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: myesdb\n        - name: DISCOVERY_SERVICE\n          value: elasticsearch\n        - name: NODE_MASTER\n          value: 'true'\n        - name: NODE_DATA\n          value: 'true'\n        - name: HTTP_ENABLE\n          value: 'true'\n        ports:\n        - containerPort: 9200\n          name: http\n          protocol: TCP\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n      volumes:\n      - name: storage\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcs178e0v.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) serviceAccount is specified (elasticsearch), but this field is deprecated; use serviceAccountName instead (check: deprecated-service-account-field, remediation: Use the serviceAccountName field instead. If you must specify serviceAccount, ensure values for serviceAccount and serviceAccountName match.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcs178e0v.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcs178e0v.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) The container \"init-sysctl\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcs178e0v.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcs178e0v.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcs178e0v.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) serviceAccount \"elasticsearch\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcs178e0v.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcs178e0v.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcs178e0v.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcs178e0v.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcs178e0v.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcs178e0v.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcs178e0v.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcs178e0v.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcs178e0v.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcs178e0v.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 16 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/elasticsearch/es-rc.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es\n  labels:\n    component: elasticsearch\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n    spec:\n      serviceAccount: elasticsearch\n      initContainers:\n      - name: init-sysctl\n        image: busybox\n        imagePullPolicy: IfNotPresent\n        command:\n        - sysctl\n        - -w\n        - vm.max_map_count=262144\n        securityContext:\n          privileged: true\n      containers:\n      - name: es\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n        image: quay.io/pires/docker-elasticsearch-kubernetes:5.6.2\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: myesdb\n        - name: DISCOVERY_SERVICE\n          value: elasticsearch\n        - name: NODE_MASTER\n          value: 'true'\n        - name: NODE_DATA\n          value: 'true'\n        - name: HTTP_ENABLE\n          value: 'true'\n        ports:\n        - containerPort: 9200\n          name: http\n          protocol: TCP\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-2qqgm8\n      volumes:\n      - name: storage\n        emptyDir: {}\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-d7dgfb\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpami5unuz.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) serviceAccount is specified (elasticsearch), but this field is deprecated; use serviceAccountName instead (check: deprecated-service-account-field, remediation: Use the serviceAccountName field instead. If you must specify serviceAccount, ensure values for serviceAccount and serviceAccountName match.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpami5unuz.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpami5unuz.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) The container \"init-sysctl\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpami5unuz.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpami5unuz.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpami5unuz.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) serviceAccount \"elasticsearch\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpami5unuz.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpami5unuz.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpami5unuz.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpami5unuz.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpami5unuz.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpami5unuz.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpami5unuz.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpami5unuz.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 14 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/elasticsearch/es-rc.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es\n  labels:\n    component: elasticsearch\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n    spec:\n      serviceAccount: elasticsearch\n      initContainers:\n      - name: init-sysctl\n        image: busybox\n        imagePullPolicy: IfNotPresent\n        command:\n        - sysctl\n        - -w\n        - vm.max_map_count=262144\n      containers:\n      - name: es\n        image: quay.io/pires/docker-elasticsearch-kubernetes:5.6.2\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: myesdb\n        - name: DISCOVERY_SERVICE\n          value: elasticsearch\n        - name: NODE_MASTER\n          value: 'true'\n        - name: NODE_DATA\n          value: 'true'\n        - name: HTTP_ENABLE\n          value: 'true'\n        ports:\n        - containerPort: 9200\n          name: http\n          protocol: TCP\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n      volumes:\n      - name: storage\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplr7kmpul.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) serviceAccount is specified (elasticsearch), but this field is deprecated; use serviceAccountName instead (check: deprecated-service-account-field, remediation: Use the serviceAccountName field instead. If you must specify serviceAccount, ensure values for serviceAccount and serviceAccountName match.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplr7kmpul.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) The container \"init-sysctl\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplr7kmpul.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplr7kmpul.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplr7kmpul.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) serviceAccount \"elasticsearch\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplr7kmpul.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplr7kmpul.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplr7kmpul.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplr7kmpul.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplr7kmpul.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplr7kmpul.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 11 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/vsphere/vsphere-volume-pvcscvsanpod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pvpod\nspec:\n  containers:\n  - name: test-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - name: test-volume\n      mountPath: /test\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test-volume\n    persistentVolumeClaim:\n      claimName: pvcsc-vsan\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv5zlq4l5.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv5zlq4l5.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv5zlq4l5.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv5zlq4l5.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv5zlq4l5.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv5zlq4l5.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv5zlq4l5.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/vsphere/vsphere-volume-pvcscvsanpod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pvpod\nspec:\n  containers:\n  - name: test-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - name: test-volume\n      mountPath: /test\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-m7ubiq\n  volumes:\n  - name: test-volume\n    persistentVolumeClaim:\n      claimName: pvcsc-vsan\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-9jvaqe\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd1p_fcvo.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd1p_fcvo.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd1p_fcvo.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd1p_fcvo.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd1p_fcvo.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/nodesjs-mongodb/mongo-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: mongo\n  name: mongo-controller\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: mongo\n    spec:\n      containers:\n      - image: mongo\n        name: mongo\n        ports:\n        - name: mongo\n          containerPort: 27017\n          hostPort: 27017\n        volumeMounts:\n        - name: mongo-persistent-storage\n          mountPath: /data/db\n        securityContext:\n          privileged: true\n      volumes:\n      - name: mongo-persistent-storage\n        gcePersistentDisk:\n          pdName: mongo-disk\n          fsType: ext4\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqp5cendi.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) The container \"mongo\" is using an invalid container image, \"mongo\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqp5cendi.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqp5cendi.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqp5cendi.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqp5cendi.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqp5cendi.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqp5cendi.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/nodesjs-mongodb/mongo-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: mongo\n  name: mongo-controller\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: mongo\n    spec:\n      containers:\n      - image: mongo\n        name: mongo\n        ports:\n        - name: mongo\n          containerPort: 27017\n          hostPort: 27017\n        volumeMounts:\n        - name: mongo-persistent-storage\n          mountPath: /data/db\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-k5pkr7\n      volumes:\n      - name: mongo-persistent-storage\n        gcePersistentDisk:\n          pdName: mongo-disk\n          fsType: ext4\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-6f4yh6\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp74znsc3p.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) The container \"mongo\" is using an invalid container image, \"mongo\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp74znsc3p.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp74znsc3p.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp74znsc3p.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp74znsc3p.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/javaweb-tomcat-sidecar/javaweb-2.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: javaweb-2\nspec:\n  initContainers:\n  - image: resouer/sample:v2\n    name: war\n    command:\n    - cp\n    - /sample.war\n    - /app\n    volumeMounts:\n    - mountPath: /app\n      name: app-volume\n  containers:\n  - image: resouer/mytomcat:7.0\n    name: tomcat\n    command:\n    - sh\n    - -c\n    - /root/apache-tomcat-7.0.42-v2/bin/start.sh\n    volumeMounts:\n    - mountPath: /root/apache-tomcat-7.0.42-v2/webapps\n      name: app-volume\n    ports:\n    - containerPort: 8080\n      hostPort: 8001\n    securityContext:\n      privileged: true\n  volumes:\n  - name: app-volume\n    emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpttso_76k.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"war\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpttso_76k.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpttso_76k.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpttso_76k.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpttso_76k.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"war\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpttso_76k.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpttso_76k.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"war\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpttso_76k.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpttso_76k.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"war\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpttso_76k.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 10 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/javaweb-tomcat-sidecar/javaweb-2.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: javaweb-2\nspec:\n  initContainers:\n  - image: resouer/sample:v2\n    name: war\n    command:\n    - cp\n    - /sample.war\n    - /app\n    volumeMounts:\n    - mountPath: /app\n      name: app-volume\n  containers:\n  - image: resouer/mytomcat:7.0\n    name: tomcat\n    command:\n    - sh\n    - -c\n    - /root/apache-tomcat-7.0.42-v2/bin/start.sh\n    volumeMounts:\n    - mountPath: /root/apache-tomcat-7.0.42-v2/webapps\n      name: app-volume\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-3tojd9\n    ports:\n    - containerPort: 8080\n      hostPort: 8001\n  volumes:\n  - name: app-volume\n    emptyDir: {}\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-n2gu5m\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeyd0fqs_.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"war\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeyd0fqs_.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeyd0fqs_.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"war\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeyd0fqs_.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeyd0fqs_.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"war\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeyd0fqs_.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeyd0fqs_.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"war\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpeyd0fqs_.yaml: (object: <no namespace>/javaweb-2 /v1, Kind=Pod) container \"tomcat\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cpu-manager/exclusive-4.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-4\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-4\n    resources:\n      requests:\n        cpu: 4\n        memory: 256M\n      limits:\n        cpu: 4\n        memory: 256M\n    securityContext:\n      privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz60fwobq.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) The container \"exclusive-4\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz60fwobq.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) container \"exclusive-4\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz60fwobq.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) container \"exclusive-4\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz60fwobq.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) container \"exclusive-4\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz60fwobq.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) container \"exclusive-4\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cpu-manager/exclusive-4.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-4\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-4\n    resources:\n      requests:\n        cpu: 4\n        memory: 256M\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdbvc2nw3.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) The container \"exclusive-4\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdbvc2nw3.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) container \"exclusive-4\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdbvc2nw3.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) container \"exclusive-4\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdbvc2nw3.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) container \"exclusive-4\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cpu-manager/exclusive-4.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-4\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-4\n    resources:\n      requests:\n        cpu: 4\n        memory: 256M\n      limits:\n        cpu: 4\n        memory: 256M\n    volumeMounts:\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-g1w3wv\n  volumes:\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-ymv7ox\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcof_5hsb.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) The container \"exclusive-4\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcof_5hsb.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) container \"exclusive-4\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcof_5hsb.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) container \"exclusive-4\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/flexvolume/nginx.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  namespace: default\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - name: test\n      mountPath: /data\n    ports:\n    - containerPort: 80\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test\n    flexVolume:\n      driver: kubernetes.io/lvm\n      fsType: ext4\n      options:\n        volumeID: vol1\n        size: 1000m\n        volumegroup: kube_vg\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblp789rs.yaml: (object: default/nginx /v1, Kind=Pod) The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblp789rs.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblp789rs.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblp789rs.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblp789rs.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblp789rs.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblp789rs.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/flexvolume/nginx.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  namespace: default\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - name: test\n      mountPath: /data\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-qcev33\n    ports:\n    - containerPort: 80\n  volumes:\n  - name: test\n    flexVolume:\n      driver: kubernetes.io/lvm\n      fsType: ext4\n      options:\n        volumeID: vol1\n        size: 1000m\n        volumegroup: kube_vg\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-vrym6c\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmwr0hqqv.yaml: (object: default/nginx /v1, Kind=Pod) The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmwr0hqqv.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmwr0hqqv.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmwr0hqqv.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmwr0hqqv.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cpu-manager/exclusive-4.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-4\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-4\n    resources:\n      requests:\n        cpu: 4\n        memory: 256M\n      limits:\n        cpu: 4\n        memory: 256M\n    securityContext:\n      privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuhb8r64r.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) The container \"exclusive-4\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuhb8r64r.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) container \"exclusive-4\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuhb8r64r.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) container \"exclusive-4\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuhb8r64r.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) container \"exclusive-4\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuhb8r64r.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) container \"exclusive-4\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cpu-manager/exclusive-4.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-4\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-4\n    resources:\n      requests:\n        cpu: 4\n        memory: 256M\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpm_6kg25m.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) The container \"exclusive-4\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpm_6kg25m.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) container \"exclusive-4\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpm_6kg25m.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) container \"exclusive-4\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpm_6kg25m.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) container \"exclusive-4\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cpu-manager/exclusive-4.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-4\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-4\n    resources:\n      requests:\n        cpu: 4\n        memory: 256M\n      limits:\n        cpu: 4\n        memory: 256M\n    volumeMounts:\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-f7caim\n  volumes:\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-a5c0yt\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxc29rqzx.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) The container \"exclusive-4\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxc29rqzx.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) container \"exclusive-4\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxc29rqzx.yaml: (object: <no namespace>/exclusive-4 /v1, Kind=Pod) container \"exclusive-4\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/cinder/cinder-web.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cinder-web\nspec:\n  containers:\n  - name: web\n    image: nginx\n    ports:\n    - name: web\n      containerPort: 80\n      protocol: tcp\n    volumeMounts:\n    - name: html-volume\n      mountPath: /usr/share/nginx/html\n    securityContext:\n      privileged: true\n  volumes:\n  - name: html-volume\n    cinder:\n      volumeID: volume_ID\n      fsType: ext4\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsg7jgjlw.yaml: (object: <no namespace>/cinder-web /v1, Kind=Pod) The container \"web\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsg7jgjlw.yaml: (object: <no namespace>/cinder-web /v1, Kind=Pod) container \"web\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsg7jgjlw.yaml: (object: <no namespace>/cinder-web /v1, Kind=Pod) container \"web\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsg7jgjlw.yaml: (object: <no namespace>/cinder-web /v1, Kind=Pod) container \"web\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsg7jgjlw.yaml: (object: <no namespace>/cinder-web /v1, Kind=Pod) container \"web\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsg7jgjlw.yaml: (object: <no namespace>/cinder-web /v1, Kind=Pod) container \"web\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsg7jgjlw.yaml: (object: <no namespace>/cinder-web /v1, Kind=Pod) container \"web\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/cinder/cinder-web.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cinder-web\nspec:\n  containers:\n  - name: web\n    image: nginx\n    ports:\n    - name: web\n      containerPort: 80\n      protocol: tcp\n    volumeMounts:\n    - name: html-volume\n      mountPath: /usr/share/nginx/html\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-adoco2\n  volumes:\n  - name: html-volume\n    cinder:\n      volumeID: volume_ID\n      fsType: ext4\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-o4etv0\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_tncxbzk.yaml: (object: <no namespace>/cinder-web /v1, Kind=Pod) The container \"web\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_tncxbzk.yaml: (object: <no namespace>/cinder-web /v1, Kind=Pod) container \"web\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_tncxbzk.yaml: (object: <no namespace>/cinder-web /v1, Kind=Pod) container \"web\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_tncxbzk.yaml: (object: <no namespace>/cinder-web /v1, Kind=Pod) container \"web\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_tncxbzk.yaml: (object: <no namespace>/cinder-web /v1, Kind=Pod) container \"web\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook-go/redis-replica-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: redis-replica\n  labels:\n    app: redis\n    role: replica\nspec:\n  replicas: 2\n  selector:\n    app: redis\n    role: replica\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: replica\n    spec:\n      containers:\n      - name: redis-replica\n        image: registry.k8s.io/redis-slave:v2\n        ports:\n        - name: redis-server\n          containerPort: 6379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprua0k87h.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprua0k87h.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprua0k87h.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprua0k87h.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprua0k87h.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprua0k87h.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprua0k87h.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook-go/redis-replica-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: redis-replica\n  labels:\n    app: redis\n    role: replica\nspec:\n  replicas: 2\n  selector:\n    app: redis\n    role: replica\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: replica\n    spec:\n      containers:\n      - name: redis-replica\n        image: registry.k8s.io/redis-slave:v2\n        ports:\n        - name: redis-server\n          containerPort: 6379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-oe5gz7\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-icpp38\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi9q6_h8o.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi9q6_h8o.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi9q6_h8o.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi9q6_h8o.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi9q6_h8o.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: applicationset-controller\n    app.kubernetes.io/name: argocd-applicationset-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-applicationset-controller\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-applicationset-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-applicationset-controller\n    spec:\n      containers:\n      - args:\n        - /usr/local/bin/argocd-applicationset-controller\n        env:\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_ANNOTATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.annotations\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_LABELS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.labels\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_LEADER_ELECTION\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.leader.election\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_POLICY_OVERRIDE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.policy.override\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.debug\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DRY_RUN\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.dryrun\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_PROGRESSIVE_SYNCS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.progressive.syncs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_TOKENREF_STRICT_MODE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.tokenref.strict.mode\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_CONCURRENT_RECONCILIATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.concurrent.reconciliations.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.allowed.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.webhook.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REQUEUE_AFTER\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.requeue.after\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: argocd-applicationset-controller\n        ports:\n        - containerPort: 7000\n          name: webhook\n        - containerPort: 8080\n          name: metrics\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-applicationset-controller\n      volumes:\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - configMap:\n          name: argocd-gpg-keys-cm\n        name: gpg-keys\n      - emptyDir: {}\n        name: gpg-keyring\n      - emptyDir: {}\n        name: tmp\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7n0qx2pc.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) The container \"argocd-applicationset-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7n0qx2pc.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) serviceAccount \"argocd-applicationset-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7n0qx2pc.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7n0qx2pc.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7n0qx2pc.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7n0qx2pc.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: applicationset-controller\n    app.kubernetes.io/name: argocd-applicationset-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-applicationset-controller\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-applicationset-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-applicationset-controller\n    spec:\n      containers:\n      - args:\n        - /usr/local/bin/argocd-applicationset-controller\n        env:\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_ANNOTATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.annotations\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_LABELS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.labels\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_LEADER_ELECTION\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.leader.election\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_POLICY_OVERRIDE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.policy.override\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.debug\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DRY_RUN\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.dryrun\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_PROGRESSIVE_SYNCS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.progressive.syncs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_TOKENREF_STRICT_MODE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.tokenref.strict.mode\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_CONCURRENT_RECONCILIATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.concurrent.reconciliations.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.allowed.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.webhook.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REQUEUE_AFTER\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.requeue.after\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: argocd-applicationset-controller\n        ports:\n        - containerPort: 7000\n          name: webhook\n        - containerPort: 8080\n          name: metrics\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-v7llm4\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-applicationset-controller\n      volumes:\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - configMap:\n          name: argocd-gpg-keys-cm\n        name: gpg-keys\n      - emptyDir: {}\n        name: gpg-keyring\n      - emptyDir: {}\n        name: tmp\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-aq5mvr\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxoykf0x5.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) The container \"argocd-applicationset-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxoykf0x5.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) serviceAccount \"argocd-applicationset-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxoykf0x5.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxoykf0x5.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: applicationset-controller\n    app.kubernetes.io/name: argocd-applicationset-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-applicationset-controller\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-applicationset-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-applicationset-controller\n    spec:\n      containers:\n      - args:\n        - /usr/local/bin/argocd-applicationset-controller\n        env:\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_ANNOTATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.annotations\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_LABELS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.labels\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_LEADER_ELECTION\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.leader.election\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_POLICY_OVERRIDE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.policy.override\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.debug\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DRY_RUN\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.dryrun\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_PROGRESSIVE_SYNCS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.progressive.syncs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_TOKENREF_STRICT_MODE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.tokenref.strict.mode\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_CONCURRENT_RECONCILIATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.concurrent.reconciliations.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.allowed.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.webhook.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REQUEUE_AFTER\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.requeue.after\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: argocd-applicationset-controller\n        ports:\n        - containerPort: 7000\n          name: webhook\n        - containerPort: 8080\n          name: metrics\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-applicationset-controller\n      volumes:\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - configMap:\n          name: argocd-gpg-keys-cm\n        name: gpg-keys\n      - emptyDir: {}\n        name: gpg-keyring\n      - emptyDir: {}\n        name: tmp\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpffoz0ook.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) The container \"argocd-applicationset-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpffoz0ook.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpffoz0ook.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) serviceAccount \"argocd-applicationset-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpffoz0ook.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpffoz0ook.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpffoz0ook.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: dex-server\n    app.kubernetes.io/name: argocd-dex-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-dex-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-dex-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-dex-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - command:\n        - /shared/argocd-dex\n        - rundex\n        env:\n        - name: ARGOCD_DEX_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.disable.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        image: ghcr.io/dexidp/dex:v2.41.1\n        imagePullPolicy: Always\n        name: dex\n        ports:\n        - containerPort: 5556\n        - containerPort: 5557\n        - containerPort: 5558\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n        - mountPath: /tls\n          name: argocd-dex-server-tls\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /shared/argocd-dex\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: copyutil\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-dex-server\n      volumes:\n      - emptyDir: {}\n        name: static-files\n      - emptyDir: {}\n        name: dexconfig\n      - name: argocd-dex-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-dex-server-tls\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv92qonub.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) The container \"copyutil\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv92qonub.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) serviceAccount \"argocd-dex-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv92qonub.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv92qonub.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv92qonub.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv92qonub.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv92qonub.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv92qonub.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: dex-server\n    app.kubernetes.io/name: argocd-dex-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-dex-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-dex-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-dex-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - command:\n        - /shared/argocd-dex\n        - rundex\n        env:\n        - name: ARGOCD_DEX_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.disable.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        image: ghcr.io/dexidp/dex:v2.41.1\n        imagePullPolicy: Always\n        name: dex\n        ports:\n        - containerPort: 5556\n        - containerPort: 5557\n        - containerPort: 5558\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n        - mountPath: /tls\n          name: argocd-dex-server-tls\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-nx5cct\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /shared/argocd-dex\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: copyutil\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-dex-server\n      volumes:\n      - emptyDir: {}\n        name: static-files\n      - emptyDir: {}\n        name: dexconfig\n      - name: argocd-dex-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-dex-server-tls\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-p0mir9\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp230yj7qb.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) The container \"copyutil\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp230yj7qb.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) serviceAccount \"argocd-dex-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp230yj7qb.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp230yj7qb.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp230yj7qb.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp230yj7qb.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: dex-server\n    app.kubernetes.io/name: argocd-dex-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-dex-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-dex-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-dex-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - command:\n        - /shared/argocd-dex\n        - rundex\n        env:\n        - name: ARGOCD_DEX_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.disable.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        image: ghcr.io/dexidp/dex:v2.41.1\n        imagePullPolicy: Always\n        name: dex\n        ports:\n        - containerPort: 5556\n        - containerPort: 5557\n        - containerPort: 5558\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n        - mountPath: /tls\n          name: argocd-dex-server-tls\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /shared/argocd-dex\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: copyutil\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-dex-server\n      volumes:\n      - emptyDir: {}\n        name: static-files\n      - emptyDir: {}\n        name: dexconfig\n      - name: argocd-dex-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-dex-server-tls\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpawu83zvp.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) The container \"copyutil\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpawu83zvp.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpawu83zvp.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpawu83zvp.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) serviceAccount \"argocd-dex-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpawu83zvp.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpawu83zvp.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpawu83zvp.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpawu83zvp.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpawu83zvp.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpawu83zvp.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 10 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: notifications-controller\n    app.kubernetes.io/name: argocd-notifications-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-notifications-controller\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-notifications-controller\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-notifications-controller\n    spec:\n      containers:\n      - args:\n        - /usr/local/bin/argocd-notifications\n        env:\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_SELF_SERVICE_NOTIFICATION_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.selfservice.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          tcpSocket:\n            port: 9001\n        name: argocd-notifications-controller\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: true\n        volumeMounts:\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        workingDir: /app\n      nodeSelector:\n        kubernetes.io/os: linux\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      serviceAccountName: argocd-notifications-controller\n      volumes:\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp18xft_k8.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) The container \"argocd-notifications-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp18xft_k8.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" does not expose port 9001 for the TCPSocket (check: liveness-port, remediation: Check which ports you've exposed and ensure they match what you have specified in the liveness probe.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp18xft_k8.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) serviceAccount \"argocd-notifications-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp18xft_k8.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp18xft_k8.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp18xft_k8.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp18xft_k8.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: notifications-controller\n    app.kubernetes.io/name: argocd-notifications-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-notifications-controller\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-notifications-controller\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-notifications-controller\n    spec:\n      containers:\n      - args:\n        - /usr/local/bin/argocd-notifications\n        env:\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_SELF_SERVICE_NOTIFICATION_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.selfservice.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          tcpSocket:\n            port: 9001\n        name: argocd-notifications-controller\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-pc7loj\n        workingDir: /app\n      nodeSelector:\n        kubernetes.io/os: linux\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      serviceAccountName: argocd-notifications-controller\n      volumes:\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-loxkld\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxncq6lai.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) The container \"argocd-notifications-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxncq6lai.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" does not expose port 9001 for the TCPSocket (check: liveness-port, remediation: Check which ports you've exposed and ensure they match what you have specified in the liveness probe.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxncq6lai.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) serviceAccount \"argocd-notifications-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxncq6lai.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxncq6lai.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: notifications-controller\n    app.kubernetes.io/name: argocd-notifications-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-notifications-controller\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-notifications-controller\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-notifications-controller\n    spec:\n      containers:\n      - args:\n        - /usr/local/bin/argocd-notifications\n        env:\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_SELF_SERVICE_NOTIFICATION_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.selfservice.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          tcpSocket:\n            port: 9001\n        name: argocd-notifications-controller\n        volumeMounts:\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        workingDir: /app\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-notifications-controller\n      volumes:\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdeiy8aat.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) The container \"argocd-notifications-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdeiy8aat.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" does not expose port 9001 for the TCPSocket (check: liveness-port, remediation: Check which ports you've exposed and ensure they match what you have specified in the liveness probe.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdeiy8aat.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdeiy8aat.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) serviceAccount \"argocd-notifications-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdeiy8aat.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdeiy8aat.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdeiy8aat.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/name: argocd-redis\n    app.kubernetes.io/part-of: argocd\n  name: argocd-redis\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-redis\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-redis\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - args:\n        - --save\n        - ''\n        - --appendonly\n        - 'no'\n        - --requirepass $(REDIS_PASSWORD)\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: redis:7.2.7-alpine\n        imagePullPolicy: Always\n        name: redis\n        ports:\n        - containerPort: 6379\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: true\n      initContainers:\n      - command:\n        - argocd\n        - admin\n        - redis-initial-password\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: IfNotPresent\n        name: secret-init\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n      nodeSelector:\n        kubernetes.io/os: linux\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 999\n        seccompProfile:\n          type: RuntimeDefault\n      serviceAccountName: argocd-redis\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd8bic55i.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) The container \"secret-init\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd8bic55i.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) serviceAccount \"argocd-redis\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd8bic55i.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) container \"redis\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd8bic55i.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) container \"redis\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd8bic55i.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) container \"secret-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd8bic55i.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd8bic55i.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) container \"secret-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd8bic55i.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/name: argocd-redis\n    app.kubernetes.io/part-of: argocd\n  name: argocd-redis\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-redis\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-redis\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - args:\n        - --save\n        - ''\n        - --appendonly\n        - 'no'\n        - --requirepass $(REDIS_PASSWORD)\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: redis:7.2.7-alpine\n        imagePullPolicy: Always\n        name: redis\n        ports:\n        - containerPort: 6379\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-ygfiuf\n      initContainers:\n      - command:\n        - argocd\n        - admin\n        - redis-initial-password\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: IfNotPresent\n        name: secret-init\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n      nodeSelector:\n        kubernetes.io/os: linux\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 999\n        seccompProfile:\n          type: RuntimeDefault\n      serviceAccountName: argocd-redis\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-iu9kgv\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfki0tjn1.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) The container \"secret-init\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfki0tjn1.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) serviceAccount \"argocd-redis\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfki0tjn1.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) container \"secret-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfki0tjn1.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfki0tjn1.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) container \"secret-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfki0tjn1.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/name: argocd-redis\n    app.kubernetes.io/part-of: argocd\n  name: argocd-redis\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-redis\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-redis\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - args:\n        - --save\n        - ''\n        - --appendonly\n        - 'no'\n        - --requirepass $(REDIS_PASSWORD)\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: redis:7.2.7-alpine\n        imagePullPolicy: Always\n        name: redis\n        ports:\n        - containerPort: 6379\n      initContainers:\n      - command:\n        - argocd\n        - admin\n        - redis-initial-password\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: IfNotPresent\n        name: secret-init\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-redis\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlx6p9n0.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) The container \"secret-init\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlx6p9n0.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) container \"secret-init\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlx6p9n0.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) container \"redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlx6p9n0.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) serviceAccount \"argocd-redis\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlx6p9n0.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) container \"secret-init\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlx6p9n0.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) container \"redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlx6p9n0.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) container \"secret-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlx6p9n0.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlx6p9n0.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) container \"secret-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlx6p9n0.yaml: (object: <no namespace>/argocd-redis apps/v1, Kind=Deployment) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 10 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: repo-server\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-repo-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-repo-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      automountServiceAccountToken: false\n      containers:\n      - args:\n        - /usr/local/bin/argocd-repo-server\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.metrics.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.minversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.maxversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.ciphers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.repo.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.max.combined.directory.manifests.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.tar.exclusions\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_USE_MANIFEST_GENERATE_PATHS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.use.manifest.generate.paths\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.allow.oob.symlinks\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.tar.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REVISION_CACHE_LOCK_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.revision.cache.lock.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.lsremote.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_REQUEST_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.request.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GRPC_MAX_SIZE_MB\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.grpc.max.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_INCLUDE_HIDDEN_DIRECTORIES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.include.hidden.directories\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: HELM_CACHE_HOME\n          value: /helm-working-dir\n        - name: HELM_CONFIG_HOME\n          value: /helm-working-dir\n        - name: HELM_DATA_HOME\n          value: /helm-working-dir\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz?full=true\n            port: 8084\n          initialDelaySeconds: 30\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: argocd-repo-server\n        ports:\n        - containerPort: 8081\n        - containerPort: 8084\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8084\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /helm-working-dir\n          name: helm-working-dir\n        - mountPath: /home/argocd/cmp-server/plugins\n          name: plugins\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /var/run/argocd/argocd-cmp-server\n        image: quay.io/argoproj/argocd:latest\n        name: copyutil\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /var/run/argocd\n          name: var-files\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-repo-server\n      volumes:\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - configMap:\n          name: argocd-gpg-keys-cm\n        name: gpg-keys\n      - emptyDir: {}\n        name: gpg-keyring\n      - emptyDir: {}\n        name: tmp\n      - emptyDir: {}\n        name: helm-working-dir\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - emptyDir: {}\n        name: var-files\n      - emptyDir: {}\n        name: plugins\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpln8eqful.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"copyutil\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpln8eqful.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"argocd-repo-server\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpln8eqful.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) serviceAccount \"argocd-repo-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpln8eqful.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpln8eqful.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpln8eqful.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpln8eqful.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpln8eqful.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpln8eqful.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 9 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: repo-server\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-repo-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-repo-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      automountServiceAccountToken: false\n      containers:\n      - args:\n        - /usr/local/bin/argocd-repo-server\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.metrics.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.minversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.maxversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.ciphers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.repo.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.max.combined.directory.manifests.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.tar.exclusions\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_USE_MANIFEST_GENERATE_PATHS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.use.manifest.generate.paths\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.allow.oob.symlinks\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.tar.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REVISION_CACHE_LOCK_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.revision.cache.lock.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.lsremote.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_REQUEST_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.request.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GRPC_MAX_SIZE_MB\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.grpc.max.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_INCLUDE_HIDDEN_DIRECTORIES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.include.hidden.directories\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: HELM_CACHE_HOME\n          value: /helm-working-dir\n        - name: HELM_CONFIG_HOME\n          value: /helm-working-dir\n        - name: HELM_DATA_HOME\n          value: /helm-working-dir\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz?full=true\n            port: 8084\n          initialDelaySeconds: 30\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: argocd-repo-server\n        ports:\n        - containerPort: 8081\n        - containerPort: 8084\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8084\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /helm-working-dir\n          name: helm-working-dir\n        - mountPath: /home/argocd/cmp-server/plugins\n          name: plugins\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-55a1pn\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /var/run/argocd/argocd-cmp-server\n        image: quay.io/argoproj/argocd:latest\n        name: copyutil\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /var/run/argocd\n          name: var-files\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-repo-server\n      volumes:\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - configMap:\n          name: argocd-gpg-keys-cm\n        name: gpg-keys\n      - emptyDir: {}\n        name: gpg-keyring\n      - emptyDir: {}\n        name: tmp\n      - emptyDir: {}\n        name: helm-working-dir\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - emptyDir: {}\n        name: var-files\n      - emptyDir: {}\n        name: plugins\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-1ajqi2\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe517a2x5.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"copyutil\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe517a2x5.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"argocd-repo-server\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe517a2x5.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) serviceAccount \"argocd-repo-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe517a2x5.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe517a2x5.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe517a2x5.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe517a2x5.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: repo-server\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-repo-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-repo-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      automountServiceAccountToken: false\n      containers:\n      - args:\n        - /usr/local/bin/argocd-repo-server\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.metrics.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.minversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.maxversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.ciphers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.repo.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.max.combined.directory.manifests.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.tar.exclusions\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_USE_MANIFEST_GENERATE_PATHS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.use.manifest.generate.paths\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.allow.oob.symlinks\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.tar.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REVISION_CACHE_LOCK_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.revision.cache.lock.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.lsremote.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_REQUEST_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.request.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GRPC_MAX_SIZE_MB\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.grpc.max.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_INCLUDE_HIDDEN_DIRECTORIES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.include.hidden.directories\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: HELM_CACHE_HOME\n          value: /helm-working-dir\n        - name: HELM_CONFIG_HOME\n          value: /helm-working-dir\n        - name: HELM_DATA_HOME\n          value: /helm-working-dir\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz?full=true\n            port: 8084\n          initialDelaySeconds: 30\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: argocd-repo-server\n        ports:\n        - containerPort: 8081\n        - containerPort: 8084\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8084\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /helm-working-dir\n          name: helm-working-dir\n        - mountPath: /home/argocd/cmp-server/plugins\n          name: plugins\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /var/run/argocd/argocd-cmp-server\n        image: quay.io/argoproj/argocd:latest\n        name: copyutil\n        volumeMounts:\n        - mountPath: /var/run/argocd\n          name: var-files\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-repo-server\n      volumes:\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - configMap:\n          name: argocd-gpg-keys-cm\n        name: gpg-keys\n      - emptyDir: {}\n        name: gpg-keyring\n      - emptyDir: {}\n        name: tmp\n      - emptyDir: {}\n        name: helm-working-dir\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - emptyDir: {}\n        name: var-files\n      - emptyDir: {}\n        name: plugins\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpahi_t5wo.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"copyutil\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpahi_t5wo.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"argocd-repo-server\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpahi_t5wo.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpahi_t5wo.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpahi_t5wo.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) serviceAccount \"argocd-repo-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpahi_t5wo.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpahi_t5wo.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpahi_t5wo.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpahi_t5wo.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpahi_t5wo.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpahi_t5wo.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 11 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: server\n    app.kubernetes.io/name: argocd-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-server\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - args:\n        - /usr/local/bin/argocd-server\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_SERVER_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: server.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_BASEHREF\n          valueFrom:\n            configMapKeyRef:\n              key: server.basehref\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ROOTPATH\n          valueFrom:\n            configMapKeyRef:\n              key: server.rootpath\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: server.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: server.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DISABLE_AUTH\n          valueFrom:\n            configMapKeyRef:\n              key: server.disable.auth\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_GZIP\n          valueFrom:\n            configMapKeyRef:\n              key: server.enable.gzip\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_X_FRAME_OPTIONS\n          valueFrom:\n            configMapKeyRef:\n              key: server.x.frame.options\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_CONTENT_SECURITY_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: server.content.security.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.minversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.maxversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.ciphers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_CONNECTION_STATUS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.connection.status.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OIDC_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.oidc.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOGIN_ATTEMPTS_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.login.attempts.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_STATIC_ASSETS\n          valueFrom:\n            configMapKeyRef:\n              key: server.staticassets\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_MAX_COOKIE_NUMBER\n          valueFrom:\n            configMapKeyRef:\n              key: server.http.cookie.maxnumber\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: server.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_METRICS_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: server.metrics.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_PROXY_EXTENSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.enable.proxy.extension\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              key: server.k8sclient.retry.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              key: server.k8sclient.retry.base.backoff\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_API_CONTENT_TYPES\n          valueFrom:\n            configMapKeyRef:\n              key: server.api.content.types\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: server.webhook.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.allowed.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: hydrator.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SYNC_WITH_REPLACE_ALLOWED\n          valueFrom:\n            configMapKeyRef:\n              key: server.sync.replace.allowed\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: 8080\n          initialDelaySeconds: 3\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: argocd-server\n        ports:\n        - containerPort: 8080\n        - containerPort: 8083\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 3\n          periodSeconds: 30\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/server/tls\n          name: argocd-repo-server-tls\n        - mountPath: /app/config/dex/tls\n          name: argocd-dex-server-tls\n        - mountPath: /home/argocd\n          name: plugins-home\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /home/argocd/params\n          name: argocd-cmd-params-cm\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-server\n      volumes:\n      - emptyDir: {}\n        name: plugins-home\n      - emptyDir: {}\n        name: tmp\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - name: argocd-dex-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-dex-server-tls\n      - configMap:\n          items:\n          - key: server.profile.enabled\n            path: profiler.enabled\n          name: argocd-cmd-params-cm\n          optional: true\n        name: argocd-cmd-params-cm\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvb80dfxp.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) The container \"argocd-server\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvb80dfxp.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) serviceAccount \"argocd-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvb80dfxp.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvb80dfxp.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvb80dfxp.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvb80dfxp.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: server\n    app.kubernetes.io/name: argocd-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-server\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - args:\n        - /usr/local/bin/argocd-server\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_SERVER_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: server.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_BASEHREF\n          valueFrom:\n            configMapKeyRef:\n              key: server.basehref\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ROOTPATH\n          valueFrom:\n            configMapKeyRef:\n              key: server.rootpath\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: server.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: server.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DISABLE_AUTH\n          valueFrom:\n            configMapKeyRef:\n              key: server.disable.auth\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_GZIP\n          valueFrom:\n            configMapKeyRef:\n              key: server.enable.gzip\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_X_FRAME_OPTIONS\n          valueFrom:\n            configMapKeyRef:\n              key: server.x.frame.options\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_CONTENT_SECURITY_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: server.content.security.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.minversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.maxversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.ciphers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_CONNECTION_STATUS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.connection.status.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OIDC_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.oidc.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOGIN_ATTEMPTS_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.login.attempts.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_STATIC_ASSETS\n          valueFrom:\n            configMapKeyRef:\n              key: server.staticassets\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_MAX_COOKIE_NUMBER\n          valueFrom:\n            configMapKeyRef:\n              key: server.http.cookie.maxnumber\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: server.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_METRICS_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: server.metrics.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_PROXY_EXTENSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.enable.proxy.extension\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              key: server.k8sclient.retry.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              key: server.k8sclient.retry.base.backoff\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_API_CONTENT_TYPES\n          valueFrom:\n            configMapKeyRef:\n              key: server.api.content.types\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: server.webhook.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.allowed.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: hydrator.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SYNC_WITH_REPLACE_ALLOWED\n          valueFrom:\n            configMapKeyRef:\n              key: server.sync.replace.allowed\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: 8080\n          initialDelaySeconds: 3\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: argocd-server\n        ports:\n        - containerPort: 8080\n        - containerPort: 8083\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 3\n          periodSeconds: 30\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/server/tls\n          name: argocd-repo-server-tls\n        - mountPath: /app/config/dex/tls\n          name: argocd-dex-server-tls\n        - mountPath: /home/argocd\n          name: plugins-home\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /home/argocd/params\n          name: argocd-cmd-params-cm\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-nie2i1\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-server\n      volumes:\n      - emptyDir: {}\n        name: plugins-home\n      - emptyDir: {}\n        name: tmp\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - name: argocd-dex-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-dex-server-tls\n      - configMap:\n          items:\n          - key: server.profile.enabled\n            path: profiler.enabled\n          name: argocd-cmd-params-cm\n          optional: true\n        name: argocd-cmd-params-cm\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-ellswh\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpugfsgorn.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) The container \"argocd-server\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpugfsgorn.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) serviceAccount \"argocd-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpugfsgorn.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpugfsgorn.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: server\n    app.kubernetes.io/name: argocd-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-server\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - args:\n        - /usr/local/bin/argocd-server\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_SERVER_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: server.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_BASEHREF\n          valueFrom:\n            configMapKeyRef:\n              key: server.basehref\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ROOTPATH\n          valueFrom:\n            configMapKeyRef:\n              key: server.rootpath\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: server.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: server.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DISABLE_AUTH\n          valueFrom:\n            configMapKeyRef:\n              key: server.disable.auth\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_GZIP\n          valueFrom:\n            configMapKeyRef:\n              key: server.enable.gzip\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_X_FRAME_OPTIONS\n          valueFrom:\n            configMapKeyRef:\n              key: server.x.frame.options\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_CONTENT_SECURITY_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: server.content.security.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.minversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.maxversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.ciphers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_CONNECTION_STATUS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.connection.status.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OIDC_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.oidc.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOGIN_ATTEMPTS_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.login.attempts.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_STATIC_ASSETS\n          valueFrom:\n            configMapKeyRef:\n              key: server.staticassets\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_MAX_COOKIE_NUMBER\n          valueFrom:\n            configMapKeyRef:\n              key: server.http.cookie.maxnumber\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: server.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_METRICS_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: server.metrics.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_PROXY_EXTENSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.enable.proxy.extension\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              key: server.k8sclient.retry.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              key: server.k8sclient.retry.base.backoff\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_API_CONTENT_TYPES\n          valueFrom:\n            configMapKeyRef:\n              key: server.api.content.types\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: server.webhook.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.allowed.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: hydrator.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SYNC_WITH_REPLACE_ALLOWED\n          valueFrom:\n            configMapKeyRef:\n              key: server.sync.replace.allowed\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: 8080\n          initialDelaySeconds: 3\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: argocd-server\n        ports:\n        - containerPort: 8080\n        - containerPort: 8083\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 3\n          periodSeconds: 30\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/server/tls\n          name: argocd-repo-server-tls\n        - mountPath: /app/config/dex/tls\n          name: argocd-dex-server-tls\n        - mountPath: /home/argocd\n          name: plugins-home\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /home/argocd/params\n          name: argocd-cmd-params-cm\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-server\n      volumes:\n      - emptyDir: {}\n        name: plugins-home\n      - emptyDir: {}\n        name: tmp\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - name: argocd-dex-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-dex-server-tls\n      - configMap:\n          items:\n          - key: server.profile.enabled\n            path: profiler.enabled\n          name: argocd-cmd-params-cm\n          optional: true\n        name: argocd-cmd-params-cm\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8q459o89.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) The container \"argocd-server\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8q459o89.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8q459o89.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) serviceAccount \"argocd-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8q459o89.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8q459o89.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8q459o89.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: application-controller\n    app.kubernetes.io/name: argocd-application-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-application-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-application-controller\n  serviceName: argocd-application-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-application-controller\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-application-controller\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - args:\n        - /usr/local/bin/argocd-application-controller\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_CONTROLLER_REPLICAS\n          value: '1'\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_HARD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.hard.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_RECONCILIATION_JITTER\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation.jitter\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_ERROR_GRACE_PERIOD_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.error.grace.period.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_STATUS_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.status.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OPERATION_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.operation.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_METRICS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.metrics.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_FACTOR\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.factor\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_CAP_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.cap.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SYNC_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.sync.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_PERSIST_RESOURCE_HEALTH\n          valueFrom:\n            configMapKeyRef:\n              key: controller.resource.health.persist\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CONTROLLER_SHARDING_ALGORITHM\n          valueFrom:\n            configMapKeyRef:\n              key: controller.sharding.algorithm\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_KUBECTL_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.kubectl.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              key: controller.k8sclient.retry.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              key: controller.k8sclient.retry.base.backoff\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SERVER_SIDE_DIFF\n          valueFrom:\n            configMapKeyRef:\n              key: controller.diff.server.side\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_IGNORE_NORMALIZER_JQ_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.ignore.normalizer.jq.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: hydrator.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_BATCH_EVENTS_PROCESSING\n          valueFrom:\n            configMapKeyRef:\n              key: controller.cluster.cache.batch.events.processing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_EVENTS_PROCESSING_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.cluster.cache.events.processing.interval\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: KUBECACHEDIR\n          value: /tmp/kubecache\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: argocd-application-controller\n        ports:\n        - containerPort: 8082\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8082\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        volumeMounts:\n        - mountPath: /app/config/controller/tls\n          name: argocd-repo-server-tls\n        - mountPath: /home/argocd\n          name: argocd-home\n        - mountPath: /home/argocd/params\n          name: argocd-cmd-params-cm\n        - mountPath: /tmp\n          name: argocd-application-controller-tmp\n        workingDir: /home/argocd\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-application-controller\n      volumes:\n      - emptyDir: {}\n        name: argocd-home\n      - emptyDir: {}\n        name: argocd-application-controller-tmp\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - configMap:\n          items:\n          - key: controller.profile.enabled\n            path: profiler.enabled\n          name: argocd-cmd-params-cm\n          optional: true\n        name: argocd-cmd-params-cm\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblipfqwv.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) The container \"argocd-application-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblipfqwv.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) serviceAccount \"argocd-application-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblipfqwv.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblipfqwv.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblipfqwv.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblipfqwv.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: application-controller\n    app.kubernetes.io/name: argocd-application-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-application-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-application-controller\n  serviceName: argocd-application-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-application-controller\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-application-controller\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - args:\n        - /usr/local/bin/argocd-application-controller\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_CONTROLLER_REPLICAS\n          value: '1'\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_HARD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.hard.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_RECONCILIATION_JITTER\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation.jitter\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_ERROR_GRACE_PERIOD_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.error.grace.period.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_STATUS_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.status.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OPERATION_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.operation.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_METRICS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.metrics.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_FACTOR\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.factor\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_CAP_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.cap.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SYNC_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.sync.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_PERSIST_RESOURCE_HEALTH\n          valueFrom:\n            configMapKeyRef:\n              key: controller.resource.health.persist\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CONTROLLER_SHARDING_ALGORITHM\n          valueFrom:\n            configMapKeyRef:\n              key: controller.sharding.algorithm\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_KUBECTL_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.kubectl.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              key: controller.k8sclient.retry.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              key: controller.k8sclient.retry.base.backoff\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SERVER_SIDE_DIFF\n          valueFrom:\n            configMapKeyRef:\n              key: controller.diff.server.side\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_IGNORE_NORMALIZER_JQ_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.ignore.normalizer.jq.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: hydrator.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_BATCH_EVENTS_PROCESSING\n          valueFrom:\n            configMapKeyRef:\n              key: controller.cluster.cache.batch.events.processing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_EVENTS_PROCESSING_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.cluster.cache.events.processing.interval\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: KUBECACHEDIR\n          value: /tmp/kubecache\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: argocd-application-controller\n        ports:\n        - containerPort: 8082\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8082\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /app/config/controller/tls\n          name: argocd-repo-server-tls\n        - mountPath: /home/argocd\n          name: argocd-home\n        - mountPath: /home/argocd/params\n          name: argocd-cmd-params-cm\n        - mountPath: /tmp\n          name: argocd-application-controller-tmp\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-1k7pmf\n        workingDir: /home/argocd\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-application-controller\n      volumes:\n      - emptyDir: {}\n        name: argocd-home\n      - emptyDir: {}\n        name: argocd-application-controller-tmp\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - configMap:\n          items:\n          - key: controller.profile.enabled\n            path: profiler.enabled\n          name: argocd-cmd-params-cm\n          optional: true\n        name: argocd-cmd-params-cm\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-hixu7h\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphykbkk5m.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) The container \"argocd-application-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphykbkk5m.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) serviceAccount \"argocd-application-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphykbkk5m.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphykbkk5m.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: application-controller\n    app.kubernetes.io/name: argocd-application-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-application-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-application-controller\n  serviceName: argocd-application-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-application-controller\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-application-controller\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - args:\n        - /usr/local/bin/argocd-application-controller\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_CONTROLLER_REPLICAS\n          value: '1'\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_HARD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.hard.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_RECONCILIATION_JITTER\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation.jitter\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_ERROR_GRACE_PERIOD_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.error.grace.period.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_STATUS_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.status.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OPERATION_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.operation.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_METRICS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.metrics.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_FACTOR\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.factor\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_CAP_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.cap.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SYNC_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.sync.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_PERSIST_RESOURCE_HEALTH\n          valueFrom:\n            configMapKeyRef:\n              key: controller.resource.health.persist\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CONTROLLER_SHARDING_ALGORITHM\n          valueFrom:\n            configMapKeyRef:\n              key: controller.sharding.algorithm\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_KUBECTL_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.kubectl.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              key: controller.k8sclient.retry.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              key: controller.k8sclient.retry.base.backoff\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SERVER_SIDE_DIFF\n          valueFrom:\n            configMapKeyRef:\n              key: controller.diff.server.side\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_IGNORE_NORMALIZER_JQ_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.ignore.normalizer.jq.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: hydrator.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_BATCH_EVENTS_PROCESSING\n          valueFrom:\n            configMapKeyRef:\n              key: controller.cluster.cache.batch.events.processing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_EVENTS_PROCESSING_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.cluster.cache.events.processing.interval\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: KUBECACHEDIR\n          value: /tmp/kubecache\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: argocd-application-controller\n        ports:\n        - containerPort: 8082\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8082\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        volumeMounts:\n        - mountPath: /app/config/controller/tls\n          name: argocd-repo-server-tls\n        - mountPath: /home/argocd\n          name: argocd-home\n        - mountPath: /home/argocd/params\n          name: argocd-cmd-params-cm\n        - mountPath: /tmp\n          name: argocd-application-controller-tmp\n        workingDir: /home/argocd\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-application-controller\n      volumes:\n      - emptyDir: {}\n        name: argocd-home\n      - emptyDir: {}\n        name: argocd-application-controller-tmp\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - configMap:\n          items:\n          - key: controller.profile.enabled\n            path: profiler.enabled\n          name: argocd-cmd-params-cm\n          optional: true\n        name: argocd-cmd-params-cm\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfhig9f43.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) The container \"argocd-application-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfhig9f43.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfhig9f43.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) serviceAccount \"argocd-application-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfhig9f43.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfhig9f43.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfhig9f43.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/persistent-volume-provisioning/rbd/pod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: server\nspec:\n  replicas: 1\n  selector:\n    role: server\n  template:\n    metadata:\n      labels:\n        role: server\n    spec:\n      containers:\n      - name: server\n        image: nginx\n        volumeMounts:\n        - mountPath: /var/lib/www/html\n          name: mypvc\n        securityContext:\n          privileged: true\n      volumes:\n      - name: mypvc\n        persistentVolumeClaim:\n          claimName: claim1\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzy67k5yo.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) The container \"server\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzy67k5yo.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzy67k5yo.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzy67k5yo.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzy67k5yo.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzy67k5yo.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzy67k5yo.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/persistent-volume-provisioning/rbd/pod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: server\nspec:\n  replicas: 1\n  selector:\n    role: server\n  template:\n    metadata:\n      labels:\n        role: server\n    spec:\n      containers:\n      - name: server\n        image: nginx\n        volumeMounts:\n        - mountPath: /var/lib/www/html\n          name: mypvc\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-03v9v7\n      volumes:\n      - name: mypvc\n        persistentVolumeClaim:\n          claimName: claim1\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-828f8b\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp78_gzwho.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) The container \"server\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp78_gzwho.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp78_gzwho.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp78_gzwho.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp78_gzwho.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/vsphere/vsphere-volume-pod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-vmdk\nspec:\n  containers:\n  - image: registry.k8s.io/test-webserver\n    name: test-container\n    volumeMounts:\n    - mountPath: /test-vmdk\n      name: test-volume\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test-volume\n    vsphereVolume:\n      volumePath: '[DatastoreName] volumes/myDisk'\n      fsType: ext4\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5j9ww82x.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5j9ww82x.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5j9ww82x.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5j9ww82x.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5j9ww82x.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5j9ww82x.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5j9ww82x.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/vsphere/vsphere-volume-pod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-vmdk\nspec:\n  containers:\n  - image: registry.k8s.io/test-webserver\n    name: test-container\n    volumeMounts:\n    - mountPath: /test-vmdk\n      name: test-volume\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-jutuay\n  volumes:\n  - name: test-volume\n    vsphereVolume:\n      volumePath: '[DatastoreName] volumes/myDisk'\n      fsType: ext4\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-d7o5i1\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmph_7lj5os.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmph_7lj5os.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmph_7lj5os.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmph_7lj5os.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmph_7lj5os.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/persistent-volume-provisioning/quobyte/example-pod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: server\nspec:\n  replicas: 1\n  selector:\n    role: server\n  template:\n    metadata:\n      labels:\n        role: server\n    spec:\n      containers:\n      - name: server\n        image: nginx\n        volumeMounts:\n        - mountPath: /var/lib/www/html\n          name: quobytepvc\n        securityContext:\n          privileged: true\n      volumes:\n      - name: quobytepvc\n        persistentVolumeClaim:\n          claimName: claim1\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpiwbksqv6.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) The container \"server\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpiwbksqv6.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpiwbksqv6.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpiwbksqv6.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpiwbksqv6.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpiwbksqv6.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpiwbksqv6.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/persistent-volume-provisioning/quobyte/example-pod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: server\nspec:\n  replicas: 1\n  selector:\n    role: server\n  template:\n    metadata:\n      labels:\n        role: server\n    spec:\n      containers:\n      - name: server\n        image: nginx\n        volumeMounts:\n        - mountPath: /var/lib/www/html\n          name: quobytepvc\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-5fuhh4\n      volumes:\n      - name: quobytepvc\n        persistentVolumeClaim:\n          claimName: claim1\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-7hbt08\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp67ibvhhr.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) The container \"server\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp67ibvhhr.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp67ibvhhr.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp67ibvhhr.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp67ibvhhr.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cpu-manager/shared.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: shared\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: shared\n    resources:\n      requests:\n        cpu: 100m\n    securityContext:\n      privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo6_23_rb.yaml: (object: <no namespace>/shared /v1, Kind=Pod) The container \"shared\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo6_23_rb.yaml: (object: <no namespace>/shared /v1, Kind=Pod) container \"shared\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo6_23_rb.yaml: (object: <no namespace>/shared /v1, Kind=Pod) container \"shared\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo6_23_rb.yaml: (object: <no namespace>/shared /v1, Kind=Pod) container \"shared\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo6_23_rb.yaml: (object: <no namespace>/shared /v1, Kind=Pod) container \"shared\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo6_23_rb.yaml: (object: <no namespace>/shared /v1, Kind=Pod) container \"shared\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cpu-manager/shared.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: shared\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: shared\n    resources:\n      requests:\n        cpu: 100m\n    volumeMounts:\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-fr2pwq\n  volumes:\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-vwpzwi\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwuesmupq.yaml: (object: <no namespace>/shared /v1, Kind=Pod) The container \"shared\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwuesmupq.yaml: (object: <no namespace>/shared /v1, Kind=Pod) container \"shared\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwuesmupq.yaml: (object: <no namespace>/shared /v1, Kind=Pod) container \"shared\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwuesmupq.yaml: (object: <no namespace>/shared /v1, Kind=Pod) container \"shared\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/elasticsearch/es-rc.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es\n  labels:\n    component: elasticsearch\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n    spec:\n      serviceAccount: elasticsearch\n      initContainers:\n      - name: init-sysctl\n        image: busybox\n        imagePullPolicy: IfNotPresent\n        command:\n        - sysctl\n        - -w\n        - vm.max_map_count=262144\n        securityContext:\n          privileged: true\n      containers:\n      - name: es\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n          privileged: true\n        image: quay.io/pires/docker-elasticsearch-kubernetes:5.6.2\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: myesdb\n        - name: DISCOVERY_SERVICE\n          value: elasticsearch\n        - name: NODE_MASTER\n          value: 'true'\n        - name: NODE_DATA\n          value: 'true'\n        - name: HTTP_ENABLE\n          value: 'true'\n        ports:\n        - containerPort: 9200\n          name: http\n          protocol: TCP\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n      volumes:\n      - name: storage\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uw7fsd4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) serviceAccount is specified (elasticsearch), but this field is deprecated; use serviceAccountName instead (check: deprecated-service-account-field, remediation: Use the serviceAccountName field instead. If you must specify serviceAccount, ensure values for serviceAccount and serviceAccountName match.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uw7fsd4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uw7fsd4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) The container \"init-sysctl\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uw7fsd4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uw7fsd4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uw7fsd4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) serviceAccount \"elasticsearch\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uw7fsd4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uw7fsd4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uw7fsd4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uw7fsd4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uw7fsd4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uw7fsd4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uw7fsd4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uw7fsd4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uw7fsd4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uw7fsd4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 16 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/elasticsearch/es-rc.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es\n  labels:\n    component: elasticsearch\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n    spec:\n      serviceAccount: elasticsearch\n      initContainers:\n      - name: init-sysctl\n        image: busybox\n        imagePullPolicy: IfNotPresent\n        command:\n        - sysctl\n        - -w\n        - vm.max_map_count=262144\n        securityContext:\n          privileged: true\n      containers:\n      - name: es\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n        image: quay.io/pires/docker-elasticsearch-kubernetes:5.6.2\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: myesdb\n        - name: DISCOVERY_SERVICE\n          value: elasticsearch\n        - name: NODE_MASTER\n          value: 'true'\n        - name: NODE_DATA\n          value: 'true'\n        - name: HTTP_ENABLE\n          value: 'true'\n        ports:\n        - containerPort: 9200\n          name: http\n          protocol: TCP\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-tkqmx0\n      volumes:\n      - name: storage\n        emptyDir: {}\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-r6g6um\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfcm2e9hc.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) serviceAccount is specified (elasticsearch), but this field is deprecated; use serviceAccountName instead (check: deprecated-service-account-field, remediation: Use the serviceAccountName field instead. If you must specify serviceAccount, ensure values for serviceAccount and serviceAccountName match.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfcm2e9hc.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfcm2e9hc.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) The container \"init-sysctl\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfcm2e9hc.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfcm2e9hc.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfcm2e9hc.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) serviceAccount \"elasticsearch\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfcm2e9hc.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfcm2e9hc.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfcm2e9hc.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfcm2e9hc.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfcm2e9hc.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfcm2e9hc.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfcm2e9hc.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfcm2e9hc.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 14 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/elasticsearch/es-rc.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es\n  labels:\n    component: elasticsearch\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n    spec:\n      serviceAccount: elasticsearch\n      initContainers:\n      - name: init-sysctl\n        image: busybox\n        imagePullPolicy: IfNotPresent\n        command:\n        - sysctl\n        - -w\n        - vm.max_map_count=262144\n      containers:\n      - name: es\n        image: quay.io/pires/docker-elasticsearch-kubernetes:5.6.2\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: myesdb\n        - name: DISCOVERY_SERVICE\n          value: elasticsearch\n        - name: NODE_MASTER\n          value: 'true'\n        - name: NODE_DATA\n          value: 'true'\n        - name: HTTP_ENABLE\n          value: 'true'\n        ports:\n        - containerPort: 9200\n          name: http\n          protocol: TCP\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n      volumes:\n      - name: storage\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprb81n4c4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) serviceAccount is specified (elasticsearch), but this field is deprecated; use serviceAccountName instead (check: deprecated-service-account-field, remediation: Use the serviceAccountName field instead. If you must specify serviceAccount, ensure values for serviceAccount and serviceAccountName match.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprb81n4c4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) The container \"init-sysctl\" is using an invalid container image, \"busybox\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprb81n4c4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprb81n4c4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprb81n4c4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) serviceAccount \"elasticsearch\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprb81n4c4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprb81n4c4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprb81n4c4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprb81n4c4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprb81n4c4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"init-sysctl\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprb81n4c4.yaml: (object: <no namespace>/es /v1, Kind=ReplicationController) container \"es\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 11 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/volumes/storageos/storageos-pvcpod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: redis\n    role: master\n  name: test-storageos-redis-pvc\nspec:\n  containers:\n  - name: master\n    image: kubernetes/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    resources:\n      limits:\n        cpu: '0.1'\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: redis-data\n    securityContext:\n      privileged: true\n  volumes:\n  - name: redis-data\n    persistentVolumeClaim:\n      claimName: pvc0001\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3t19gpje.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3t19gpje.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3t19gpje.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3t19gpje.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3t19gpje.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3t19gpje.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/volumes/storageos/storageos-pvcpod.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: redis\n    role: master\n  name: test-storageos-redis-pvc\nspec:\n  containers:\n  - name: master\n    image: kubernetes/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: redis-data\n  volumes:\n  - name: redis-data\n    persistentVolumeClaim:\n      claimName: pvc0001\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlmaxek1.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlmaxek1.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlmaxek1.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlmaxek1.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/volumes/storageos/storageos-pvcpod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: redis\n    role: master\n  name: test-storageos-redis-pvc\nspec:\n  containers:\n  - name: master\n    image: kubernetes/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    resources:\n      limits:\n        cpu: '0.1'\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: redis-data\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-hk4kcu\n  volumes:\n  - name: redis-data\n    persistentVolumeClaim:\n      claimName: pvc0001\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-7hgtq2\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpc1sjg1ii.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpc1sjg1ii.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpc1sjg1ii.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpc1sjg1ii.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/azure_disk/claim/blob-based-disk/shared-hdd/pod-uses-shared-hdd.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-uses-shared-hdd-5g\n  labels:\n    name: storage\nspec:\n  containers:\n  - image: nginx\n    name: az-c-01\n    command:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> /mnt/blobdisk/outfile; sleep 1; done\n    volumeMounts:\n    - name: blobdisk01\n      mountPath: /mnt/blobdisk\n    securityContext:\n      privileged: true\n  volumes:\n  - name: blobdisk01\n    persistentVolumeClaim:\n      claimName: pv-dd-shared-hdd-5g\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjasgn0mz.yaml: (object: <no namespace>/pod-uses-shared-hdd-5g /v1, Kind=Pod) The container \"az-c-01\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjasgn0mz.yaml: (object: <no namespace>/pod-uses-shared-hdd-5g /v1, Kind=Pod) container \"az-c-01\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjasgn0mz.yaml: (object: <no namespace>/pod-uses-shared-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjasgn0mz.yaml: (object: <no namespace>/pod-uses-shared-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjasgn0mz.yaml: (object: <no namespace>/pod-uses-shared-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjasgn0mz.yaml: (object: <no namespace>/pod-uses-shared-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjasgn0mz.yaml: (object: <no namespace>/pod-uses-shared-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/azure_disk/claim/blob-based-disk/shared-hdd/pod-uses-shared-hdd.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-uses-shared-hdd-5g\n  labels:\n    name: storage\nspec:\n  containers:\n  - image: nginx\n    name: az-c-01\n    command:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> /mnt/blobdisk/outfile; sleep 1; done\n    volumeMounts:\n    - name: blobdisk01\n      mountPath: /mnt/blobdisk\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-7na2yu\n  volumes:\n  - name: blobdisk01\n    persistentVolumeClaim:\n      claimName: pv-dd-shared-hdd-5g\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-nrkbzm\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppt8ti0mu.yaml: (object: <no namespace>/pod-uses-shared-hdd-5g /v1, Kind=Pod) The container \"az-c-01\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppt8ti0mu.yaml: (object: <no namespace>/pod-uses-shared-hdd-5g /v1, Kind=Pod) container \"az-c-01\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppt8ti0mu.yaml: (object: <no namespace>/pod-uses-shared-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppt8ti0mu.yaml: (object: <no namespace>/pod-uses-shared-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppt8ti0mu.yaml: (object: <no namespace>/pod-uses-shared-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/nfs/nfs-server-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nfs-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      role: nfs-server\n  template:\n    metadata:\n      labels:\n        role: nfs-server\n    spec:\n      containers:\n      - name: nfs-server\n        image: registry.k8s.io/volume-nfs:0.8\n        ports:\n        - name: nfs\n          containerPort: 2049\n        - name: mountd\n          containerPort: 20048\n        - name: rpcbind\n          containerPort: 111\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /exports\n          name: mypvc\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-zw4u7v\n      volumes:\n      - name: mypvc\n        persistentVolumeClaim:\n          claimName: nfs-pv-provisioning-demo\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-wiplos\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpir_3_8xn.yaml: (object: <no namespace>/nfs-server apps/v1, Kind=Deployment) container \"nfs-server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpir_3_8xn.yaml: (object: <no namespace>/nfs-server apps/v1, Kind=Deployment) container \"nfs-server\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpir_3_8xn.yaml: (object: <no namespace>/nfs-server apps/v1, Kind=Deployment) container \"nfs-server\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpir_3_8xn.yaml: (object: <no namespace>/nfs-server apps/v1, Kind=Deployment) container \"nfs-server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpir_3_8xn.yaml: (object: <no namespace>/nfs-server apps/v1, Kind=Deployment) container \"nfs-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpir_3_8xn.yaml: (object: <no namespace>/nfs-server apps/v1, Kind=Deployment) container \"nfs-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/nfs/nfs-server-deployment.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nfs-server\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      role: nfs-server\n  template:\n    metadata:\n      labels:\n        role: nfs-server\n    spec:\n      containers:\n      - name: nfs-server\n        image: registry.k8s.io/volume-nfs:0.8\n        ports:\n        - name: nfs\n          containerPort: 2049\n        - name: mountd\n          containerPort: 20048\n        - name: rpcbind\n          containerPort: 111\n        volumeMounts:\n        - mountPath: /exports\n          name: mypvc\n      volumes:\n      - name: mypvc\n        persistentVolumeClaim:\n          claimName: nfs-pv-provisioning-demo\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmw5w74_o.yaml: (object: <no namespace>/nfs-server apps/v1, Kind=Deployment) container \"nfs-server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmw5w74_o.yaml: (object: <no namespace>/nfs-server apps/v1, Kind=Deployment) container \"nfs-server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmw5w74_o.yaml: (object: <no namespace>/nfs-server apps/v1, Kind=Deployment) container \"nfs-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmw5w74_o.yaml: (object: <no namespace>/nfs-server apps/v1, Kind=Deployment) container \"nfs-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/volumes/cephfs/cephfs.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cephfs\nspec:\n  containers:\n  - name: cephfs-rw\n    image: kubernetes/pause\n    volumeMounts:\n    - mountPath: /mnt/cephfs\n      name: cephfs\n    securityContext:\n      privileged: true\n  volumes:\n  - name: cephfs\n    cephfs:\n      monitors:\n      - 10.16.154.78:6789\n      - 10.16.154.82:6789\n      - 10.16.154.83:6789\n      user: admin\n      secretFile: /etc/ceph/admin.secret\n      readOnly: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd0fwiznt.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) The container \"cephfs-rw\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd0fwiznt.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd0fwiznt.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd0fwiznt.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd0fwiznt.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd0fwiznt.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd0fwiznt.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/volumes/cephfs/cephfs.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cephfs\nspec:\n  containers:\n  - name: cephfs-rw\n    image: kubernetes/pause\n    volumeMounts:\n    - mountPath: /mnt/cephfs\n      name: cephfs\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-yz77h7\n  volumes:\n  - name: cephfs\n    cephfs:\n      monitors:\n      - 10.16.154.78:6789\n      - 10.16.154.82:6789\n      - 10.16.154.83:6789\n      user: admin\n      secretFile: /etc/ceph/admin.secret\n      readOnly: true\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-l5ni28\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpff0i4pfc.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) The container \"cephfs-rw\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpff0i4pfc.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpff0i4pfc.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpff0i4pfc.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpff0i4pfc.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storm/storm-worker-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: storm-worker-controller\n  labels:\n    name: storm-worker\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: storm-worker\n      uses: nimbus\n  template:\n    metadata:\n      labels:\n        name: storm-worker\n        uses: nimbus\n    spec:\n      containers:\n      - name: storm-worke\n        image: mattf/storm-worker\n        resources:\n          limits:\n            cpu: 200m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - hostPort: 6700\n          containerPort: 6700\n        - hostPort: 6701\n          containerPort: 6701\n        - hostPort: 6702\n          containerPort: 6702\n        - hostPort: 6703\n          containerPort: 6703\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptf71fufg.yaml: (object: <no namespace>/storm-worker-controller apps/v1, Kind=Deployment) The container \"storm-worke\" is using an invalid container image, \"mattf/storm-worker\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptf71fufg.yaml: (object: <no namespace>/storm-worker-controller apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptf71fufg.yaml: (object: <no namespace>/storm-worker-controller apps/v1, Kind=Deployment) container \"storm-worke\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptf71fufg.yaml: (object: <no namespace>/storm-worker-controller apps/v1, Kind=Deployment) container \"storm-worke\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptf71fufg.yaml: (object: <no namespace>/storm-worker-controller apps/v1, Kind=Deployment) container \"storm-worke\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptf71fufg.yaml: (object: <no namespace>/storm-worker-controller apps/v1, Kind=Deployment) container \"storm-worke\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storm/storm-worker-controller.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: storm-worker-controller\n  labels:\n    name: storm-worker\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: storm-worker\n      uses: nimbus\n  template:\n    metadata:\n      labels:\n        name: storm-worker\n        uses: nimbus\n    spec:\n      containers:\n      - name: storm-worke\n        image: mattf/storm-worker\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - hostPort: 6700\n          containerPort: 6700\n        - hostPort: 6701\n          containerPort: 6701\n        - hostPort: 6702\n          containerPort: 6702\n        - hostPort: 6703\n          containerPort: 6703\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplbuk5r_g.yaml: (object: <no namespace>/storm-worker-controller apps/v1, Kind=Deployment) The container \"storm-worke\" is using an invalid container image, \"mattf/storm-worker\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplbuk5r_g.yaml: (object: <no namespace>/storm-worker-controller apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplbuk5r_g.yaml: (object: <no namespace>/storm-worker-controller apps/v1, Kind=Deployment) container \"storm-worke\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplbuk5r_g.yaml: (object: <no namespace>/storm-worker-controller apps/v1, Kind=Deployment) container \"storm-worke\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplbuk5r_g.yaml: (object: <no namespace>/storm-worker-controller apps/v1, Kind=Deployment) container \"storm-worke\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storm/storm-worker-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: storm-worker-controller\n  labels:\n    name: storm-worker\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      name: storm-worker\n      uses: nimbus\n  template:\n    metadata:\n      labels:\n        name: storm-worker\n        uses: nimbus\n    spec:\n      containers:\n      - name: storm-worke\n        image: mattf/storm-worker\n        resources:\n          limits:\n            cpu: 200m\n            memory: 500Mi\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - hostPort: 6700\n          containerPort: 6700\n        - hostPort: 6701\n          containerPort: 6701\n        - hostPort: 6702\n          containerPort: 6702\n        - hostPort: 6703\n          containerPort: 6703\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-p0uv6v\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-vnxhvd\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpllvw6qdg.yaml: (object: <no namespace>/storm-worker-controller apps/v1, Kind=Deployment) The container \"storm-worke\" is using an invalid container image, \"mattf/storm-worker\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpllvw6qdg.yaml: (object: <no namespace>/storm-worker-controller apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpllvw6qdg.yaml: (object: <no namespace>/storm-worker-controller apps/v1, Kind=Deployment) container \"storm-worke\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpllvw6qdg.yaml: (object: <no namespace>/storm-worker-controller apps/v1, Kind=Deployment) container \"storm-worke\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/spark/zeppelin-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: zeppelin-controller\nspec:\n  replicas: 1\n  selector:\n    component: zeppelin\n  template:\n    metadata:\n      labels:\n        component: zeppelin\n    spec:\n      containers:\n      - name: zeppelin\n        image: registry.k8s.io/zeppelin:v0.5.6_v1\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9tbhdk06.yaml: (object: <no namespace>/zeppelin-controller /v1, Kind=ReplicationController) container \"zeppelin\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9tbhdk06.yaml: (object: <no namespace>/zeppelin-controller /v1, Kind=ReplicationController) container \"zeppelin\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9tbhdk06.yaml: (object: <no namespace>/zeppelin-controller /v1, Kind=ReplicationController) container \"zeppelin\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9tbhdk06.yaml: (object: <no namespace>/zeppelin-controller /v1, Kind=ReplicationController) container \"zeppelin\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9tbhdk06.yaml: (object: <no namespace>/zeppelin-controller /v1, Kind=ReplicationController) container \"zeppelin\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/spark/zeppelin-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: zeppelin-controller\nspec:\n  replicas: 1\n  selector:\n    component: zeppelin\n  template:\n    metadata:\n      labels:\n        component: zeppelin\n    spec:\n      containers:\n      - name: zeppelin\n        image: registry.k8s.io/zeppelin:v0.5.6_v1\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-sk2ro5\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-8l432r\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2907bhgv.yaml: (object: <no namespace>/zeppelin-controller /v1, Kind=ReplicationController) container \"zeppelin\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2907bhgv.yaml: (object: <no namespace>/zeppelin-controller /v1, Kind=ReplicationController) container \"zeppelin\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2907bhgv.yaml: (object: <no namespace>/zeppelin-controller /v1, Kind=ReplicationController) container \"zeppelin\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/redis/redis-master.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: redis\n    redis-sentinel: 'true'\n    role: master\n  name: redis-master\nspec:\n  containers:\n  - name: master\n    image: registry.k8s.io/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    resources:\n      limits:\n        cpu: '0.1'\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: data\n    securityContext:\n      privileged: true\n  - name: sentinel\n    image: registry.k8s.io/redis:v1\n    env:\n    - name: SENTINEL\n      value: 'true'\n    ports:\n    - containerPort: 26379\n  volumes:\n  - name: data\n    emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6dfpdzap.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6dfpdzap.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"sentinel\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6dfpdzap.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"master\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6dfpdzap.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"master\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6dfpdzap.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6dfpdzap.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"sentinel\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6dfpdzap.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6dfpdzap.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6dfpdzap.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6dfpdzap.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 10 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/redis/redis-master.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: redis\n    redis-sentinel: 'true'\n    role: master\n  name: redis-master\nspec:\n  containers:\n  - name: master\n    image: registry.k8s.io/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: data\n  - name: sentinel\n    image: registry.k8s.io/redis:v1\n    env:\n    - name: SENTINEL\n      value: 'true'\n    ports:\n    - containerPort: 26379\n  volumes:\n  - name: data\n    emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7k51ngd6.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7k51ngd6.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"sentinel\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7k51ngd6.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7k51ngd6.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"sentinel\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7k51ngd6.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7k51ngd6.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7k51ngd6.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7k51ngd6.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/redis/redis-master.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: redis\n    redis-sentinel: 'true'\n    role: master\n  name: redis-master\nspec:\n  containers:\n  - name: master\n    image: registry.k8s.io/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    resources:\n      limits:\n        cpu: '0.1'\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: data\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-p8lxfc\n  - name: sentinel\n    image: registry.k8s.io/redis:v1\n    env:\n    - name: SENTINEL\n      value: 'true'\n    ports:\n    - containerPort: 26379\n  volumes:\n  - name: data\n    emptyDir: {}\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-f4zo2a\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprgarirsb.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprgarirsb.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"sentinel\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprgarirsb.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprgarirsb.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"sentinel\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprgarirsb.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprgarirsb.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprgarirsb.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprgarirsb.yaml: (object: <no namespace>/redis-master /v1, Kind=Pod) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/mysql-wordpress-pd/wordpress-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wordpress\n  labels:\n    app: wordpress\nspec:\n  selector:\n    matchLabels:\n      app: wordpress\n      tier: frontend\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app: wordpress\n        tier: frontend\n    spec:\n      containers:\n      - image: wordpress:6.2.1-apache\n        name: wordpress\n        env:\n        - name: WORDPRESS_DB_HOST\n          value: wordpress-mysql\n        - name: WORDPRESS_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-pass\n              key: password\n        - name: WORDPRESS_DB_USER\n          value: wordpress\n        ports:\n        - containerPort: 80\n          name: wordpress\n        volumeMounts:\n        - name: wordpress-persistent-storage\n          mountPath: /var/www/html\n        securityContext:\n          privileged: true\n      volumes:\n      - name: wordpress-persistent-storage\n        persistentVolumeClaim:\n          claimName: wp-pv-claim\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0a2hdhen.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0a2hdhen.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0a2hdhen.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0a2hdhen.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0a2hdhen.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0a2hdhen.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/mysql-wordpress-pd/wordpress-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wordpress\n  labels:\n    app: wordpress\nspec:\n  selector:\n    matchLabels:\n      app: wordpress\n      tier: frontend\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app: wordpress\n        tier: frontend\n    spec:\n      containers:\n      - image: wordpress:6.2.1-apache\n        name: wordpress\n        env:\n        - name: WORDPRESS_DB_HOST\n          value: wordpress-mysql\n        - name: WORDPRESS_DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-pass\n              key: password\n        - name: WORDPRESS_DB_USER\n          value: wordpress\n        ports:\n        - containerPort: 80\n          name: wordpress\n        volumeMounts:\n        - name: wordpress-persistent-storage\n          mountPath: /var/www/html\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-8mjzsh\n      volumes:\n      - name: wordpress-persistent-storage\n        persistentVolumeClaim:\n          claimName: wp-pv-claim\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-vl9taf\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt_3bm1nc.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt_3bm1nc.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt_3bm1nc.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt_3bm1nc.yaml: (object: <no namespace>/wordpress apps/v1, Kind=Deployment) container \"wordpress\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/openshift-origin/openshift-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    name: openshift\n  name: openshift\nspec:\n  selector:\n    matchLabels:\n      name: openshift\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: openshift\n    spec:\n      containers:\n      - args:\n        - start\n        - master\n        - --config=/config/master-config.yaml\n        image: openshift/origin\n        name: origin\n        ports:\n        - containerPort: 8443\n          name: openshift\n        volumeMounts:\n        - mountPath: /config\n          name: config\n          readOnly: true\n        securityContext:\n          privileged: true\n      volumes:\n      - name: config\n        secret:\n          secretName: openshift-config\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5hxvg93u.yaml: (object: <no namespace>/openshift apps/v1, Kind=Deployment) The container \"origin\" is using an invalid container image, \"openshift/origin\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5hxvg93u.yaml: (object: <no namespace>/openshift apps/v1, Kind=Deployment) container \"origin\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5hxvg93u.yaml: (object: <no namespace>/openshift apps/v1, Kind=Deployment) container \"origin\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5hxvg93u.yaml: (object: <no namespace>/openshift apps/v1, Kind=Deployment) container \"origin\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5hxvg93u.yaml: (object: <no namespace>/openshift apps/v1, Kind=Deployment) container \"origin\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5hxvg93u.yaml: (object: <no namespace>/openshift apps/v1, Kind=Deployment) container \"origin\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5hxvg93u.yaml: (object: <no namespace>/openshift apps/v1, Kind=Deployment) container \"origin\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/openshift-origin/openshift-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    name: openshift\n  name: openshift\nspec:\n  selector:\n    matchLabels:\n      name: openshift\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: openshift\n    spec:\n      containers:\n      - args:\n        - start\n        - master\n        - --config=/config/master-config.yaml\n        image: openshift/origin\n        name: origin\n        ports:\n        - containerPort: 8443\n          name: openshift\n        volumeMounts:\n        - mountPath: /config\n          name: config\n          readOnly: true\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-3gvjp6\n      volumes:\n      - name: config\n        secret:\n          secretName: openshift-config\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-q08y9o\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnvus9bjm.yaml: (object: <no namespace>/openshift apps/v1, Kind=Deployment) The container \"origin\" is using an invalid container image, \"openshift/origin\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnvus9bjm.yaml: (object: <no namespace>/openshift apps/v1, Kind=Deployment) container \"origin\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnvus9bjm.yaml: (object: <no namespace>/openshift apps/v1, Kind=Deployment) container \"origin\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnvus9bjm.yaml: (object: <no namespace>/openshift apps/v1, Kind=Deployment) container \"origin\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnvus9bjm.yaml: (object: <no namespace>/openshift apps/v1, Kind=Deployment) container \"origin\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/openshift-origin/etcd-discovery-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etcd-discovery\nspec:\n  selector:\n    matchLabels:\n      name: etcd-discovery\n  strategy:\n    type: Recreate\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: etcd-discovery\n    spec:\n      containers:\n      - name: discovery\n        image: openshift/etcd-20-centos7\n        args:\n        - etcd-discovery.sh\n        ports:\n        - containerPort: 2379\n          protocol: TCP\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          capabilities: {}\n          privileged: true\n      restartPolicy: Always\n      dnsPolicy: ClusterFirst\n      serviceAccount: ''\nstatus: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9k6jweod.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9k6jweod.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) The container \"discovery\" is using an invalid container image, \"openshift/etcd-20-centos7\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9k6jweod.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9k6jweod.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9k6jweod.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9k6jweod.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9k6jweod.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9k6jweod.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/openshift-origin/etcd-discovery-controller.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etcd-discovery\nspec:\n  selector:\n    matchLabels:\n      name: etcd-discovery\n  strategy:\n    type: Recreate\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: etcd-discovery\n    spec:\n      containers:\n      - name: discovery\n        image: openshift/etcd-20-centos7\n        args:\n        - etcd-discovery.sh\n        ports:\n        - containerPort: 2379\n          protocol: TCP\n        terminationMessagePath: /dev/termination-log\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          capabilities: {}\n          privileged: false\n      restartPolicy: Always\n      dnsPolicy: ClusterFirst\n      serviceAccount: ''\nstatus: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpm7_469vw.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpm7_469vw.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) The container \"discovery\" is using an invalid container image, \"openshift/etcd-20-centos7\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpm7_469vw.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpm7_469vw.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpm7_469vw.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpm7_469vw.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/openshift-origin/etcd-discovery-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etcd-discovery\nspec:\n  selector:\n    matchLabels:\n      name: etcd-discovery\n  strategy:\n    type: Recreate\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: etcd-discovery\n    spec:\n      containers:\n      - name: discovery\n        image: openshift/etcd-20-centos7\n        args:\n        - etcd-discovery.sh\n        ports:\n        - containerPort: 2379\n          protocol: TCP\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          capabilities: {}\n          privileged: false\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-06v5yq\n      restartPolicy: Always\n      dnsPolicy: ClusterFirst\n      serviceAccount: ''\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-oig1ar\n          type: DirectoryOrCreate\nstatus: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7rvwtz4w.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7rvwtz4w.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) The container \"discovery\" is using an invalid container image, \"openshift/etcd-20-centos7\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7rvwtz4w.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7rvwtz4w.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7rvwtz4w.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7rvwtz4w.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/openshift-origin/etcd-discovery-controller.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etcd-discovery\nspec:\n  selector:\n    matchLabels:\n      name: etcd-discovery\n  strategy:\n    type: Recreate\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: etcd-discovery\n    spec:\n      containers:\n      - name: discovery\n        image: openshift/etcd-20-centos7\n        args:\n        - etcd-discovery.sh\n        ports:\n        - containerPort: 2379\n          protocol: TCP\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        imagePullPolicy: IfNotPresent\n      restartPolicy: Always\n      dnsPolicy: ClusterFirst\n      serviceAccount: ''\nstatus: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgvy6lz60.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) The container \"discovery\" is using an invalid container image, \"openshift/etcd-20-centos7\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgvy6lz60.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgvy6lz60.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgvy6lz60.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgvy6lz60.yaml: (object: <no namespace>/etcd-discovery apps/v1, Kind=Deployment) container \"discovery\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/vsphere/deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: deployment\nspec:\n  selector:\n    matchLabels:\n      app: redis\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis\n        volumeMounts:\n        - name: vmfs-vmdk-storage\n          mountPath: /data/\n        securityContext:\n          privileged: true\n      volumes:\n      - name: vmfs-vmdk-storage\n        vsphereVolume:\n          volumePath: '[Datastore] volumes/testdir'\n          fsType: ext4\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpoe_q1sc0.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) The container \"redis\" is using an invalid container image, \"redis\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpoe_q1sc0.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpoe_q1sc0.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpoe_q1sc0.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpoe_q1sc0.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpoe_q1sc0.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpoe_q1sc0.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/vsphere/deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: deployment\nspec:\n  selector:\n    matchLabels:\n      app: redis\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis\n        volumeMounts:\n        - name: vmfs-vmdk-storage\n          mountPath: /data/\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-x0cpbc\n      volumes:\n      - name: vmfs-vmdk-storage\n        vsphereVolume:\n          volumePath: '[Datastore] volumes/testdir'\n          fsType: ext4\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-j78ws0\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkfgdpany.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) The container \"redis\" is using an invalid container image, \"redis\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkfgdpany.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkfgdpany.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkfgdpany.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkfgdpany.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/frontend-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google-samples/gb-frontend:v5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphksob2tn.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphksob2tn.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphksob2tn.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphksob2tn.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphksob2tn.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphksob2tn.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/frontend-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google-samples/gb-frontend:v5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-e4j7fj\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-lmtwf9\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpn49lwh1w.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpn49lwh1w.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpn49lwh1w.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpn49lwh1w.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/azure_disk/azure.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: azure\nspec:\n  containers:\n  - image: kubernetes/pause\n    name: azure\n    volumeMounts:\n    - name: azure\n      mountPath: /mnt/azure\n    securityContext:\n      privileged: true\n  volumes:\n  - name: azure\n    azureDisk:\n      diskName: test.vhd\n      diskURI: https://someaccount.blob.microsoft.net/vhds/test.vhd\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_fwzv78x.yaml: (object: <no namespace>/azure /v1, Kind=Pod) The container \"azure\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_fwzv78x.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_fwzv78x.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_fwzv78x.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_fwzv78x.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_fwzv78x.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_fwzv78x.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/azure_disk/azure.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: azure\nspec:\n  containers:\n  - image: kubernetes/pause\n    name: azure\n    volumeMounts:\n    - name: azure\n      mountPath: /mnt/azure\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-qjwj5a\n  volumes:\n  - name: azure\n    azureDisk:\n      diskName: test.vhd\n      diskURI: https://someaccount.blob.microsoft.net/vhds/test.vhd\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-b3xp70\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3ze43r3a.yaml: (object: <no namespace>/azure /v1, Kind=Pod) The container \"azure\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3ze43r3a.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3ze43r3a.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3ze43r3a.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3ze43r3a.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/volumes/storageos/storageos-pvcpod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: redis\n    role: master\n  name: test-storageos-redis-pvc\nspec:\n  containers:\n  - name: master\n    image: kubernetes/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    resources:\n      limits:\n        cpu: '0.1'\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: redis-data\n    securityContext:\n      privileged: true\n  volumes:\n  - name: redis-data\n    persistentVolumeClaim:\n      claimName: pvc0001\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpp74vhbgn.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpp74vhbgn.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpp74vhbgn.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpp74vhbgn.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpp74vhbgn.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpp74vhbgn.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/volumes/storageos/storageos-pvcpod.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: redis\n    role: master\n  name: test-storageos-redis-pvc\nspec:\n  containers:\n  - name: master\n    image: kubernetes/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: redis-data\n  volumes:\n  - name: redis-data\n    persistentVolumeClaim:\n      claimName: pvc0001\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5pegtzud.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5pegtzud.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5pegtzud.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5pegtzud.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/volumes/storageos/storageos-pvcpod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: redis\n    role: master\n  name: test-storageos-redis-pvc\nspec:\n  containers:\n  - name: master\n    image: kubernetes/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    resources:\n      limits:\n        cpu: '0.1'\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: redis-data\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-3qemuc\n  volumes:\n  - name: redis-data\n    persistentVolumeClaim:\n      claimName: pvc0001\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-x6dkyz\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz1bgh93z.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz1bgh93z.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz1bgh93z.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz1bgh93z.yaml: (object: <no namespace>/test-storageos-redis-pvc /v1, Kind=Pod) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/legacy/redis-master-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: redis-master\n  labels:\n    app: redis\n    role: master\n    tier: backend\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: master\n        tier: backend\n    spec:\n      containers:\n      - name: master\n        image: registry.k8s.io/redis:e2e\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 6379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptgc9x012.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptgc9x012.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"master\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptgc9x012.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"master\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptgc9x012.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptgc9x012.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/legacy/redis-master-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: redis-master\n  labels:\n    app: redis\n    role: master\n    tier: backend\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: master\n        tier: backend\n    spec:\n      containers:\n      - name: master\n        image: registry.k8s.io/redis:e2e\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 6379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-akv2fo\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-yj0zc1\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppksufvk9.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppksufvk9.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppksufvk9.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/scaleio/pod-sc-pvc.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-sio-small\nspec:\n  containers:\n  - name: pod-sio-small-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - mountPath: /test\n      name: test-data\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test-data\n    persistentVolumeClaim:\n      claimName: pvc-sio-small\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptf9kbii3.yaml: (object: <no namespace>/pod-sio-small /v1, Kind=Pod) The container \"pod-sio-small-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptf9kbii3.yaml: (object: <no namespace>/pod-sio-small /v1, Kind=Pod) container \"pod-sio-small-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptf9kbii3.yaml: (object: <no namespace>/pod-sio-small /v1, Kind=Pod) container \"pod-sio-small-container\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptf9kbii3.yaml: (object: <no namespace>/pod-sio-small /v1, Kind=Pod) container \"pod-sio-small-container\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptf9kbii3.yaml: (object: <no namespace>/pod-sio-small /v1, Kind=Pod) container \"pod-sio-small-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptf9kbii3.yaml: (object: <no namespace>/pod-sio-small /v1, Kind=Pod) container \"pod-sio-small-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptf9kbii3.yaml: (object: <no namespace>/pod-sio-small /v1, Kind=Pod) container \"pod-sio-small-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/scaleio/pod-sc-pvc.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-sio-small\nspec:\n  containers:\n  - name: pod-sio-small-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - mountPath: /test\n      name: test-data\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-ncts43\n  volumes:\n  - name: test-data\n    persistentVolumeClaim:\n      claimName: pvc-sio-small\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-pt6vky\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3tk583fl.yaml: (object: <no namespace>/pod-sio-small /v1, Kind=Pod) The container \"pod-sio-small-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3tk583fl.yaml: (object: <no namespace>/pod-sio-small /v1, Kind=Pod) container \"pod-sio-small-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3tk583fl.yaml: (object: <no namespace>/pod-sio-small /v1, Kind=Pod) container \"pod-sio-small-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3tk583fl.yaml: (object: <no namespace>/pod-sio-small /v1, Kind=Pod) container \"pod-sio-small-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3tk583fl.yaml: (object: <no namespace>/pod-sio-small /v1, Kind=Pod) container \"pod-sio-small-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/azure_file/azure.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: azure\nspec:\n  containers:\n  - image: kubernetes/pause\n    name: azure\n    volumeMounts:\n    - name: azure\n      mountPath: /mnt/azure\n    securityContext:\n      privileged: true\n  volumes:\n  - name: azure\n    azureFile:\n      secretName: azure-secret\n      shareName: k8stest\n      readOnly: false\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_6nh1g7e.yaml: (object: <no namespace>/azure /v1, Kind=Pod) The container \"azure\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_6nh1g7e.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_6nh1g7e.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_6nh1g7e.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_6nh1g7e.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_6nh1g7e.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_6nh1g7e.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/azure_file/azure.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: azure\nspec:\n  containers:\n  - image: kubernetes/pause\n    name: azure\n    volumeMounts:\n    - name: azure\n      mountPath: /mnt/azure\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-77y7or\n  volumes:\n  - name: azure\n    azureFile:\n      secretName: azure-secret\n      shareName: k8stest\n      readOnly: false\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-355k2k\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9kygic6i.yaml: (object: <no namespace>/azure /v1, Kind=Pod) The container \"azure\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9kygic6i.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9kygic6i.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9kygic6i.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9kygic6i.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/cassandra/cassandra-statefulset.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: cassandra\n  labels:\n    app: cassandra\nspec:\n  serviceName: cassandra\n  replicas: 3\n  selector:\n    matchLabels:\n      app: cassandra\n  template:\n    metadata:\n      labels:\n        app: cassandra\n    spec:\n      terminationGracePeriodSeconds: 1800\n      containers:\n      - name: cassandra\n        image: gcr.io/google-samples/cassandra:v14\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 7000\n          name: intra-node\n        - containerPort: 7001\n          name: tls-intra-node\n        - containerPort: 7199\n          name: jmx\n        - containerPort: 9042\n          name: cql\n        resources:\n          limits:\n            cpu: 500m\n            memory: 1Gi\n          requests:\n            cpu: 500m\n            memory: 1Gi\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n          privileged: true\n        lifecycle:\n          preStop:\n            exec:\n              command:\n              - /bin/sh\n              - -c\n              - nodetool drain\n        env:\n        - name: MAX_HEAP_SIZE\n          value: 512M\n        - name: HEAP_NEWSIZE\n          value: 100M\n        - name: CASSANDRA_SEEDS\n          value: cassandra-0.cassandra.default.svc.cluster.local\n        - name: CASSANDRA_CLUSTER_NAME\n          value: K8Demo\n        - name: CASSANDRA_DC\n          value: DC1-K8Demo\n        - name: CASSANDRA_RACK\n          value: Rack1-K8Demo\n        - name: CASSANDRA_SEED_PROVIDER\n          value: io.k8s.cassandra.KubernetesSeedProvider\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        readinessProbe:\n          exec:\n            command:\n            - /bin/bash\n            - -c\n            - /ready-probe.sh\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          periodSeconds: 10\n          failureThreshold: 3\n        livenessProbe:\n          exec:\n            command:\n            - /bin/bash\n            - -c\n            - nodetool status\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          periodSeconds: 10\n          failureThreshold: 3\n        volumeMounts:\n        - name: cassandra-data\n          mountPath: /var/lib/cassandra\n  volumeClaimTemplates:\n  - metadata:\n      name: cassandra-data\n      annotations:\n        volume.beta.kubernetes.io/storage-class: fast\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 1Gi\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmw8gncd9.yaml: (object: <no namespace>/cassandra apps/v1, Kind=StatefulSet) container \"cassandra\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmw8gncd9.yaml: (object: <no namespace>/cassandra apps/v1, Kind=StatefulSet) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmw8gncd9.yaml: (object: <no namespace>/cassandra apps/v1, Kind=StatefulSet) container \"cassandra\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmw8gncd9.yaml: (object: <no namespace>/cassandra apps/v1, Kind=StatefulSet) container \"cassandra\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmw8gncd9.yaml: (object: <no namespace>/cassandra apps/v1, Kind=StatefulSet) container \"cassandra\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmw8gncd9.yaml: (object: <no namespace>/cassandra apps/v1, Kind=StatefulSet) container \"cassandra\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/cassandra/cassandra-statefulset.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: cassandra\n  labels:\n    app: cassandra\nspec:\n  serviceName: cassandra\n  replicas: 3\n  selector:\n    matchLabels:\n      app: cassandra\n  template:\n    metadata:\n      labels:\n        app: cassandra\n    spec:\n      terminationGracePeriodSeconds: 1800\n      containers:\n      - name: cassandra\n        image: gcr.io/google-samples/cassandra:v14\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 7000\n          name: intra-node\n        - containerPort: 7001\n          name: tls-intra-node\n        - containerPort: 7199\n          name: jmx\n        - containerPort: 9042\n          name: cql\n        resources:\n          requests:\n            cpu: 500m\n            memory: 1Gi\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n        lifecycle:\n          preStop:\n            exec:\n              command:\n              - /bin/sh\n              - -c\n              - nodetool drain\n        env:\n        - name: MAX_HEAP_SIZE\n          value: 512M\n        - name: HEAP_NEWSIZE\n          value: 100M\n        - name: CASSANDRA_SEEDS\n          value: cassandra-0.cassandra.default.svc.cluster.local\n        - name: CASSANDRA_CLUSTER_NAME\n          value: K8Demo\n        - name: CASSANDRA_DC\n          value: DC1-K8Demo\n        - name: CASSANDRA_RACK\n          value: Rack1-K8Demo\n        - name: CASSANDRA_SEED_PROVIDER\n          value: io.k8s.cassandra.KubernetesSeedProvider\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        readinessProbe:\n          exec:\n            command:\n            - /bin/bash\n            - -c\n            - /ready-probe.sh\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          periodSeconds: 10\n          failureThreshold: 3\n        livenessProbe:\n          exec:\n            command:\n            - /bin/bash\n            - -c\n            - nodetool status\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          periodSeconds: 10\n          failureThreshold: 3\n        volumeMounts:\n        - name: cassandra-data\n          mountPath: /var/lib/cassandra\n  volumeClaimTemplates:\n  - metadata:\n      name: cassandra-data\n      annotations:\n        volume.beta.kubernetes.io/storage-class: fast\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 1Gi\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6udwqrv4.yaml: (object: <no namespace>/cassandra apps/v1, Kind=StatefulSet) container \"cassandra\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6udwqrv4.yaml: (object: <no namespace>/cassandra apps/v1, Kind=StatefulSet) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6udwqrv4.yaml: (object: <no namespace>/cassandra apps/v1, Kind=StatefulSet) container \"cassandra\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6udwqrv4.yaml: (object: <no namespace>/cassandra apps/v1, Kind=StatefulSet) container \"cassandra\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6udwqrv4.yaml: (object: <no namespace>/cassandra apps/v1, Kind=StatefulSet) container \"cassandra\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/cassandra/cassandra-statefulset.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: cassandra\n  labels:\n    app: cassandra\nspec:\n  serviceName: cassandra\n  replicas: 3\n  selector:\n    matchLabels:\n      app: cassandra\n  template:\n    metadata:\n      labels:\n        app: cassandra\n    spec:\n      terminationGracePeriodSeconds: 1800\n      containers:\n      - name: cassandra\n        image: gcr.io/google-samples/cassandra:v14\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 7000\n          name: intra-node\n        - containerPort: 7001\n          name: tls-intra-node\n        - containerPort: 7199\n          name: jmx\n        - containerPort: 9042\n          name: cql\n        resources:\n          limits:\n            cpu: 500m\n            memory: 1Gi\n          requests:\n            cpu: 500m\n            memory: 1Gi\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n        lifecycle:\n          preStop:\n            exec:\n              command:\n              - /bin/sh\n              - -c\n              - nodetool drain\n        env:\n        - name: MAX_HEAP_SIZE\n          value: 512M\n        - name: HEAP_NEWSIZE\n          value: 100M\n        - name: CASSANDRA_SEEDS\n          value: cassandra-0.cassandra.default.svc.cluster.local\n        - name: CASSANDRA_CLUSTER_NAME\n          value: K8Demo\n        - name: CASSANDRA_DC\n          value: DC1-K8Demo\n        - name: CASSANDRA_RACK\n          value: Rack1-K8Demo\n        - name: CASSANDRA_SEED_PROVIDER\n          value: io.k8s.cassandra.KubernetesSeedProvider\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        readinessProbe:\n          exec:\n            command:\n            - /bin/bash\n            - -c\n            - /ready-probe.sh\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          periodSeconds: 10\n          failureThreshold: 3\n        livenessProbe:\n          exec:\n            command:\n            - /bin/bash\n            - -c\n            - nodetool status\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          periodSeconds: 10\n          failureThreshold: 3\n        volumeMounts:\n        - name: cassandra-data\n          mountPath: /var/lib/cassandra\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-iezeyh\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-ya26oq\n          type: DirectoryOrCreate\n  volumeClaimTemplates:\n  - metadata:\n      name: cassandra-data\n      annotations:\n        volume.beta.kubernetes.io/storage-class: fast\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 1Gi\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9qak1gpp.yaml: (object: <no namespace>/cassandra apps/v1, Kind=StatefulSet) container \"cassandra\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9qak1gpp.yaml: (object: <no namespace>/cassandra apps/v1, Kind=StatefulSet) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9qak1gpp.yaml: (object: <no namespace>/cassandra apps/v1, Kind=StatefulSet) container \"cassandra\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9qak1gpp.yaml: (object: <no namespace>/cassandra apps/v1, Kind=StatefulSet) container \"cassandra\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/cassandra/cassandra-statefulset.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: cassandra\n  labels:\n    app: cassandra\nspec:\n  serviceName: cassandra\n  replicas: 3\n  selector:\n    matchLabels:\n      app: cassandra\n  template:\n    metadata:\n      labels:\n        app: cassandra\n    spec:\n      terminationGracePeriodSeconds: 1800\n      containers:\n      - name: cassandra\n        image: gcr.io/google-samples/cassandra:v14\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 7000\n          name: intra-node\n        - containerPort: 7001\n          name: tls-intra-node\n        - containerPort: 7199\n          name: jmx\n        - containerPort: 9042\n          name: cql\n        resources:\n          limits:\n            cpu: 500m\n            memory: 1Gi\n          requests:\n            cpu: 500m\n            memory: 1Gi\n        lifecycle:\n          preStop:\n            exec:\n              command:\n              - /bin/sh\n              - -c\n              - nodetool drain\n        env:\n        - name: MAX_HEAP_SIZE\n          value: 512M\n        - name: HEAP_NEWSIZE\n          value: 100M\n        - name: CASSANDRA_SEEDS\n          value: cassandra-0.cassandra.default.svc.cluster.local\n        - name: CASSANDRA_CLUSTER_NAME\n          value: K8Demo\n        - name: CASSANDRA_DC\n          value: DC1-K8Demo\n        - name: CASSANDRA_RACK\n          value: Rack1-K8Demo\n        - name: CASSANDRA_SEED_PROVIDER\n          value: io.k8s.cassandra.KubernetesSeedProvider\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        readinessProbe:\n          exec:\n            command:\n            - /bin/bash\n            - -c\n            - /ready-probe.sh\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          periodSeconds: 10\n          failureThreshold: 3\n        livenessProbe:\n          exec:\n            command:\n            - /bin/bash\n            - -c\n            - nodetool status\n          initialDelaySeconds: 15\n          timeoutSeconds: 5\n          periodSeconds: 10\n          failureThreshold: 3\n        volumeMounts:\n        - name: cassandra-data\n          mountPath: /var/lib/cassandra\n  volumeClaimTemplates:\n  - metadata:\n      name: cassandra-data\n      annotations:\n        volume.beta.kubernetes.io/storage-class: fast\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 1Gi\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplkx5rqcp.yaml: (object: <no namespace>/cassandra apps/v1, Kind=StatefulSet) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplkx5rqcp.yaml: (object: <no namespace>/cassandra apps/v1, Kind=StatefulSet) container \"cassandra\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplkx5rqcp.yaml: (object: <no namespace>/cassandra apps/v1, Kind=StatefulSet) container \"cassandra\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/mysql-galera/pxc-node1.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: pxc-node1\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        node: pxc-node1\n        unit: pxc-cluster\n    spec:\n      containers:\n      - resources:\n          limits:\n            cpu: 0.3\n        image: capttofu/percona_xtradb_cluster_5_6:beta\n        name: pxc-node1\n        ports:\n        - containerPort: 3306\n        - containerPort: 4444\n        - containerPort: 4567\n        - containerPort: 4568\n        env:\n        - name: GALERA_CLUSTER\n          value: 'true'\n        - name: WSREP_CLUSTER_ADDRESS\n          value: gcomm://\n        - name: WSREP_SST_USER\n          value: sst\n        - name: WSREP_SST_PASSWORD\n          value: sst\n        - name: MYSQL_USER\n          value: mysql\n        - name: MYSQL_PASSWORD\n          value: mysql\n        - name: MYSQL_ROOT_PASSWORD\n          value: c-krit\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2z7h924x.yaml: (object: <no namespace>/pxc-node1 /v1, Kind=ReplicationController) container \"pxc-node1\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2z7h924x.yaml: (object: <no namespace>/pxc-node1 /v1, Kind=ReplicationController) container \"pxc-node1\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2z7h924x.yaml: (object: <no namespace>/pxc-node1 /v1, Kind=ReplicationController) container \"pxc-node1\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2z7h924x.yaml: (object: <no namespace>/pxc-node1 /v1, Kind=ReplicationController) container \"pxc-node1\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2z7h924x.yaml: (object: <no namespace>/pxc-node1 /v1, Kind=ReplicationController) container \"pxc-node1\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2z7h924x.yaml: (object: <no namespace>/pxc-node1 /v1, Kind=ReplicationController) container \"pxc-node1\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/mysql-galera/pxc-node1.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: pxc-node1\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        node: pxc-node1\n        unit: pxc-cluster\n    spec:\n      containers:\n      - image: capttofu/percona_xtradb_cluster_5_6:beta\n        name: pxc-node1\n        ports:\n        - containerPort: 3306\n        - containerPort: 4444\n        - containerPort: 4567\n        - containerPort: 4568\n        env:\n        - name: GALERA_CLUSTER\n          value: 'true'\n        - name: WSREP_CLUSTER_ADDRESS\n          value: gcomm://\n        - name: WSREP_SST_USER\n          value: sst\n        - name: WSREP_SST_PASSWORD\n          value: sst\n        - name: MYSQL_USER\n          value: mysql\n        - name: MYSQL_PASSWORD\n          value: mysql\n        - name: MYSQL_ROOT_PASSWORD\n          value: c-krit\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnfpovkne.yaml: (object: <no namespace>/pxc-node1 /v1, Kind=ReplicationController) container \"pxc-node1\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnfpovkne.yaml: (object: <no namespace>/pxc-node1 /v1, Kind=ReplicationController) container \"pxc-node1\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnfpovkne.yaml: (object: <no namespace>/pxc-node1 /v1, Kind=ReplicationController) container \"pxc-node1\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnfpovkne.yaml: (object: <no namespace>/pxc-node1 /v1, Kind=ReplicationController) container \"pxc-node1\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/mysql-galera/pxc-node1.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: pxc-node1\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        node: pxc-node1\n        unit: pxc-cluster\n    spec:\n      containers:\n      - resources:\n          limits:\n            cpu: 0.3\n        image: capttofu/percona_xtradb_cluster_5_6:beta\n        name: pxc-node1\n        ports:\n        - containerPort: 3306\n        - containerPort: 4444\n        - containerPort: 4567\n        - containerPort: 4568\n        env:\n        - name: GALERA_CLUSTER\n          value: 'true'\n        - name: WSREP_CLUSTER_ADDRESS\n          value: gcomm://\n        - name: WSREP_SST_USER\n          value: sst\n        - name: WSREP_SST_PASSWORD\n          value: sst\n        - name: MYSQL_USER\n          value: mysql\n        - name: MYSQL_PASSWORD\n          value: mysql\n        - name: MYSQL_ROOT_PASSWORD\n          value: c-krit\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-d1mgxz\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-2e5d7i\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpflyrwbav.yaml: (object: <no namespace>/pxc-node1 /v1, Kind=ReplicationController) container \"pxc-node1\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpflyrwbav.yaml: (object: <no namespace>/pxc-node1 /v1, Kind=ReplicationController) container \"pxc-node1\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpflyrwbav.yaml: (object: <no namespace>/pxc-node1 /v1, Kind=ReplicationController) container \"pxc-node1\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpflyrwbav.yaml: (object: <no namespace>/pxc-node1 /v1, Kind=ReplicationController) container \"pxc-node1\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/hazelcast/hazelcast-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hazelcast\n  labels:\n    name: hazelcast\nspec:\n  selector:\n    matchLabels:\n      name: hazelcast\n  template:\n    metadata:\n      labels:\n        name: hazelcast\n    spec:\n      containers:\n      - name: hazelcast\n        image: quay.io/pires/hazelcast-kubernetes:3.8_1\n        imagePullPolicy: Always\n        env:\n        - name: DNS_DOMAIN\n          value: cluster.local\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - name: hazelcast\n          containerPort: 5701\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgiwpjq5t.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgiwpjq5t.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgiwpjq5t.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgiwpjq5t.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgiwpjq5t.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgiwpjq5t.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/hazelcast/hazelcast-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hazelcast\n  labels:\n    name: hazelcast\nspec:\n  selector:\n    matchLabels:\n      name: hazelcast\n  template:\n    metadata:\n      labels:\n        name: hazelcast\n    spec:\n      containers:\n      - name: hazelcast\n        image: quay.io/pires/hazelcast-kubernetes:3.8_1\n        imagePullPolicy: Always\n        env:\n        - name: DNS_DOMAIN\n          value: cluster.local\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - name: hazelcast\n          containerPort: 5701\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-o85rdj\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-5oea73\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpazzy7mgy.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpazzy7mgy.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpazzy7mgy.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpazzy7mgy.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cluster-dns/dns-frontend-pod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dns-frontend\n  labels:\n    name: dns-frontend\nspec:\n  containers:\n  - name: dns-frontend\n    image: registry.k8s.io/example-dns-frontend:v1\n    command:\n    - python\n    - client.py\n    - http://dns-backend.development.svc.cluster.local:8000\n    imagePullPolicy: Always\n    securityContext:\n      privileged: true\n  restartPolicy: Never\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3aoufla4.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3aoufla4.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3aoufla4.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3aoufla4.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3aoufla4.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3aoufla4.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cluster-dns/dns-frontend-pod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dns-frontend\n  labels:\n    name: dns-frontend\nspec:\n  containers:\n  - name: dns-frontend\n    image: registry.k8s.io/example-dns-frontend:v1\n    command:\n    - python\n    - client.py\n    - http://dns-backend.development.svc.cluster.local:8000\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-57ey9u\n  restartPolicy: Never\n  volumes:\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-6vcojd\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfxsedbbg.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfxsedbbg.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfxsedbbg.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfxsedbbg.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/legacy/frontend-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: frontend\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google_samples/gb-frontend:v4\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpriiditj6.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpriiditj6.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) container \"php-redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpriiditj6.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) container \"php-redis\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpriiditj6.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) container \"php-redis\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpriiditj6.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) container \"php-redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpriiditj6.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) container \"php-redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/legacy/frontend-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: frontend\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google_samples/gb-frontend:v4\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-sje8em\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-9qmliv\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6grx1qbf.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6grx1qbf.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) container \"php-redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6grx1qbf.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) container \"php-redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6grx1qbf.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) container \"php-redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook/all-in-one/frontend.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google-samples/gb-frontend:v5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpek627rre.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpek627rre.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpek627rre.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpek627rre.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpek627rre.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpek627rre.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook/all-in-one/frontend.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google-samples/gb-frontend:v5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-ii0o7c\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-9qdnpc\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9jxsiz19.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9jxsiz19.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9jxsiz19.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9jxsiz19.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cockroachdb/cockroachdb-statefulset.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: cockroachdb\n  labels:\n    app: cockroachdb\nspec:\n  serviceName: cockroachdb\n  replicas: 3\n  selector:\n    matchLabels:\n      app: cockroachdb\n  template:\n    metadata:\n      labels:\n        app: cockroachdb\n    spec:\n      initContainers:\n      - name: bootstrap\n        image: cockroachdb/cockroach-k8s-init:0.2\n        imagePullPolicy: IfNotPresent\n        args:\n        - -on-start=/on-start.sh\n        - -service=cockroachdb\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: datadir\n          mountPath: /cockroach/cockroach-data\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - cockroachdb\n              topologyKey: kubernetes.io/hostname\n      containers:\n      - name: cockroachdb\n        image: cockroachdb/cockroach:v1.1.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 26257\n          name: grpc\n        - containerPort: 8080\n          name: http\n        volumeMounts:\n        - name: datadir\n          mountPath: /cockroach/cockroach-data\n        command:\n        - /bin/bash\n        - -ecx\n        - \"# The use of qualified `hostname -f` is crucial:\\n# Other nodes aren't\\\n          \\ able to look up the unqualified hostname.\\nCRARGS=(\\\"start\\\" \\\"--logtostderr\\\"\\\n          \\ \\\"--insecure\\\" \\\"--host\\\" \\\"$(hostname -f)\\\" \\\"--http-host\\\" \\\"0.0.0.0\\\"\\\n          )\\n# We only want to initialize a new cluster (by omitting the join flag)\\n\\\n          # if we're sure that we're the first node (i.e. index 0) and that\\n# there\\\n          \\ aren't any other nodes running as part of the cluster that\\n# this is\\\n          \\ supposed to be a part of (which indicates that a cluster\\n# already exists\\\n          \\ and we should make sure not to create a new one).\\n# It's fine to run\\\n          \\ without --join on a restart if there aren't any\\n# other nodes.\\nif [\\\n          \\ ! \\\"$(hostname)\\\" == \\\"cockroachdb-0\\\" ] || \\\\\\n   [ -e \\\"/cockroach/cockroach-data/cluster_exists_marker\\\"\\\n          \\ ]\\nthen\\n  # We don't join cockroachdb in order to avoid a node attempting\\n\\\n          \\  # to join itself, which currently doesn't work\\n  # (https://github.com/cockroachdb/cockroach/issues/9625).\\n\\\n          \\  CRARGS+=(\\\"--join\\\" \\\"cockroachdb-public\\\")\\nfi\\nexec /cockroach/cockroach\\\n          \\ ${CRARGS[*]}\\n\"\n        securityContext:\n          privileged: true\n      terminationGracePeriodSeconds: 60\n      volumes:\n      - name: datadir\n        persistentVolumeClaim:\n          claimName: datadir\n  volumeClaimTemplates:\n  - metadata:\n      name: datadir\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 1Gi\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdxeplu8k.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"bootstrap\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdxeplu8k.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdxeplu8k.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdxeplu8k.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdxeplu8k.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"bootstrap\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdxeplu8k.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdxeplu8k.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"bootstrap\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdxeplu8k.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdxeplu8k.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"bootstrap\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdxeplu8k.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 10 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cockroachdb/cockroachdb-statefulset.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: cockroachdb\n  labels:\n    app: cockroachdb\nspec:\n  serviceName: cockroachdb\n  replicas: 3\n  selector:\n    matchLabels:\n      app: cockroachdb\n  template:\n    metadata:\n      labels:\n        app: cockroachdb\n    spec:\n      initContainers:\n      - name: bootstrap\n        image: cockroachdb/cockroach-k8s-init:0.2\n        imagePullPolicy: IfNotPresent\n        args:\n        - -on-start=/on-start.sh\n        - -service=cockroachdb\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: datadir\n          mountPath: /cockroach/cockroach-data\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - cockroachdb\n              topologyKey: kubernetes.io/hostname\n      containers:\n      - name: cockroachdb\n        image: cockroachdb/cockroach:v1.1.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 26257\n          name: grpc\n        - containerPort: 8080\n          name: http\n        volumeMounts:\n        - name: datadir\n          mountPath: /cockroach/cockroach-data\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-pygo68\n        command:\n        - /bin/bash\n        - -ecx\n        - \"# The use of qualified `hostname -f` is crucial:\\n# Other nodes aren't\\\n          \\ able to look up the unqualified hostname.\\nCRARGS=(\\\"start\\\" \\\"--logtostderr\\\"\\\n          \\ \\\"--insecure\\\" \\\"--host\\\" \\\"$(hostname -f)\\\" \\\"--http-host\\\" \\\"0.0.0.0\\\"\\\n          )\\n# We only want to initialize a new cluster (by omitting the join flag)\\n\\\n          # if we're sure that we're the first node (i.e. index 0) and that\\n# there\\\n          \\ aren't any other nodes running as part of the cluster that\\n# this is\\\n          \\ supposed to be a part of (which indicates that a cluster\\n# already exists\\\n          \\ and we should make sure not to create a new one).\\n# It's fine to run\\\n          \\ without --join on a restart if there aren't any\\n# other nodes.\\nif [\\\n          \\ ! \\\"$(hostname)\\\" == \\\"cockroachdb-0\\\" ] || \\\\\\n   [ -e \\\"/cockroach/cockroach-data/cluster_exists_marker\\\"\\\n          \\ ]\\nthen\\n  # We don't join cockroachdb in order to avoid a node attempting\\n\\\n          \\  # to join itself, which currently doesn't work\\n  # (https://github.com/cockroachdb/cockroach/issues/9625).\\n\\\n          \\  CRARGS+=(\\\"--join\\\" \\\"cockroachdb-public\\\")\\nfi\\nexec /cockroach/cockroach\\\n          \\ ${CRARGS[*]}\\n\"\n      terminationGracePeriodSeconds: 60\n      volumes:\n      - name: datadir\n        persistentVolumeClaim:\n          claimName: datadir\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-h44afq\n          type: DirectoryOrCreate\n  volumeClaimTemplates:\n  - metadata:\n      name: datadir\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 1Gi\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3wz_4z6f.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"bootstrap\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3wz_4z6f.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3wz_4z6f.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"bootstrap\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3wz_4z6f.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3wz_4z6f.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"bootstrap\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3wz_4z6f.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3wz_4z6f.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"bootstrap\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3wz_4z6f.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/kubebuilder-declarative-pattern/examples/guestbook-operator/config/default/manager_webhook_patch.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: controller-manager\n  namespace: system\nspec:\n  template:\n    spec:\n      containers:\n      - name: manager\n        ports:\n        - containerPort: 9443\n          name: webhook-server\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: cert\n          readOnly: true\n        securityContext:\n          privileged: true\n      volumes:\n      - name: cert\n        secret:\n          defaultMode: 420\n          secretName: webhook-server-cert\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_ejjlevn.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) The container \"manager\" is using an invalid container image, \"\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_ejjlevn.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) object has no selector specified (check: mismatching-selector, remediation: Confirm that your deployment selector correctly matches the labels in its pod template.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_ejjlevn.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_ejjlevn.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_ejjlevn.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_ejjlevn.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_ejjlevn.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_ejjlevn.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/kubebuilder-declarative-pattern/examples/guestbook-operator/config/default/manager_webhook_patch.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: controller-manager\n  namespace: system\nspec:\n  template:\n    spec:\n      containers:\n      - name: manager\n        ports:\n        - containerPort: 9443\n          name: webhook-server\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /tmp/k8s-webhook-server/serving-certs\n          name: cert\n          readOnly: true\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-a3k48x\n      volumes:\n      - name: cert\n        secret:\n          defaultMode: 420\n          secretName: webhook-server-cert\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-o6fryh\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp52_tlmh4.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) The container \"manager\" is using an invalid container image, \"\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp52_tlmh4.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) object has no selector specified (check: mismatching-selector, remediation: Confirm that your deployment selector correctly matches the labels in its pod template.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp52_tlmh4.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp52_tlmh4.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp52_tlmh4.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp52_tlmh4.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cpu-manager/exclusive-3.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-3\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-3\n    resources:\n      requests:\n        cpu: 3\n        memory: 256M\n      limits:\n        cpu: 3\n        memory: 256M\n    securityContext:\n      privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpn_2npaae.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) The container \"exclusive-3\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpn_2npaae.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) container \"exclusive-3\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpn_2npaae.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) container \"exclusive-3\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpn_2npaae.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) container \"exclusive-3\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpn_2npaae.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) container \"exclusive-3\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cpu-manager/exclusive-3.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-3\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-3\n    resources:\n      requests:\n        cpu: 3\n        memory: 256M\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpngduz7w2.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) The container \"exclusive-3\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpngduz7w2.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) container \"exclusive-3\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpngduz7w2.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) container \"exclusive-3\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpngduz7w2.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) container \"exclusive-3\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cpu-manager/exclusive-3.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-3\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-3\n    resources:\n      requests:\n        cpu: 3\n        memory: 256M\n      limits:\n        cpu: 3\n        memory: 256M\n    volumeMounts:\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-049hdo\n  volumes:\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-tv8mak\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwi_mlinz.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) The container \"exclusive-3\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwi_mlinz.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) container \"exclusive-3\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwi_mlinz.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) container \"exclusive-3\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/spark/spark-gluster/spark-master-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: spark-master-controller\n  namespace: spark-cluster\n  labels:\n    component: spark-master\nspec:\n  replicas: 1\n  selector:\n    component: spark-master\n  template:\n    metadata:\n      labels:\n        component: spark-master\n    spec:\n      containers:\n      - name: spark-master\n        image: registry.k8s.io/spark:1.5.2_v1\n        command:\n        - /start-master\n        ports:\n        - containerPort: 7077\n        volumeMounts:\n        - mountPath: /mnt/glusterfs\n          name: glusterfsvol\n        resources:\n          requests:\n            cpu: 100m\n        securityContext:\n          privileged: true\n      volumes:\n      - name: glusterfsvol\n        glusterfs:\n          endpoints: glusterfs-cluster\n          path: MyVolume\n          readOnly: false\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpadnwbj9i.yaml: (object: spark-cluster/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpadnwbj9i.yaml: (object: spark-cluster/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpadnwbj9i.yaml: (object: spark-cluster/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpadnwbj9i.yaml: (object: spark-cluster/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpadnwbj9i.yaml: (object: spark-cluster/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/spark/spark-gluster/spark-master-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: spark-master-controller\n  namespace: spark-cluster\n  labels:\n    component: spark-master\nspec:\n  replicas: 1\n  selector:\n    component: spark-master\n  template:\n    metadata:\n      labels:\n        component: spark-master\n    spec:\n      containers:\n      - name: spark-master\n        image: registry.k8s.io/spark:1.5.2_v1\n        command:\n        - /start-master\n        ports:\n        - containerPort: 7077\n        volumeMounts:\n        - mountPath: /mnt/glusterfs\n          name: glusterfsvol\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-18oopa\n        resources:\n          requests:\n            cpu: 100m\n      volumes:\n      - name: glusterfsvol\n        glusterfs:\n          endpoints: glusterfs-cluster\n          path: MyVolume\n          readOnly: false\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-gnznb3\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9hwjnzrm.yaml: (object: spark-cluster/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9hwjnzrm.yaml: (object: spark-cluster/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9hwjnzrm.yaml: (object: spark-cluster/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/spark/spark-master-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: spark-master-controller\nspec:\n  replicas: 1\n  selector:\n    component: spark-master\n  template:\n    metadata:\n      labels:\n        component: spark-master\n    spec:\n      containers:\n      - name: spark-master\n        image: registry.k8s.io/spark:1.5.2_v1\n        command:\n        - /start-master\n        ports:\n        - containerPort: 7077\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1av63f_x.yaml: (object: <no namespace>/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1av63f_x.yaml: (object: <no namespace>/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1av63f_x.yaml: (object: <no namespace>/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1av63f_x.yaml: (object: <no namespace>/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1av63f_x.yaml: (object: <no namespace>/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/spark/spark-master-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: spark-master-controller\nspec:\n  replicas: 1\n  selector:\n    component: spark-master\n  template:\n    metadata:\n      labels:\n        component: spark-master\n    spec:\n      containers:\n      - name: spark-master\n        image: registry.k8s.io/spark:1.5.2_v1\n        command:\n        - /start-master\n        ports:\n        - containerPort: 7077\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-9aca49\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-ijrvel\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptnpkeal9.yaml: (object: <no namespace>/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptnpkeal9.yaml: (object: <no namespace>/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptnpkeal9.yaml: (object: <no namespace>/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/flocker/flocker-pod.yml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: flocker-web\nspec:\n  containers:\n  - name: web\n    image: nginx\n    ports:\n    - name: web\n      containerPort: 80\n    volumeMounts:\n    - name: www-root\n      mountPath: /usr/share/nginx/html\n    securityContext:\n      privileged: true\n  volumes:\n  - name: www-root\n    flocker:\n      datasetName: my-flocker-vol\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbucfekga.yaml: (object: <no namespace>/flocker-web /v1, Kind=Pod) The container \"web\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbucfekga.yaml: (object: <no namespace>/flocker-web /v1, Kind=Pod) container \"web\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbucfekga.yaml: (object: <no namespace>/flocker-web /v1, Kind=Pod) container \"web\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbucfekga.yaml: (object: <no namespace>/flocker-web /v1, Kind=Pod) container \"web\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbucfekga.yaml: (object: <no namespace>/flocker-web /v1, Kind=Pod) container \"web\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbucfekga.yaml: (object: <no namespace>/flocker-web /v1, Kind=Pod) container \"web\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbucfekga.yaml: (object: <no namespace>/flocker-web /v1, Kind=Pod) container \"web\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/flocker/flocker-pod.yml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: flocker-web\nspec:\n  containers:\n  - name: web\n    image: nginx\n    ports:\n    - name: web\n      containerPort: 80\n    volumeMounts:\n    - name: www-root\n      mountPath: /usr/share/nginx/html\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-ks657f\n  volumes:\n  - name: www-root\n    flocker:\n      datasetName: my-flocker-vol\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-iiojxm\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplt2olglr.yaml: (object: <no namespace>/flocker-web /v1, Kind=Pod) The container \"web\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplt2olglr.yaml: (object: <no namespace>/flocker-web /v1, Kind=Pod) container \"web\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplt2olglr.yaml: (object: <no namespace>/flocker-web /v1, Kind=Pod) container \"web\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplt2olglr.yaml: (object: <no namespace>/flocker-web /v1, Kind=Pod) container \"web\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplt2olglr.yaml: (object: <no namespace>/flocker-web /v1, Kind=Pod) container \"web\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook-go/redis-replica-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: redis-replica\n  labels:\n    app: redis\n    role: replica\nspec:\n  replicas: 2\n  selector:\n    app: redis\n    role: replica\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: replica\n    spec:\n      containers:\n      - name: redis-replica\n        image: registry.k8s.io/redis-slave:v2\n        ports:\n        - name: redis-server\n          containerPort: 6379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1tj1qxyx.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1tj1qxyx.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1tj1qxyx.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1tj1qxyx.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1tj1qxyx.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1tj1qxyx.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1tj1qxyx.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook-go/redis-replica-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: redis-replica\n  labels:\n    app: redis\n    role: replica\nspec:\n  replicas: 2\n  selector:\n    app: redis\n    role: replica\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: replica\n    spec:\n      containers:\n      - name: redis-replica\n        image: registry.k8s.io/redis-slave:v2\n        ports:\n        - name: redis-server\n          containerPort: 6379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-8z170v\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-y5bbx9\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb9i35ly6.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb9i35ly6.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb9i35ly6.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb9i35ly6.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb9i35ly6.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"redis-replica\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/javaee/mysql-pod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mysql-pod\n  labels:\n    name: mysql-pod\n    context: docker-k8s-lab\nspec:\n  containers:\n  - name: mysql\n    image: mysql:latest\n    env:\n    - name: MYSQL_USER\n      value: mysql\n    - name: MYSQL_PASSWORD\n      value: mysql\n    - name: MYSQL_DATABASE\n      value: sample\n    - name: MYSQL_ROOT_PASSWORD\n      value: supersecret\n    ports:\n    - containerPort: 3306\n    securityContext:\n      privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1a3nth1g.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) The container \"mysql\" is using an invalid container image, \"mysql:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1a3nth1g.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1a3nth1g.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1a3nth1g.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1a3nth1g.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1a3nth1g.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1a3nth1g.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/javaee/mysql-pod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mysql-pod\n  labels:\n    name: mysql-pod\n    context: docker-k8s-lab\nspec:\n  containers:\n  - name: mysql\n    image: mysql:latest\n    env:\n    - name: MYSQL_USER\n      value: mysql\n    - name: MYSQL_PASSWORD\n      value: mysql\n    - name: MYSQL_DATABASE\n      value: sample\n    - name: MYSQL_ROOT_PASSWORD\n      value: supersecret\n    ports:\n    - containerPort: 3306\n    volumeMounts:\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-4h3zjo\n  volumes:\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-9rbhz3\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp980aubmx.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) The container \"mysql\" is using an invalid container image, \"mysql:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp980aubmx.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp980aubmx.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp980aubmx.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp980aubmx.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/sysdig-cloud/sysdig-rc.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: sysdig-agent\n  labels:\n    app: sysdig-agent\nspec:\n  replicas: 100\n  template:\n    spec:\n      volumes:\n      - name: docker-sock\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: dev-vol\n        hostPath:\n          path: /dev\n      - name: proc-vol\n        hostPath:\n          path: /proc\n      - name: boot-vol\n        hostPath:\n          path: /boot\n      - name: modules-vol\n        hostPath:\n          path: /lib/modules\n      - name: usr-vol\n        hostPath:\n          path: /usr\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-11ef9x\n          type: DirectoryOrCreate\n      hostNetwork: true\n      hostPID: true\n      containers:\n      - name: sysdig-agent\n        image: sysdig/agent\n        ports:\n        - containerPort: 6666\n          hostPort: 6666\n        securityContext:\n          privileged: true\n        env:\n        - name: ACCESS_KEY\n          value: 8312341g-5678-abcd-4a2b2c-33bcsd655\n        volumeMounts:\n        - mountPath: /host/var/run/docker.sock\n          name: docker-sock\n          readOnly: false\n        - mountPath: /host/dev\n          name: dev-vol\n          readOnly: false\n        - mountPath: /host/proc\n          name: proc-vol\n          readOnly: true\n        - mountPath: /host/boot\n          name: boot-vol\n          readOnly: true\n        - mountPath: /host/lib/modules\n          name: modules-vol\n          readOnly: true\n        - mountPath: /host/usr\n          name: usr-vol\n          readOnly: true\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-v3bobu\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk4y9fzrj.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) host system directory \"/var/run/docker.sock\" is mounted on container \"sysdig-agent\" (check: docker-sock, remediation: Ensure the Docker socket is not mounted inside any containers by removing the associated  Volume and VolumeMount in deployment yaml specification. If the Docker socket is mounted inside a container it could allow processes running within  the container to execute Docker commands which would effectively allow for full control of the host.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk4y9fzrj.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) resource shares host's network namespace (via hostNetwork=true). (check: host-network, remediation: Ensure the host's network namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk4y9fzrj.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) object shares the host's process namespace (via hostPID=true). (check: host-pid, remediation: Ensure the host's process namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk4y9fzrj.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) The container \"sysdig-agent\" is using an invalid container image, \"sysdig/agent\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk4y9fzrj.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) object has 100 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk4y9fzrj.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) container \"sysdig-agent\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk4y9fzrj.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) container \"sysdig-agent\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk4y9fzrj.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) container \"sysdig-agent\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk4y9fzrj.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) container \"sysdig-agent\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk4y9fzrj.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) host system directory \"/dev\" is mounted on container \"sysdig-agent\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk4y9fzrj.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) host system directory \"/proc\" is mounted on container \"sysdig-agent\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk4y9fzrj.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) host system directory \"/boot\" is mounted on container \"sysdig-agent\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk4y9fzrj.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) host system directory \"/usr\" is mounted on container \"sysdig-agent\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk4y9fzrj.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) container \"sysdig-agent\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk4y9fzrj.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) container \"sysdig-agent\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 15 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/sysdig-cloud/sysdig-rc.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: sysdig-agent\n  labels:\n    app: sysdig-agent\nspec:\n  replicas: 100\n  template:\n    spec:\n      volumes:\n      - name: docker-sock\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: dev-vol\n        hostPath:\n          path: /dev\n      - name: proc-vol\n        hostPath:\n          path: /proc\n      - name: boot-vol\n        hostPath:\n          path: /boot\n      - name: modules-vol\n        hostPath:\n          path: /lib/modules\n      - name: usr-vol\n        hostPath:\n          path: /usr\n      hostNetwork: true\n      hostPID: true\n      containers:\n      - name: sysdig-agent\n        image: sysdig/agent\n        ports:\n        - containerPort: 6666\n          hostPort: 6666\n        env:\n        - name: ACCESS_KEY\n          value: 8312341g-5678-abcd-4a2b2c-33bcsd655\n        volumeMounts:\n        - mountPath: /host/var/run/docker.sock\n          name: docker-sock\n          readOnly: false\n        - mountPath: /host/dev\n          name: dev-vol\n          readOnly: false\n        - mountPath: /host/proc\n          name: proc-vol\n          readOnly: true\n        - mountPath: /host/boot\n          name: boot-vol\n          readOnly: true\n        - mountPath: /host/lib/modules\n          name: modules-vol\n          readOnly: true\n        - mountPath: /host/usr\n          name: usr-vol\n          readOnly: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_vkn6h_l.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) host system directory \"/var/run/docker.sock\" is mounted on container \"sysdig-agent\" (check: docker-sock, remediation: Ensure the Docker socket is not mounted inside any containers by removing the associated  Volume and VolumeMount in deployment yaml specification. If the Docker socket is mounted inside a container it could allow processes running within  the container to execute Docker commands which would effectively allow for full control of the host.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_vkn6h_l.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) resource shares host's network namespace (via hostNetwork=true). (check: host-network, remediation: Ensure the host's network namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_vkn6h_l.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) object shares the host's process namespace (via hostPID=true). (check: host-pid, remediation: Ensure the host's process namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_vkn6h_l.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) The container \"sysdig-agent\" is using an invalid container image, \"sysdig/agent\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_vkn6h_l.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) object has 100 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_vkn6h_l.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) container \"sysdig-agent\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_vkn6h_l.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) container \"sysdig-agent\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_vkn6h_l.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) host system directory \"/dev\" is mounted on container \"sysdig-agent\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_vkn6h_l.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) host system directory \"/proc\" is mounted on container \"sysdig-agent\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_vkn6h_l.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) host system directory \"/boot\" is mounted on container \"sysdig-agent\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_vkn6h_l.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) host system directory \"/usr\" is mounted on container \"sysdig-agent\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_vkn6h_l.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) container \"sysdig-agent\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_vkn6h_l.yaml: (object: <no namespace>/sysdig-agent /v1, Kind=ReplicationController) container \"sysdig-agent\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 13 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/azure_disk/claim/blob-based-disk/shared-ssd/pod-uses-shared-ssd.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-uses-shared-ssd-5g\n  labels:\n    name: storage\nspec:\n  containers:\n  - image: nginx\n    name: az-c-01\n    command:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> /mnt/blobdisk/outfile; sleep 1; done\n    volumeMounts:\n    - name: blobdisk01\n      mountPath: /mnt/blobdisk\n    securityContext:\n      privileged: true\n  volumes:\n  - name: blobdisk01\n    persistentVolumeClaim:\n      claimName: pv-dd-shared-ssd-5g\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw1xhduz7.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) The container \"az-c-01\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw1xhduz7.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw1xhduz7.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw1xhduz7.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw1xhduz7.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw1xhduz7.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpw1xhduz7.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/azure_disk/claim/blob-based-disk/shared-ssd/pod-uses-shared-ssd.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-uses-shared-ssd-5g\n  labels:\n    name: storage\nspec:\n  containers:\n  - image: nginx\n    name: az-c-01\n    command:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> /mnt/blobdisk/outfile; sleep 1; done\n    volumeMounts:\n    - name: blobdisk01\n      mountPath: /mnt/blobdisk\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-a9a5md\n  volumes:\n  - name: blobdisk01\n    persistentVolumeClaim:\n      claimName: pv-dd-shared-ssd-5g\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-t0uf13\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuh2n8wdm.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) The container \"az-c-01\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuh2n8wdm.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuh2n8wdm.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuh2n8wdm.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuh2n8wdm.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/volumes/iscsi/iscsi.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: iscsipd\nspec:\n  containers:\n  - name: iscsipd-rw\n    image: kubernetes/pause\n    volumeMounts:\n    - mountPath: /mnt/iscsipd\n      name: iscsipd-rw\n    securityContext:\n      privileged: true\n  volumes:\n  - name: iscsipd-rw\n    iscsi:\n      targetPortal: 10.0.2.15:3260\n      portals:\n      - 10.0.2.16:3260\n      - 10.0.2.17:3260\n      iqn: iqn.2001-04.com.example:storage.kube.sys1.xyz\n      lun: 0\n      fsType: ext4\n      readOnly: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpl036xubp.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) The container \"iscsipd-rw\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpl036xubp.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpl036xubp.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpl036xubp.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpl036xubp.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpl036xubp.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpl036xubp.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/volumes/iscsi/iscsi.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: iscsipd\nspec:\n  containers:\n  - name: iscsipd-rw\n    image: kubernetes/pause\n    volumeMounts:\n    - mountPath: /mnt/iscsipd\n      name: iscsipd-rw\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-0s2cyr\n  volumes:\n  - name: iscsipd-rw\n    iscsi:\n      targetPortal: 10.0.2.15:3260\n      portals:\n      - 10.0.2.16:3260\n      - 10.0.2.17:3260\n      iqn: iqn.2001-04.com.example:storage.kube.sys1.xyz\n      lun: 0\n      fsType: ext4\n      readOnly: true\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-nkazwc\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplzeyfbyj.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) The container \"iscsipd-rw\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplzeyfbyj.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplzeyfbyj.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplzeyfbyj.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplzeyfbyj.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/vitess/vtctld-controller-template.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: vtctld\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: vtctld\n        app: vitess\n    spec:\n      containers:\n      - name: vtctld\n        image: vitess/lite:v2.0.0-alpha5\n        volumeMounts:\n        - name: syslog\n          mountPath: /dev/log\n        - name: vtdataroot\n          mountPath: /vt/vtdataroot\n        - name: certs\n          readOnly: true\n          mountPath: /etc/ssl/certs\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 100m\n        command:\n        - sh\n        - -c\n        - mkdir -p $VTDATAROOT/tmp && chown -R vitess /vt && su -p -c \"/vt/bin/vtctld\n          -debug -templates $VTTOP/go/cmd/vtctld/templates -web_dir $VTTOP/web/vtctld\n          -log_dir $VTDATAROOT/tmp -alsologtostderr -port 15000 -grpc_port 15001 -service_map\n          'grpc-vtctl' -topo_implementation etcd -tablet_protocol grpc -tablet_manager_protocol\n          grpc -etcd_global_addrs http://$ETCD_GLOBAL_SERVICE_HOST:$ETCD_GLOBAL_SERVICE_PORT\n          {{backup_flags}}\" vitess\n        securityContext:\n          privileged: true\n      volumes:\n      - name: syslog\n        hostPath:\n          path: /dev/log\n      - name: vtdataroot\n        emptyDir: {}\n      - name: certs\n        hostPath:\n          path: /etc/ssl/certs\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr04z5dgy.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr04z5dgy.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr04z5dgy.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr04z5dgy.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr04z5dgy.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/vitess/vtctld-controller-template.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: vtctld\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: vtctld\n        app: vitess\n    spec:\n      containers:\n      - name: vtctld\n        image: vitess/lite:v2.0.0-alpha5\n        volumeMounts:\n        - name: syslog\n          mountPath: /dev/log\n        - name: vtdataroot\n          mountPath: /vt/vtdataroot\n        - name: certs\n          readOnly: true\n          mountPath: /etc/ssl/certs\n        command:\n        - sh\n        - -c\n        - mkdir -p $VTDATAROOT/tmp && chown -R vitess /vt && su -p -c \"/vt/bin/vtctld\n          -debug -templates $VTTOP/go/cmd/vtctld/templates -web_dir $VTTOP/web/vtctld\n          -log_dir $VTDATAROOT/tmp -alsologtostderr -port 15000 -grpc_port 15001 -service_map\n          'grpc-vtctl' -topo_implementation etcd -tablet_protocol grpc -tablet_manager_protocol\n          grpc -etcd_global_addrs http://$ETCD_GLOBAL_SERVICE_HOST:$ETCD_GLOBAL_SERVICE_PORT\n          {{backup_flags}}\" vitess\n      volumes:\n      - name: syslog\n        hostPath:\n          path: /dev/log\n      - name: vtdataroot\n        emptyDir: {}\n      - name: certs\n        hostPath:\n          path: /etc/ssl/certs\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpn_tmnjnn.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpn_tmnjnn.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpn_tmnjnn.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpn_tmnjnn.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/vitess/vtctld-controller-template.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: vtctld\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: vtctld\n        app: vitess\n    spec:\n      containers:\n      - name: vtctld\n        image: vitess/lite:v2.0.0-alpha5\n        volumeMounts:\n        - name: syslog\n          mountPath: /dev/log\n        - name: vtdataroot\n          mountPath: /vt/vtdataroot\n        - name: certs\n          readOnly: true\n          mountPath: /etc/ssl/certs\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-txtkia\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 100m\n        command:\n        - sh\n        - -c\n        - mkdir -p $VTDATAROOT/tmp && chown -R vitess /vt && su -p -c \"/vt/bin/vtctld\n          -debug -templates $VTTOP/go/cmd/vtctld/templates -web_dir $VTTOP/web/vtctld\n          -log_dir $VTDATAROOT/tmp -alsologtostderr -port 15000 -grpc_port 15001 -service_map\n          'grpc-vtctl' -topo_implementation etcd -tablet_protocol grpc -tablet_manager_protocol\n          grpc -etcd_global_addrs http://$ETCD_GLOBAL_SERVICE_HOST:$ETCD_GLOBAL_SERVICE_PORT\n          {{backup_flags}}\" vitess\n      volumes:\n      - name: syslog\n        hostPath:\n          path: /dev/log\n      - name: vtdataroot\n        emptyDir: {}\n      - name: certs\n        hostPath:\n          path: /etc/ssl/certs\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-i4549v\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdx7vk92b.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdx7vk92b.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdx7vk92b.yaml: (object: <no namespace>/vtctld /v1, Kind=ReplicationController) container \"vtctld\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/azure_disk/claim/managed-disk/managed-hdd/pod-uses-managed-hdd.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-uses-managed-hdd-5g\n  labels:\n    name: storage\nspec:\n  containers:\n  - image: nginx\n    name: az-c-01\n    command:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> /mnt/managed/outfile; sleep 1; done\n    volumeMounts:\n    - name: managed01\n      mountPath: /mnt/managed\n    securityContext:\n      privileged: true\n  volumes:\n  - name: managed01\n    persistentVolumeClaim:\n      claimName: dd-managed-hdd-5g\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphhqlqw7_.yaml: (object: <no namespace>/pod-uses-managed-hdd-5g /v1, Kind=Pod) The container \"az-c-01\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphhqlqw7_.yaml: (object: <no namespace>/pod-uses-managed-hdd-5g /v1, Kind=Pod) container \"az-c-01\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphhqlqw7_.yaml: (object: <no namespace>/pod-uses-managed-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphhqlqw7_.yaml: (object: <no namespace>/pod-uses-managed-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphhqlqw7_.yaml: (object: <no namespace>/pod-uses-managed-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphhqlqw7_.yaml: (object: <no namespace>/pod-uses-managed-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphhqlqw7_.yaml: (object: <no namespace>/pod-uses-managed-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/azure_disk/claim/managed-disk/managed-hdd/pod-uses-managed-hdd.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-uses-managed-hdd-5g\n  labels:\n    name: storage\nspec:\n  containers:\n  - image: nginx\n    name: az-c-01\n    command:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> /mnt/managed/outfile; sleep 1; done\n    volumeMounts:\n    - name: managed01\n      mountPath: /mnt/managed\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-f3kmle\n  volumes:\n  - name: managed01\n    persistentVolumeClaim:\n      claimName: dd-managed-hdd-5g\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-0y5795\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmps532yy.yaml: (object: <no namespace>/pod-uses-managed-hdd-5g /v1, Kind=Pod) The container \"az-c-01\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmps532yy.yaml: (object: <no namespace>/pod-uses-managed-hdd-5g /v1, Kind=Pod) container \"az-c-01\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmps532yy.yaml: (object: <no namespace>/pod-uses-managed-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmps532yy.yaml: (object: <no namespace>/pod-uses-managed-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmps532yy.yaml: (object: <no namespace>/pod-uses-managed-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/base/overlays/argocd-application-controller-statefulset.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: argocd-application-controller\nspec:\n  template:\n    spec:\n      containers:\n      - name: argocd-application-controller\n        args:\n        - /usr/local/bin/argocd-application-controller\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2ezyi2oc.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) The container \"argocd-application-controller\" is using an invalid container image, \"\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2ezyi2oc.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) object has no selector specified (check: mismatching-selector, remediation: Confirm that your deployment selector correctly matches the labels in its pod template.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2ezyi2oc.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2ezyi2oc.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2ezyi2oc.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2ezyi2oc.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2ezyi2oc.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2ezyi2oc.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/base/overlays/argocd-application-controller-statefulset.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: argocd-application-controller\nspec:\n  template:\n    spec:\n      containers:\n      - name: argocd-application-controller\n        args:\n        - /usr/local/bin/argocd-application-controller\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-ewye6x\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-gbpy41\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4vpqo_qe.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) The container \"argocd-application-controller\" is using an invalid container image, \"\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4vpqo_qe.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) object has no selector specified (check: mismatching-selector, remediation: Confirm that your deployment selector correctly matches the labels in its pod template.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4vpqo_qe.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4vpqo_qe.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4vpqo_qe.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4vpqo_qe.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cpu-manager/be.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: be\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: be\n    securityContext:\n      privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnhqwi1qu.yaml: (object: <no namespace>/be /v1, Kind=Pod) The container \"be\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnhqwi1qu.yaml: (object: <no namespace>/be /v1, Kind=Pod) container \"be\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnhqwi1qu.yaml: (object: <no namespace>/be /v1, Kind=Pod) container \"be\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnhqwi1qu.yaml: (object: <no namespace>/be /v1, Kind=Pod) container \"be\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnhqwi1qu.yaml: (object: <no namespace>/be /v1, Kind=Pod) container \"be\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnhqwi1qu.yaml: (object: <no namespace>/be /v1, Kind=Pod) container \"be\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnhqwi1qu.yaml: (object: <no namespace>/be /v1, Kind=Pod) container \"be\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cpu-manager/be.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: be\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: be\n    volumeMounts:\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-ybdgqg\n  volumes:\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-0j5h0y\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptzbmfxru.yaml: (object: <no namespace>/be /v1, Kind=Pod) The container \"be\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptzbmfxru.yaml: (object: <no namespace>/be /v1, Kind=Pod) container \"be\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptzbmfxru.yaml: (object: <no namespace>/be /v1, Kind=Pod) container \"be\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptzbmfxru.yaml: (object: <no namespace>/be /v1, Kind=Pod) container \"be\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptzbmfxru.yaml: (object: <no namespace>/be /v1, Kind=Pod) container \"be\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/volumes/cephfs/cephfs-with-secret.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cephfs2\nspec:\n  containers:\n  - name: cephfs-rw\n    image: kubernetes/pause\n    volumeMounts:\n    - mountPath: /mnt/cephfs\n      name: cephfs\n    securityContext:\n      privileged: true\n  volumes:\n  - name: cephfs\n    cephfs:\n      monitors:\n      - 10.16.154.78:6789\n      - 10.16.154.82:6789\n      - 10.16.154.83:6789\n      user: admin\n      secretRef:\n        name: ceph-secret\n      readOnly: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa500e2zv.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) The container \"cephfs-rw\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa500e2zv.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa500e2zv.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa500e2zv.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa500e2zv.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa500e2zv.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa500e2zv.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/volumes/cephfs/cephfs-with-secret.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cephfs2\nspec:\n  containers:\n  - name: cephfs-rw\n    image: kubernetes/pause\n    volumeMounts:\n    - mountPath: /mnt/cephfs\n      name: cephfs\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-38fn0g\n  volumes:\n  - name: cephfs\n    cephfs:\n      monitors:\n      - 10.16.154.78:6789\n      - 10.16.154.82:6789\n      - 10.16.154.83:6789\n      user: admin\n      secretRef:\n        name: ceph-secret\n      readOnly: true\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-0lpy9b\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppcvm35kp.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) The container \"cephfs-rw\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppcvm35kp.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppcvm35kp.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppcvm35kp.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppcvm35kp.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/portworx/portworx-volume-pvcscpod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pvpod\nspec:\n  containers:\n  - name: test-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - name: test-volume\n      mountPath: /test-portworx-volume\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test-volume\n    persistentVolumeClaim:\n      claimName: pvcsc001\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpaf_ou889.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpaf_ou889.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpaf_ou889.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpaf_ou889.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpaf_ou889.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpaf_ou889.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpaf_ou889.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/portworx/portworx-volume-pvcscpod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pvpod\nspec:\n  containers:\n  - name: test-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - name: test-volume\n      mountPath: /test-portworx-volume\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-rh8e1z\n  volumes:\n  - name: test-volume\n    persistentVolumeClaim:\n      claimName: pvcsc001\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-zrvy87\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpecb1apnu.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpecb1apnu.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpecb1apnu.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpecb1apnu.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpecb1apnu.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook/legacy/redis-replica-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: redis-replica\n  labels:\n    app: redis\n    role: replica\n    tier: backend\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: replica\n        tier: backend\n    spec:\n      containers:\n      - name: replica\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpheotjr1l.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpheotjr1l.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"replica\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpheotjr1l.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"replica\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpheotjr1l.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"replica\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpheotjr1l.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"replica\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpheotjr1l.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"replica\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook/legacy/redis-replica-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: redis-replica\n  labels:\n    app: redis\n    role: replica\n    tier: backend\nspec:\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: replica\n        tier: backend\n    spec:\n      containers:\n      - name: replica\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-trh1ly\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-6u57i5\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9jbktqek.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9jbktqek.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"replica\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9jbktqek.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"replica\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9jbktqek.yaml: (object: <no namespace>/redis-replica /v1, Kind=ReplicationController) container \"replica\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/volumes/iscsi/iscsi-chap.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: iscsipd\nspec:\n  containers:\n  - name: iscsipd-ro\n    image: kubernetes/pause\n    volumeMounts:\n    - mountPath: /mnt/iscsipd\n      name: iscsivol\n    securityContext:\n      privileged: true\n  volumes:\n  - name: iscsivol\n    iscsi:\n      targetPortal: 127.0.0.1\n      iqn: iqn.2015-02.example.com:test\n      lun: 0\n      fsType: ext4\n      readOnly: true\n      chapAuthDiscovery: true\n      chapAuthSession: true\n      secretRef:\n        name: chap-secret\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6srano5i.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) The container \"iscsipd-ro\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6srano5i.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6srano5i.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6srano5i.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6srano5i.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6srano5i.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6srano5i.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/volumes/iscsi/iscsi-chap.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: iscsipd\nspec:\n  containers:\n  - name: iscsipd-ro\n    image: kubernetes/pause\n    volumeMounts:\n    - mountPath: /mnt/iscsipd\n      name: iscsivol\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-5idhtl\n  volumes:\n  - name: iscsivol\n    iscsi:\n      targetPortal: 127.0.0.1\n      iqn: iqn.2015-02.example.com:test\n      lun: 0\n      fsType: ext4\n      readOnly: true\n      chapAuthDiscovery: true\n      chapAuthSession: true\n      secretRef:\n        name: chap-secret\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-gpgr10\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmhpt9vdy.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) The container \"iscsipd-ro\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmhpt9vdy.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmhpt9vdy.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmhpt9vdy.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmhpt9vdy.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-ro\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/vitess/vttablet-pod-template.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: vttablet-{{uid}}\n  labels:\n    component: vttablet\n    keyspace: '{{keyspace}}'\n    shard: '{{shard_label}}'\n    tablet: '{{alias}}'\n    app: vitess\nspec:\n  containers:\n  - name: vttablet\n    image: vitess/lite:v2.0.0-alpha5\n    volumeMounts:\n    - name: syslog\n      mountPath: /dev/log\n    - name: vtdataroot\n      mountPath: /vt/vtdataroot\n    - name: certs\n      readOnly: true\n      mountPath: /etc/ssl/certs\n    resources:\n      limits:\n        memory: 1Gi\n        cpu: 500m\n    command:\n    - bash\n    - -c\n    - 'set -e\n\n      mysql_socket=\"$VTDATAROOT/{{tablet_subdir}}/mysql.sock\"\n\n      mkdir -p $VTDATAROOT/tmp\n\n      chown -R vitess /vt\n\n      while [ ! -e $mysql_socket ]; do echo \"[$(date)] waiting for $mysql_socket\"\n      ; sleep 1 ; done\n\n      su -p -s /bin/bash -c \"mysql -u vt_dba -S $mysql_socket -e ''CREATE DATABASE\n      IF NOT EXISTS vt_{{keyspace}}''\" vitess\n\n      su -p -s /bin/bash -c \"/vt/bin/vttablet -topo_implementation etcd -etcd_global_addrs\n      http://$ETCD_GLOBAL_SERVICE_HOST:$ETCD_GLOBAL_SERVICE_PORT -log_dir $VTDATAROOT/tmp\n      -alsologtostderr -port {{port}} -grpc_port {{grpc_port}} -service_map ''grpc-queryservice,grpc-tabletmanager,grpc-updatestream''\n      -binlog_player_protocol grpc -tablet-path {{alias}} -tablet_hostname $(hostname\n      -i) -init_keyspace {{keyspace}} -init_shard {{shard}} -target_tablet_type {{tablet_type}}\n      -mysqlctl_socket $VTDATAROOT/mysqlctl.sock -db-config-app-uname vt_app -db-config-app-dbname\n      vt_{{keyspace}} -db-config-app-charset utf8 -db-config-dba-uname vt_dba -db-config-dba-dbname\n      vt_{{keyspace}} -db-config-dba-charset utf8 -db-config-repl-uname vt_repl -db-config-repl-dbname\n      vt_{{keyspace}} -db-config-repl-charset utf8 -db-config-filtered-uname vt_filtered\n      -db-config-filtered-dbname vt_{{keyspace}} -db-config-filtered-charset utf8\n      -enable-rowcache -rowcache-bin /usr/bin/memcached -rowcache-socket $VTDATAROOT/{{tablet_subdir}}/memcache.sock\n      -health_check_interval 5s -restore_from_backup {{backup_flags}}\" vitess'\n    securityContext:\n      privileged: true\n  - name: mysql\n    image: vitess/lite:v2.0.0-alpha5\n    volumeMounts:\n    - name: syslog\n      mountPath: /dev/log\n    - name: vtdataroot\n      mountPath: /vt/vtdataroot\n    resources:\n      limits:\n        memory: 1Gi\n        cpu: 500m\n    command:\n    - sh\n    - -c\n    - 'mkdir -p $VTDATAROOT/tmp && chown -R vitess /vt\n\n      su -p -c \"/vt/bin/mysqlctld -log_dir $VTDATAROOT/tmp -alsologtostderr -tablet_uid\n      {{uid}} -socket_file $VTDATAROOT/mysqlctl.sock -db-config-app-uname vt_app -db-config-app-dbname\n      vt_{{keyspace}} -db-config-app-charset utf8 -db-config-dba-uname vt_dba -db-config-dba-dbname\n      vt_{{keyspace}} -db-config-dba-charset utf8 -db-config-repl-uname vt_repl -db-config-repl-dbname\n      vt_{{keyspace}} -db-config-repl-charset utf8 -db-config-filtered-uname vt_filtered\n      -db-config-filtered-dbname vt_{{keyspace}} -db-config-filtered-charset utf8\n      -bootstrap_archive mysql-db-dir_10.0.13-MariaDB.tbz\" vitess'\n    env:\n    - name: EXTRA_MY_CNF\n      value: /vt/config/mycnf/master_mariadb.cnf\n  volumes:\n  - name: syslog\n    hostPath:\n      path: /dev/log\n  - name: vtdataroot\n    emptyDir: {}\n  - name: certs\n    hostPath:\n      path: /etc/ssl/certs\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6cwl9ydd.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6cwl9ydd.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6cwl9ydd.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6cwl9ydd.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6cwl9ydd.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6cwl9ydd.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6cwl9ydd.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6cwl9ydd.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/vitess/vttablet-pod-template.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: vttablet-{{uid}}\n  labels:\n    component: vttablet\n    keyspace: '{{keyspace}}'\n    shard: '{{shard_label}}'\n    tablet: '{{alias}}'\n    app: vitess\nspec:\n  containers:\n  - name: vttablet\n    image: vitess/lite:v2.0.0-alpha5\n    volumeMounts:\n    - name: syslog\n      mountPath: /dev/log\n    - name: vtdataroot\n      mountPath: /vt/vtdataroot\n    - name: certs\n      readOnly: true\n      mountPath: /etc/ssl/certs\n    command:\n    - bash\n    - -c\n    - 'set -e\n\n      mysql_socket=\"$VTDATAROOT/{{tablet_subdir}}/mysql.sock\"\n\n      mkdir -p $VTDATAROOT/tmp\n\n      chown -R vitess /vt\n\n      while [ ! -e $mysql_socket ]; do echo \"[$(date)] waiting for $mysql_socket\"\n      ; sleep 1 ; done\n\n      su -p -s /bin/bash -c \"mysql -u vt_dba -S $mysql_socket -e ''CREATE DATABASE\n      IF NOT EXISTS vt_{{keyspace}}''\" vitess\n\n      su -p -s /bin/bash -c \"/vt/bin/vttablet -topo_implementation etcd -etcd_global_addrs\n      http://$ETCD_GLOBAL_SERVICE_HOST:$ETCD_GLOBAL_SERVICE_PORT -log_dir $VTDATAROOT/tmp\n      -alsologtostderr -port {{port}} -grpc_port {{grpc_port}} -service_map ''grpc-queryservice,grpc-tabletmanager,grpc-updatestream''\n      -binlog_player_protocol grpc -tablet-path {{alias}} -tablet_hostname $(hostname\n      -i) -init_keyspace {{keyspace}} -init_shard {{shard}} -target_tablet_type {{tablet_type}}\n      -mysqlctl_socket $VTDATAROOT/mysqlctl.sock -db-config-app-uname vt_app -db-config-app-dbname\n      vt_{{keyspace}} -db-config-app-charset utf8 -db-config-dba-uname vt_dba -db-config-dba-dbname\n      vt_{{keyspace}} -db-config-dba-charset utf8 -db-config-repl-uname vt_repl -db-config-repl-dbname\n      vt_{{keyspace}} -db-config-repl-charset utf8 -db-config-filtered-uname vt_filtered\n      -db-config-filtered-dbname vt_{{keyspace}} -db-config-filtered-charset utf8\n      -enable-rowcache -rowcache-bin /usr/bin/memcached -rowcache-socket $VTDATAROOT/{{tablet_subdir}}/memcache.sock\n      -health_check_interval 5s -restore_from_backup {{backup_flags}}\" vitess'\n  - name: mysql\n    image: vitess/lite:v2.0.0-alpha5\n    volumeMounts:\n    - name: syslog\n      mountPath: /dev/log\n    - name: vtdataroot\n      mountPath: /vt/vtdataroot\n    command:\n    - sh\n    - -c\n    - 'mkdir -p $VTDATAROOT/tmp && chown -R vitess /vt\n\n      su -p -c \"/vt/bin/mysqlctld -log_dir $VTDATAROOT/tmp -alsologtostderr -tablet_uid\n      {{uid}} -socket_file $VTDATAROOT/mysqlctl.sock -db-config-app-uname vt_app -db-config-app-dbname\n      vt_{{keyspace}} -db-config-app-charset utf8 -db-config-dba-uname vt_dba -db-config-dba-dbname\n      vt_{{keyspace}} -db-config-dba-charset utf8 -db-config-repl-uname vt_repl -db-config-repl-dbname\n      vt_{{keyspace}} -db-config-repl-charset utf8 -db-config-filtered-uname vt_filtered\n      -db-config-filtered-dbname vt_{{keyspace}} -db-config-filtered-charset utf8\n      -bootstrap_archive mysql-db-dir_10.0.13-MariaDB.tbz\" vitess'\n    env:\n    - name: EXTRA_MY_CNF\n      value: /vt/config/mycnf/master_mariadb.cnf\n  volumes:\n  - name: syslog\n    hostPath:\n      path: /dev/log\n  - name: vtdataroot\n    emptyDir: {}\n  - name: certs\n    hostPath:\n      path: /etc/ssl/certs\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptaioudyg.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptaioudyg.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptaioudyg.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptaioudyg.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptaioudyg.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptaioudyg.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptaioudyg.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptaioudyg.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/vitess/vttablet-pod-template.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: vttablet-{{uid}}\n  labels:\n    component: vttablet\n    keyspace: '{{keyspace}}'\n    shard: '{{shard_label}}'\n    tablet: '{{alias}}'\n    app: vitess\nspec:\n  containers:\n  - name: vttablet\n    image: vitess/lite:v2.0.0-alpha5\n    volumeMounts:\n    - name: syslog\n      mountPath: /dev/log\n    - name: vtdataroot\n      mountPath: /vt/vtdataroot\n    - name: certs\n      readOnly: true\n      mountPath: /etc/ssl/certs\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-yaewmx\n    resources:\n      limits:\n        memory: 1Gi\n        cpu: 500m\n    command:\n    - bash\n    - -c\n    - 'set -e\n\n      mysql_socket=\"$VTDATAROOT/{{tablet_subdir}}/mysql.sock\"\n\n      mkdir -p $VTDATAROOT/tmp\n\n      chown -R vitess /vt\n\n      while [ ! -e $mysql_socket ]; do echo \"[$(date)] waiting for $mysql_socket\"\n      ; sleep 1 ; done\n\n      su -p -s /bin/bash -c \"mysql -u vt_dba -S $mysql_socket -e ''CREATE DATABASE\n      IF NOT EXISTS vt_{{keyspace}}''\" vitess\n\n      su -p -s /bin/bash -c \"/vt/bin/vttablet -topo_implementation etcd -etcd_global_addrs\n      http://$ETCD_GLOBAL_SERVICE_HOST:$ETCD_GLOBAL_SERVICE_PORT -log_dir $VTDATAROOT/tmp\n      -alsologtostderr -port {{port}} -grpc_port {{grpc_port}} -service_map ''grpc-queryservice,grpc-tabletmanager,grpc-updatestream''\n      -binlog_player_protocol grpc -tablet-path {{alias}} -tablet_hostname $(hostname\n      -i) -init_keyspace {{keyspace}} -init_shard {{shard}} -target_tablet_type {{tablet_type}}\n      -mysqlctl_socket $VTDATAROOT/mysqlctl.sock -db-config-app-uname vt_app -db-config-app-dbname\n      vt_{{keyspace}} -db-config-app-charset utf8 -db-config-dba-uname vt_dba -db-config-dba-dbname\n      vt_{{keyspace}} -db-config-dba-charset utf8 -db-config-repl-uname vt_repl -db-config-repl-dbname\n      vt_{{keyspace}} -db-config-repl-charset utf8 -db-config-filtered-uname vt_filtered\n      -db-config-filtered-dbname vt_{{keyspace}} -db-config-filtered-charset utf8\n      -enable-rowcache -rowcache-bin /usr/bin/memcached -rowcache-socket $VTDATAROOT/{{tablet_subdir}}/memcache.sock\n      -health_check_interval 5s -restore_from_backup {{backup_flags}}\" vitess'\n  - name: mysql\n    image: vitess/lite:v2.0.0-alpha5\n    volumeMounts:\n    - name: syslog\n      mountPath: /dev/log\n    - name: vtdataroot\n      mountPath: /vt/vtdataroot\n    resources:\n      limits:\n        memory: 1Gi\n        cpu: 500m\n    command:\n    - sh\n    - -c\n    - 'mkdir -p $VTDATAROOT/tmp && chown -R vitess /vt\n\n      su -p -c \"/vt/bin/mysqlctld -log_dir $VTDATAROOT/tmp -alsologtostderr -tablet_uid\n      {{uid}} -socket_file $VTDATAROOT/mysqlctl.sock -db-config-app-uname vt_app -db-config-app-dbname\n      vt_{{keyspace}} -db-config-app-charset utf8 -db-config-dba-uname vt_dba -db-config-dba-dbname\n      vt_{{keyspace}} -db-config-dba-charset utf8 -db-config-repl-uname vt_repl -db-config-repl-dbname\n      vt_{{keyspace}} -db-config-repl-charset utf8 -db-config-filtered-uname vt_filtered\n      -db-config-filtered-dbname vt_{{keyspace}} -db-config-filtered-charset utf8\n      -bootstrap_archive mysql-db-dir_10.0.13-MariaDB.tbz\" vitess'\n    env:\n    - name: EXTRA_MY_CNF\n      value: /vt/config/mycnf/master_mariadb.cnf\n  volumes:\n  - name: syslog\n    hostPath:\n      path: /dev/log\n  - name: vtdataroot\n    emptyDir: {}\n  - name: certs\n    hostPath:\n      path: /etc/ssl/certs\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-28gqsk\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz0sfrubk.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz0sfrubk.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz0sfrubk.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz0sfrubk.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz0sfrubk.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz0sfrubk.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/persistent-volume-provisioning/quobyte/example-pod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: server\nspec:\n  replicas: 1\n  selector:\n    role: server\n  template:\n    metadata:\n      labels:\n        role: server\n    spec:\n      containers:\n      - name: server\n        image: nginx\n        volumeMounts:\n        - mountPath: /var/lib/www/html\n          name: quobytepvc\n        securityContext:\n          privileged: true\n      volumes:\n      - name: quobytepvc\n        persistentVolumeClaim:\n          claimName: claim1\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprim30vak.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) The container \"server\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprim30vak.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprim30vak.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprim30vak.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprim30vak.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprim30vak.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprim30vak.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/persistent-volume-provisioning/quobyte/example-pod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: server\nspec:\n  replicas: 1\n  selector:\n    role: server\n  template:\n    metadata:\n      labels:\n        role: server\n    spec:\n      containers:\n      - name: server\n        image: nginx\n        volumeMounts:\n        - mountPath: /var/lib/www/html\n          name: quobytepvc\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-4flxo3\n      volumes:\n      - name: quobytepvc\n        persistentVolumeClaim:\n          claimName: claim1\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-d7u8ux\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzimhzmsq.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) The container \"server\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzimhzmsq.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzimhzmsq.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzimhzmsq.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzimhzmsq.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/kubebuilder-declarative-pattern/examples/guestbook-operator/config/default/manager_auth_proxy_patch.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: controller-manager\n  namespace: system\nspec:\n  template:\n    spec:\n      containers:\n      - name: kube-rbac-proxy\n        image: gcr.io/kubebuilder/kube-rbac-proxy:v0.8.0\n        args:\n        - --secure-listen-address=0.0.0.0:8443\n        - --upstream=http://127.0.0.1:8080/\n        - --logtostderr=true\n        - --v=10\n        ports:\n        - containerPort: 8443\n          name: https\n        securityContext:\n          privileged: true\n      - name: manager\n        args:\n        - --health-probe-bind-address=:8081\n        - --metrics-bind-address=127.0.0.1:8080\n        - --leader-elect\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzv4lbv.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) The container \"manager\" is using an invalid container image, \"\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzv4lbv.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) object has no selector specified (check: mismatching-selector, remediation: Confirm that your deployment selector correctly matches the labels in its pod template.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzv4lbv.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"kube-rbac-proxy\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzv4lbv.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzv4lbv.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"kube-rbac-proxy\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzv4lbv.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"kube-rbac-proxy\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzv4lbv.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"kube-rbac-proxy\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzv4lbv.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzv4lbv.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"kube-rbac-proxy\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzv4lbv.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzv4lbv.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"kube-rbac-proxy\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzv4lbv.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 12 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/kubebuilder-declarative-pattern/examples/guestbook-operator/config/default/manager_auth_proxy_patch.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: controller-manager\n  namespace: system\nspec:\n  template:\n    spec:\n      containers:\n      - name: kube-rbac-proxy\n        image: gcr.io/kubebuilder/kube-rbac-proxy:v0.8.0\n        args:\n        - --secure-listen-address=0.0.0.0:8443\n        - --upstream=http://127.0.0.1:8080/\n        - --logtostderr=true\n        - --v=10\n        ports:\n        - containerPort: 8443\n          name: https\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-v42q7t\n      - name: manager\n        args:\n        - --health-probe-bind-address=:8081\n        - --metrics-bind-address=127.0.0.1:8080\n        - --leader-elect\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-yx3vms\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp84fkqslw.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) The container \"manager\" is using an invalid container image, \"\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp84fkqslw.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) object has no selector specified (check: mismatching-selector, remediation: Confirm that your deployment selector correctly matches the labels in its pod template.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp84fkqslw.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"kube-rbac-proxy\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp84fkqslw.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp84fkqslw.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"kube-rbac-proxy\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp84fkqslw.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp84fkqslw.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"kube-rbac-proxy\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp84fkqslw.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp84fkqslw.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"kube-rbac-proxy\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp84fkqslw.yaml: (object: system/controller-manager apps/v1, Kind=Deployment) container \"manager\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 10 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/minio/minio-distributed-statefulset.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: minio\n  labels:\n    app: minio\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  serviceName: minio\n  replicas: 4\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      containers:\n      - name: minio\n        env:\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          value: minio123\n        image: minio/minio:latest\n        args:\n        - server\n        - http://minio-0.minio.default.svc.cluster.local/data\n        - http://minio-1.minio.default.svc.cluster.local/data\n        - http://minio-2.minio.default.svc.cluster.local/data\n        - http://minio-3.minio.default.svc.cluster.local/data\n        ports:\n        - containerPort: 9000\n          hostPort: 9000\n        volumeMounts:\n        - name: data\n          mountPath: /data\n        securityContext:\n          privileged: true\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      storageClassName: standard\n      resources:\n        requests:\n          storage: 10Gi\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp69n8bnrn.yaml: (object: <no namespace>/minio apps/v1, Kind=StatefulSet) environment variable MINIO_SECRET_KEY in container \"minio\" found (check: env-var-secret, remediation: Do not use raw secrets in environment variables. Instead, either mount the secret as a file or use a secretKeyRef. Refer to https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp69n8bnrn.yaml: (object: <no namespace>/minio apps/v1, Kind=StatefulSet) The container \"minio\" is using an invalid container image, \"minio/minio:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp69n8bnrn.yaml: (object: <no namespace>/minio apps/v1, Kind=StatefulSet) object has 4 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp69n8bnrn.yaml: (object: <no namespace>/minio apps/v1, Kind=StatefulSet) container \"minio\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp69n8bnrn.yaml: (object: <no namespace>/minio apps/v1, Kind=StatefulSet) container \"minio\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp69n8bnrn.yaml: (object: <no namespace>/minio apps/v1, Kind=StatefulSet) container \"minio\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp69n8bnrn.yaml: (object: <no namespace>/minio apps/v1, Kind=StatefulSet) container \"minio\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp69n8bnrn.yaml: (object: <no namespace>/minio apps/v1, Kind=StatefulSet) container \"minio\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp69n8bnrn.yaml: (object: <no namespace>/minio apps/v1, Kind=StatefulSet) container \"minio\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 9 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/minio/minio-distributed-statefulset.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: minio\n  labels:\n    app: minio\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  serviceName: minio\n  replicas: 4\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      containers:\n      - name: minio\n        env:\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          value: minio123\n        image: minio/minio:latest\n        args:\n        - server\n        - http://minio-0.minio.default.svc.cluster.local/data\n        - http://minio-1.minio.default.svc.cluster.local/data\n        - http://minio-2.minio.default.svc.cluster.local/data\n        - http://minio-3.minio.default.svc.cluster.local/data\n        ports:\n        - containerPort: 9000\n          hostPort: 9000\n        volumeMounts:\n        - name: data\n          mountPath: /data\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-arckc1\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-s288wr\n          type: DirectoryOrCreate\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      storageClassName: standard\n      resources:\n        requests:\n          storage: 10Gi\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp46t87if2.yaml: (object: <no namespace>/minio apps/v1, Kind=StatefulSet) environment variable MINIO_SECRET_KEY in container \"minio\" found (check: env-var-secret, remediation: Do not use raw secrets in environment variables. Instead, either mount the secret as a file or use a secretKeyRef. Refer to https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp46t87if2.yaml: (object: <no namespace>/minio apps/v1, Kind=StatefulSet) The container \"minio\" is using an invalid container image, \"minio/minio:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp46t87if2.yaml: (object: <no namespace>/minio apps/v1, Kind=StatefulSet) object has 4 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp46t87if2.yaml: (object: <no namespace>/minio apps/v1, Kind=StatefulSet) container \"minio\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp46t87if2.yaml: (object: <no namespace>/minio apps/v1, Kind=StatefulSet) container \"minio\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp46t87if2.yaml: (object: <no namespace>/minio apps/v1, Kind=StatefulSet) container \"minio\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp46t87if2.yaml: (object: <no namespace>/minio apps/v1, Kind=StatefulSet) container \"minio\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/flexvolume/nginx-lvm.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  namespace: default\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - name: test\n      mountPath: /data\n    ports:\n    - containerPort: 80\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test\n    flexVolume:\n      driver: kubernetes.io/lvm\n      fsType: ext4\n      options:\n        volumeID: vol1\n        size: 1000m\n        volumegroup: kube_vg\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6sx370q6.yaml: (object: default/nginx /v1, Kind=Pod) The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6sx370q6.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6sx370q6.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6sx370q6.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6sx370q6.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6sx370q6.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6sx370q6.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/flexvolume/nginx-lvm.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  namespace: default\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - name: test\n      mountPath: /data\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-u3t8tb\n    ports:\n    - containerPort: 80\n  volumes:\n  - name: test\n    flexVolume:\n      driver: kubernetes.io/lvm\n      fsType: ext4\n      options:\n        volumeID: vol1\n        size: 1000m\n        volumegroup: kube_vg\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-oh826q\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwvrs76hk.yaml: (object: default/nginx /v1, Kind=Pod) The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwvrs76hk.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwvrs76hk.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwvrs76hk.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwvrs76hk.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/vsphere/vsphere-volume-pvcscpod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pvpod\nspec:\n  containers:\n  - name: test-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - name: test-volume\n      mountPath: /test-vmdk\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test-volume\n    persistentVolumeClaim:\n      claimName: pvcsc001\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4eqn542e.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4eqn542e.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4eqn542e.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4eqn542e.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4eqn542e.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4eqn542e.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4eqn542e.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/vsphere/vsphere-volume-pvcscpod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pvpod\nspec:\n  containers:\n  - name: test-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - name: test-volume\n      mountPath: /test-vmdk\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-chbf1t\n  volumes:\n  - name: test-volume\n    persistentVolumeClaim:\n      claimName: pvcsc001\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-g06aeq\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp541o74qu.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp541o74qu.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp541o74qu.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp541o74qu.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp541o74qu.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/selenium/selenium-hub-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: selenium-hub\n  labels:\n    app: selenium-hub\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: selenium-hub\n  template:\n    metadata:\n      labels:\n        app: selenium-hub\n    spec:\n      containers:\n      - name: selenium-hub\n        image: selenium/hub:4.0\n        ports:\n        - containerPort: 4444\n        - containerPort: 4443\n        - containerPort: 4442\n        resources:\n          limits:\n            memory: 1000Mi\n            cpu: '.5'\n        livenessProbe:\n          httpGet:\n            path: /wd/hub/status\n            port: 4444\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /wd/hub/status\n            port: 4444\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdspryjt3.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdspryjt3.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdspryjt3.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdspryjt3.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdspryjt3.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/selenium/selenium-hub-deployment.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: selenium-hub\n  labels:\n    app: selenium-hub\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: selenium-hub\n  template:\n    metadata:\n      labels:\n        app: selenium-hub\n    spec:\n      containers:\n      - name: selenium-hub\n        image: selenium/hub:4.0\n        ports:\n        - containerPort: 4444\n        - containerPort: 4443\n        - containerPort: 4442\n        livenessProbe:\n          httpGet:\n            path: /wd/hub/status\n            port: 4444\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /wd/hub/status\n            port: 4444\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcw7a64ep.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcw7a64ep.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcw7a64ep.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcw7a64ep.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/selenium/selenium-hub-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: selenium-hub\n  labels:\n    app: selenium-hub\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: selenium-hub\n  template:\n    metadata:\n      labels:\n        app: selenium-hub\n    spec:\n      containers:\n      - name: selenium-hub\n        image: selenium/hub:4.0\n        ports:\n        - containerPort: 4444\n        - containerPort: 4443\n        - containerPort: 4442\n        resources:\n          limits:\n            memory: 1000Mi\n            cpu: '.5'\n        livenessProbe:\n          httpGet:\n            path: /wd/hub/status\n            port: 4444\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        readinessProbe:\n          httpGet:\n            path: /wd/hub/status\n            port: 4444\n          initialDelaySeconds: 30\n          timeoutSeconds: 5\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-fzwik6\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-i8nq18\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsus27y7p.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsus27y7p.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsus27y7p.yaml: (object: <no namespace>/selenium-hub apps/v1, Kind=Deployment) container \"selenium-hub\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/flexvolume/nginx-dummy.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-dummy\n  namespace: default\nspec:\n  containers:\n  - name: nginx-dummy\n    image: nginx\n    volumeMounts:\n    - name: dummy\n      mountPath: /data\n    ports:\n    - containerPort: 80\n    securityContext:\n      privileged: true\n  volumes:\n  - name: dummy\n    flexVolume:\n      driver: k8s/dummy\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpy6sjfnkk.yaml: (object: default/nginx-dummy /v1, Kind=Pod) The container \"nginx-dummy\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpy6sjfnkk.yaml: (object: default/nginx-dummy /v1, Kind=Pod) container \"nginx-dummy\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpy6sjfnkk.yaml: (object: default/nginx-dummy /v1, Kind=Pod) container \"nginx-dummy\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpy6sjfnkk.yaml: (object: default/nginx-dummy /v1, Kind=Pod) container \"nginx-dummy\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpy6sjfnkk.yaml: (object: default/nginx-dummy /v1, Kind=Pod) container \"nginx-dummy\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpy6sjfnkk.yaml: (object: default/nginx-dummy /v1, Kind=Pod) container \"nginx-dummy\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpy6sjfnkk.yaml: (object: default/nginx-dummy /v1, Kind=Pod) container \"nginx-dummy\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/flexvolume/nginx-dummy.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-dummy\n  namespace: default\nspec:\n  containers:\n  - name: nginx-dummy\n    image: nginx\n    volumeMounts:\n    - name: dummy\n      mountPath: /data\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-p00b85\n    ports:\n    - containerPort: 80\n  volumes:\n  - name: dummy\n    flexVolume:\n      driver: k8s/dummy\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-dofpbd\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpucwoox5k.yaml: (object: default/nginx-dummy /v1, Kind=Pod) The container \"nginx-dummy\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpucwoox5k.yaml: (object: default/nginx-dummy /v1, Kind=Pod) container \"nginx-dummy\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpucwoox5k.yaml: (object: default/nginx-dummy /v1, Kind=Pod) container \"nginx-dummy\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpucwoox5k.yaml: (object: default/nginx-dummy /v1, Kind=Pod) container \"nginx-dummy\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpucwoox5k.yaml: (object: default/nginx-dummy /v1, Kind=Pod) container \"nginx-dummy\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cpu-manager/exclusive-2.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-2\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-2\n    resources:\n      requests:\n        cpu: 2\n        memory: 256M\n      limits:\n        cpu: 2\n        memory: 256M\n    securityContext:\n      privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1gnvvi0n.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) The container \"exclusive-2\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1gnvvi0n.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) container \"exclusive-2\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1gnvvi0n.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) container \"exclusive-2\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1gnvvi0n.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) container \"exclusive-2\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1gnvvi0n.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) container \"exclusive-2\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cpu-manager/exclusive-2.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-2\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-2\n    resources:\n      requests:\n        cpu: 2\n        memory: 256M\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0es156hg.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) The container \"exclusive-2\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0es156hg.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) container \"exclusive-2\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0es156hg.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) container \"exclusive-2\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0es156hg.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) container \"exclusive-2\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cpu-manager/exclusive-2.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-2\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-2\n    resources:\n      requests:\n        cpu: 2\n        memory: 256M\n      limits:\n        cpu: 2\n        memory: 256M\n    volumeMounts:\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-t3srgh\n  volumes:\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-5sev2f\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpal45r0q2.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) The container \"exclusive-2\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpal45r0q2.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) container \"exclusive-2\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpal45r0q2.yaml: (object: <no namespace>/exclusive-2 /v1, Kind=Pod) container \"exclusive-2\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/redis-master-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-master\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: master\n      tier: backend\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: master\n        tier: backend\n    spec:\n      containers:\n      - name: master\n        image: registry.k8s.io/redis:e2e\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 6379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx8pol717.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx8pol717.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx8pol717.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx8pol717.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx8pol717.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/redis-master-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-master\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: master\n      tier: backend\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: master\n        tier: backend\n    spec:\n      containers:\n      - name: master\n        image: registry.k8s.io/redis:e2e\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 6379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-ubsjai\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-ijgcy1\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpffo_se1h.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpffo_se1h.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpffo_se1h.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/elasticsearch/production_cluster/es-data-rc.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es-data\n  labels:\n    component: elasticsearch\n    role: data\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n        role: data\n    spec:\n      serviceAccount: elasticsearch\n      containers:\n      - name: es-data\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n          privileged: true\n        image: quay.io/pires/docker-elasticsearch-kubernetes:1.7.1-4\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: myesdb\n        - name: NODE_MASTER\n          value: 'false'\n        - name: HTTP_ENABLE\n          value: 'false'\n        ports:\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n      volumes:\n      - name: storage\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1du2588_.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) serviceAccount is specified (elasticsearch), but this field is deprecated; use serviceAccountName instead (check: deprecated-service-account-field, remediation: Use the serviceAccountName field instead. If you must specify serviceAccount, ensure values for serviceAccount and serviceAccountName match.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1du2588_.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1du2588_.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1du2588_.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) serviceAccount \"elasticsearch\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1du2588_.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1du2588_.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1du2588_.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1du2588_.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1du2588_.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 9 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/elasticsearch/production_cluster/es-data-rc.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es-data\n  labels:\n    component: elasticsearch\n    role: data\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n        role: data\n    spec:\n      serviceAccount: elasticsearch\n      containers:\n      - name: es-data\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n        image: quay.io/pires/docker-elasticsearch-kubernetes:1.7.1-4\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: myesdb\n        - name: NODE_MASTER\n          value: 'false'\n        - name: HTTP_ENABLE\n          value: 'false'\n        ports:\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-udaez2\n      volumes:\n      - name: storage\n        emptyDir: {}\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-pps5k1\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphpgof163.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) serviceAccount is specified (elasticsearch), but this field is deprecated; use serviceAccountName instead (check: deprecated-service-account-field, remediation: Use the serviceAccountName field instead. If you must specify serviceAccount, ensure values for serviceAccount and serviceAccountName match.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphpgof163.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphpgof163.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphpgof163.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) serviceAccount \"elasticsearch\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphpgof163.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphpgof163.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphpgof163.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/elasticsearch/production_cluster/es-data-rc.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es-data\n  labels:\n    component: elasticsearch\n    role: data\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n        role: data\n    spec:\n      serviceAccount: elasticsearch\n      containers:\n      - name: es-data\n        image: quay.io/pires/docker-elasticsearch-kubernetes:1.7.1-4\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: myesdb\n        - name: NODE_MASTER\n          value: 'false'\n        - name: HTTP_ENABLE\n          value: 'false'\n        ports:\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n      volumes:\n      - name: storage\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpiirb3di5.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) serviceAccount is specified (elasticsearch), but this field is deprecated; use serviceAccountName instead (check: deprecated-service-account-field, remediation: Use the serviceAccountName field instead. If you must specify serviceAccount, ensure values for serviceAccount and serviceAccountName match.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpiirb3di5.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpiirb3di5.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) serviceAccount \"elasticsearch\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpiirb3di5.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpiirb3di5.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpiirb3di5.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/volumes/iscsi/iscsi.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: iscsipd\nspec:\n  containers:\n  - name: iscsipd-rw\n    image: kubernetes/pause\n    volumeMounts:\n    - mountPath: /mnt/iscsipd\n      name: iscsipd-rw\n    securityContext:\n      privileged: true\n  volumes:\n  - name: iscsipd-rw\n    iscsi:\n      targetPortal: 10.0.2.15:3260\n      portals:\n      - 10.0.2.16:3260\n      - 10.0.2.17:3260\n      iqn: iqn.2001-04.com.example:storage.kube.sys1.xyz\n      lun: 0\n      fsType: ext4\n      readOnly: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi2hrzop6.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) The container \"iscsipd-rw\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi2hrzop6.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi2hrzop6.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi2hrzop6.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi2hrzop6.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi2hrzop6.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi2hrzop6.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/volumes/iscsi/iscsi.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: iscsipd\nspec:\n  containers:\n  - name: iscsipd-rw\n    image: kubernetes/pause\n    volumeMounts:\n    - mountPath: /mnt/iscsipd\n      name: iscsipd-rw\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-ah8bpn\n  volumes:\n  - name: iscsipd-rw\n    iscsi:\n      targetPortal: 10.0.2.15:3260\n      portals:\n      - 10.0.2.16:3260\n      - 10.0.2.17:3260\n      iqn: iqn.2001-04.com.example:storage.kube.sys1.xyz\n      lun: 0\n      fsType: ext4\n      readOnly: true\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-ccq1pk\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpprl9c_dy.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) The container \"iscsipd-rw\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpprl9c_dy.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpprl9c_dy.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpprl9c_dy.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpprl9c_dy.yaml: (object: <no namespace>/iscsipd /v1, Kind=Pod) container \"iscsipd-rw\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/mysql-cinder-pd/mysql.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mysql\n  labels:\n    name: mysql\nspec:\n  containers:\n  - resources:\n      limits:\n        cpu: 0.5\n    image: mysql\n    name: mysql\n    args:\n    - --ignore-db-dir\n    - lost+found\n    env:\n    - name: MYSQL_ROOT_PASSWORD\n      value: yourpassword\n    ports:\n    - containerPort: 3306\n      name: mysql\n    volumeMounts:\n    - name: mysql-persistent-storage\n      mountPath: /var/lib/mysql\n    securityContext:\n      privileged: true\n  volumes:\n  - name: mysql-persistent-storage\n    cinder:\n      volumeID: bd82f7e2-wece-4c01-a505-4acf60b07f4a\n      fsType: ext4\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsh4rmcwl.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) The container \"mysql\" is using an invalid container image, \"mysql\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsh4rmcwl.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsh4rmcwl.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsh4rmcwl.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsh4rmcwl.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsh4rmcwl.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsh4rmcwl.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/mysql-cinder-pd/mysql.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mysql\n  labels:\n    name: mysql\nspec:\n  containers:\n  - image: mysql\n    name: mysql\n    args:\n    - --ignore-db-dir\n    - lost+found\n    env:\n    - name: MYSQL_ROOT_PASSWORD\n      value: yourpassword\n    ports:\n    - containerPort: 3306\n      name: mysql\n    volumeMounts:\n    - name: mysql-persistent-storage\n      mountPath: /var/lib/mysql\n  volumes:\n  - name: mysql-persistent-storage\n    cinder:\n      volumeID: bd82f7e2-wece-4c01-a505-4acf60b07f4a\n      fsType: ext4\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkdepue_b.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) The container \"mysql\" is using an invalid container image, \"mysql\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkdepue_b.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkdepue_b.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkdepue_b.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkdepue_b.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/mysql-cinder-pd/mysql.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mysql\n  labels:\n    name: mysql\nspec:\n  containers:\n  - resources:\n      limits:\n        cpu: 0.5\n    image: mysql\n    name: mysql\n    args:\n    - --ignore-db-dir\n    - lost+found\n    env:\n    - name: MYSQL_ROOT_PASSWORD\n      value: yourpassword\n    ports:\n    - containerPort: 3306\n      name: mysql\n    volumeMounts:\n    - name: mysql-persistent-storage\n      mountPath: /var/lib/mysql\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-w3ig2z\n  volumes:\n  - name: mysql-persistent-storage\n    cinder:\n      volumeID: bd82f7e2-wece-4c01-a505-4acf60b07f4a\n      fsType: ext4\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-89omc9\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp96a4ets0.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) The container \"mysql\" is using an invalid container image, \"mysql\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp96a4ets0.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp96a4ets0.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp96a4ets0.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp96a4ets0.yaml: (object: <no namespace>/mysql /v1, Kind=Pod) container \"mysql\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/spark/spark-gluster/spark-master-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: spark-master-controller\n  namespace: spark-cluster\n  labels:\n    component: spark-master\nspec:\n  replicas: 1\n  selector:\n    component: spark-master\n  template:\n    metadata:\n      labels:\n        component: spark-master\n    spec:\n      containers:\n      - name: spark-master\n        image: registry.k8s.io/spark:1.5.2_v1\n        command:\n        - /start-master\n        ports:\n        - containerPort: 7077\n        volumeMounts:\n        - mountPath: /mnt/glusterfs\n          name: glusterfsvol\n        resources:\n          requests:\n            cpu: 100m\n        securityContext:\n          privileged: true\n      volumes:\n      - name: glusterfsvol\n        glusterfs:\n          endpoints: glusterfs-cluster\n          path: MyVolume\n          readOnly: false\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp82n9wqy8.yaml: (object: spark-cluster/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp82n9wqy8.yaml: (object: spark-cluster/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp82n9wqy8.yaml: (object: spark-cluster/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp82n9wqy8.yaml: (object: spark-cluster/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp82n9wqy8.yaml: (object: spark-cluster/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/spark/spark-gluster/spark-master-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: spark-master-controller\n  namespace: spark-cluster\n  labels:\n    component: spark-master\nspec:\n  replicas: 1\n  selector:\n    component: spark-master\n  template:\n    metadata:\n      labels:\n        component: spark-master\n    spec:\n      containers:\n      - name: spark-master\n        image: registry.k8s.io/spark:1.5.2_v1\n        command:\n        - /start-master\n        ports:\n        - containerPort: 7077\n        volumeMounts:\n        - mountPath: /mnt/glusterfs\n          name: glusterfsvol\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-u7yzff\n        resources:\n          requests:\n            cpu: 100m\n      volumes:\n      - name: glusterfsvol\n        glusterfs:\n          endpoints: glusterfs-cluster\n          path: MyVolume\n          readOnly: false\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-rorsgw\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5zfrlgol.yaml: (object: spark-cluster/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5zfrlgol.yaml: (object: spark-cluster/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5zfrlgol.yaml: (object: spark-cluster/spark-master-controller /v1, Kind=ReplicationController) container \"spark-master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/kubebuilder-declarative-pattern/examples/guestbook-operator/channels/packages/guestbook/0.1.0/manifest.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-master\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: master\n      tier: backend\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: master\n        tier: backend\n    spec:\n      containers:\n      - name: master\n        image: registry.k8s.io/redis:e2e\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 6379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjp1hbwwx.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjp1hbwwx.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjp1hbwwx.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjp1hbwwx.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjp1hbwwx.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/kubebuilder-declarative-pattern/examples/guestbook-operator/channels/packages/guestbook/0.1.0/manifest.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-master\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: master\n      tier: backend\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: master\n        tier: backend\n    spec:\n      containers:\n      - name: master\n        image: registry.k8s.io/redis:e2e\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 6379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-gk2lx1\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-ctckkc\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqdn5nsk7.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqdn5nsk7.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqdn5nsk7.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/kubebuilder-declarative-pattern/examples/guestbook-operator/channels/packages/guestbook/0.1.0/manifest.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-slave\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: slave\n      tier: backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: slave\n        tier: backend\n    spec:\n      containers:\n      - name: slave\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgg5v3ajn.yaml: (object: <no namespace>/redis-slave apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgg5v3ajn.yaml: (object: <no namespace>/redis-slave apps/v1, Kind=Deployment) container \"slave\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgg5v3ajn.yaml: (object: <no namespace>/redis-slave apps/v1, Kind=Deployment) container \"slave\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgg5v3ajn.yaml: (object: <no namespace>/redis-slave apps/v1, Kind=Deployment) container \"slave\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgg5v3ajn.yaml: (object: <no namespace>/redis-slave apps/v1, Kind=Deployment) container \"slave\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgg5v3ajn.yaml: (object: <no namespace>/redis-slave apps/v1, Kind=Deployment) container \"slave\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/kubebuilder-declarative-pattern/examples/guestbook-operator/channels/packages/guestbook/0.1.0/manifest.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-slave\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: slave\n      tier: backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: slave\n        tier: backend\n    spec:\n      containers:\n      - name: slave\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-ugcw7g\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-iio66d\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppa75v59t.yaml: (object: <no namespace>/redis-slave apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppa75v59t.yaml: (object: <no namespace>/redis-slave apps/v1, Kind=Deployment) container \"slave\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppa75v59t.yaml: (object: <no namespace>/redis-slave apps/v1, Kind=Deployment) container \"slave\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppa75v59t.yaml: (object: <no namespace>/redis-slave apps/v1, Kind=Deployment) container \"slave\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/kubebuilder-declarative-pattern/examples/guestbook-operator/channels/packages/guestbook/0.1.0/manifest.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google-samples/gb-frontend:v4\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2_qpf0ow.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2_qpf0ow.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2_qpf0ow.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2_qpf0ow.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2_qpf0ow.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2_qpf0ow.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/kubebuilder-declarative-pattern/examples/guestbook-operator/channels/packages/guestbook/0.1.0/manifest.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google-samples/gb-frontend:v4\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-donees\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-yyb293\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmsbmtk17.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmsbmtk17.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmsbmtk17.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmsbmtk17.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/volumes/cephfs/cephfs.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cephfs\nspec:\n  containers:\n  - name: cephfs-rw\n    image: kubernetes/pause\n    volumeMounts:\n    - mountPath: /mnt/cephfs\n      name: cephfs\n    securityContext:\n      privileged: true\n  volumes:\n  - name: cephfs\n    cephfs:\n      monitors:\n      - 10.16.154.78:6789\n      - 10.16.154.82:6789\n      - 10.16.154.83:6789\n      user: admin\n      secretFile: /etc/ceph/admin.secret\n      readOnly: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprty65_5g.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) The container \"cephfs-rw\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprty65_5g.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprty65_5g.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprty65_5g.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprty65_5g.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprty65_5g.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprty65_5g.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/volumes/cephfs/cephfs.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cephfs\nspec:\n  containers:\n  - name: cephfs-rw\n    image: kubernetes/pause\n    volumeMounts:\n    - mountPath: /mnt/cephfs\n      name: cephfs\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-ttv5wy\n  volumes:\n  - name: cephfs\n    cephfs:\n      monitors:\n      - 10.16.154.78:6789\n      - 10.16.154.82:6789\n      - 10.16.154.83:6789\n      user: admin\n      secretFile: /etc/ceph/admin.secret\n      readOnly: true\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-nce99z\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5_mptwwu.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) The container \"cephfs-rw\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5_mptwwu.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5_mptwwu.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5_mptwwu.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5_mptwwu.yaml: (object: <no namespace>/cephfs /v1, Kind=Pod) container \"cephfs-rw\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/javaweb-tomcat-sidecar/javaweb.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: javaweb\nspec:\n  initContainers:\n  - image: resouer/sample:v1\n    name: war\n    command:\n    - cp\n    - /sample.war\n    - /app\n    volumeMounts:\n    - mountPath: /app\n      name: app-volume\n  containers:\n  - image: resouer/mytomcat:7.0\n    name: tomcat\n    command:\n    - sh\n    - -c\n    - /root/apache-tomcat-7.0.42-v2/bin/start.sh\n    volumeMounts:\n    - mountPath: /root/apache-tomcat-7.0.42-v2/webapps\n      name: app-volume\n    ports:\n    - containerPort: 8080\n      hostPort: 8001\n    securityContext:\n      privileged: true\n  volumes:\n  - name: app-volume\n    emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7tsyty52.yaml: (object: <no namespace>/javaweb /v1, Kind=Pod) container \"war\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7tsyty52.yaml: (object: <no namespace>/javaweb /v1, Kind=Pod) container \"tomcat\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7tsyty52.yaml: (object: <no namespace>/javaweb /v1, Kind=Pod) container \"tomcat\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7tsyty52.yaml: (object: <no namespace>/javaweb /v1, Kind=Pod) container \"tomcat\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7tsyty52.yaml: (object: <no namespace>/javaweb /v1, Kind=Pod) container \"war\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7tsyty52.yaml: (object: <no namespace>/javaweb /v1, Kind=Pod) container \"tomcat\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7tsyty52.yaml: (object: <no namespace>/javaweb /v1, Kind=Pod) container \"war\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7tsyty52.yaml: (object: <no namespace>/javaweb /v1, Kind=Pod) container \"tomcat\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7tsyty52.yaml: (object: <no namespace>/javaweb /v1, Kind=Pod) container \"war\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7tsyty52.yaml: (object: <no namespace>/javaweb /v1, Kind=Pod) container \"tomcat\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 10 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/javaweb-tomcat-sidecar/javaweb.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: javaweb\nspec:\n  initContainers:\n  - image: resouer/sample:v1\n    name: war\n    command:\n    - cp\n    - /sample.war\n    - /app\n    volumeMounts:\n    - mountPath: /app\n      name: app-volume\n  containers:\n  - image: resouer/mytomcat:7.0\n    name: tomcat\n    command:\n    - sh\n    - -c\n    - /root/apache-tomcat-7.0.42-v2/bin/start.sh\n    volumeMounts:\n    - mountPath: /root/apache-tomcat-7.0.42-v2/webapps\n      name: app-volume\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-g8m771\n    ports:\n    - containerPort: 8080\n      hostPort: 8001\n  volumes:\n  - name: app-volume\n    emptyDir: {}\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-8xeumx\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplce_vvqa.yaml: (object: <no namespace>/javaweb /v1, Kind=Pod) container \"war\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplce_vvqa.yaml: (object: <no namespace>/javaweb /v1, Kind=Pod) container \"tomcat\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplce_vvqa.yaml: (object: <no namespace>/javaweb /v1, Kind=Pod) container \"war\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplce_vvqa.yaml: (object: <no namespace>/javaweb /v1, Kind=Pod) container \"tomcat\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplce_vvqa.yaml: (object: <no namespace>/javaweb /v1, Kind=Pod) container \"war\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplce_vvqa.yaml: (object: <no namespace>/javaweb /v1, Kind=Pod) container \"tomcat\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplce_vvqa.yaml: (object: <no namespace>/javaweb /v1, Kind=Pod) container \"war\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplce_vvqa.yaml: (object: <no namespace>/javaweb /v1, Kind=Pod) container \"tomcat\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook-go/guestbook-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: guestbook\n  labels:\n    app: guestbook\nspec:\n  replicas: 3\n  selector:\n    app: guestbook\n  template:\n    metadata:\n      labels:\n        app: guestbook\n    spec:\n      containers:\n      - name: guestbook\n        image: registry.k8s.io/guestbook:v3\n        ports:\n        - name: http-server\n          containerPort: 3000\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq71cgqi_.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq71cgqi_.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq71cgqi_.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq71cgqi_.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq71cgqi_.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq71cgqi_.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq71cgqi_.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook-go/guestbook-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: guestbook\n  labels:\n    app: guestbook\nspec:\n  replicas: 3\n  selector:\n    app: guestbook\n  template:\n    metadata:\n      labels:\n        app: guestbook\n    spec:\n      containers:\n      - name: guestbook\n        image: registry.k8s.io/guestbook:v3\n        ports:\n        - name: http-server\n          containerPort: 3000\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-blo4ps\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-aed3rk\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkljzd0tf.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkljzd0tf.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkljzd0tf.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkljzd0tf.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkljzd0tf.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/vitess/vttablet-pod-template.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: vttablet-{{uid}}\n  labels:\n    component: vttablet\n    keyspace: '{{keyspace}}'\n    shard: '{{shard_label}}'\n    tablet: '{{alias}}'\n    app: vitess\nspec:\n  containers:\n  - name: vttablet\n    image: vitess/lite:v2.0.0-alpha5\n    volumeMounts:\n    - name: syslog\n      mountPath: /dev/log\n    - name: vtdataroot\n      mountPath: /vt/vtdataroot\n    - name: certs\n      readOnly: true\n      mountPath: /etc/ssl/certs\n    resources:\n      limits:\n        memory: 1Gi\n        cpu: 500m\n    command:\n    - bash\n    - -c\n    - 'set -e\n\n      mysql_socket=\"$VTDATAROOT/{{tablet_subdir}}/mysql.sock\"\n\n      mkdir -p $VTDATAROOT/tmp\n\n      chown -R vitess /vt\n\n      while [ ! -e $mysql_socket ]; do echo \"[$(date)] waiting for $mysql_socket\"\n      ; sleep 1 ; done\n\n      su -p -s /bin/bash -c \"mysql -u vt_dba -S $mysql_socket -e ''CREATE DATABASE\n      IF NOT EXISTS vt_{{keyspace}}''\" vitess\n\n      su -p -s /bin/bash -c \"/vt/bin/vttablet -topo_implementation etcd -etcd_global_addrs\n      http://$ETCD_GLOBAL_SERVICE_HOST:$ETCD_GLOBAL_SERVICE_PORT -log_dir $VTDATAROOT/tmp\n      -alsologtostderr -port {{port}} -grpc_port {{grpc_port}} -service_map ''grpc-queryservice,grpc-tabletmanager,grpc-updatestream''\n      -binlog_player_protocol grpc -tablet-path {{alias}} -tablet_hostname $(hostname\n      -i) -init_keyspace {{keyspace}} -init_shard {{shard}} -target_tablet_type {{tablet_type}}\n      -mysqlctl_socket $VTDATAROOT/mysqlctl.sock -db-config-app-uname vt_app -db-config-app-dbname\n      vt_{{keyspace}} -db-config-app-charset utf8 -db-config-dba-uname vt_dba -db-config-dba-dbname\n      vt_{{keyspace}} -db-config-dba-charset utf8 -db-config-repl-uname vt_repl -db-config-repl-dbname\n      vt_{{keyspace}} -db-config-repl-charset utf8 -db-config-filtered-uname vt_filtered\n      -db-config-filtered-dbname vt_{{keyspace}} -db-config-filtered-charset utf8\n      -enable-rowcache -rowcache-bin /usr/bin/memcached -rowcache-socket $VTDATAROOT/{{tablet_subdir}}/memcache.sock\n      -health_check_interval 5s -restore_from_backup {{backup_flags}}\" vitess'\n    securityContext:\n      privileged: true\n  - name: mysql\n    image: vitess/lite:v2.0.0-alpha5\n    volumeMounts:\n    - name: syslog\n      mountPath: /dev/log\n    - name: vtdataroot\n      mountPath: /vt/vtdataroot\n    resources:\n      limits:\n        memory: 1Gi\n        cpu: 500m\n    command:\n    - sh\n    - -c\n    - 'mkdir -p $VTDATAROOT/tmp && chown -R vitess /vt\n\n      su -p -c \"/vt/bin/mysqlctld -log_dir $VTDATAROOT/tmp -alsologtostderr -tablet_uid\n      {{uid}} -socket_file $VTDATAROOT/mysqlctl.sock -db-config-app-uname vt_app -db-config-app-dbname\n      vt_{{keyspace}} -db-config-app-charset utf8 -db-config-dba-uname vt_dba -db-config-dba-dbname\n      vt_{{keyspace}} -db-config-dba-charset utf8 -db-config-repl-uname vt_repl -db-config-repl-dbname\n      vt_{{keyspace}} -db-config-repl-charset utf8 -db-config-filtered-uname vt_filtered\n      -db-config-filtered-dbname vt_{{keyspace}} -db-config-filtered-charset utf8\n      -bootstrap_archive mysql-db-dir_10.0.13-MariaDB.tbz\" vitess'\n    env:\n    - name: EXTRA_MY_CNF\n      value: /vt/config/mycnf/master_mariadb.cnf\n  volumes:\n  - name: syslog\n    hostPath:\n      path: /dev/log\n  - name: vtdataroot\n    emptyDir: {}\n  - name: certs\n    hostPath:\n      path: /etc/ssl/certs\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt58g7xvz.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt58g7xvz.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt58g7xvz.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt58g7xvz.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt58g7xvz.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt58g7xvz.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt58g7xvz.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt58g7xvz.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/vitess/vttablet-pod-template.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: vttablet-{{uid}}\n  labels:\n    component: vttablet\n    keyspace: '{{keyspace}}'\n    shard: '{{shard_label}}'\n    tablet: '{{alias}}'\n    app: vitess\nspec:\n  containers:\n  - name: vttablet\n    image: vitess/lite:v2.0.0-alpha5\n    volumeMounts:\n    - name: syslog\n      mountPath: /dev/log\n    - name: vtdataroot\n      mountPath: /vt/vtdataroot\n    - name: certs\n      readOnly: true\n      mountPath: /etc/ssl/certs\n    command:\n    - bash\n    - -c\n    - 'set -e\n\n      mysql_socket=\"$VTDATAROOT/{{tablet_subdir}}/mysql.sock\"\n\n      mkdir -p $VTDATAROOT/tmp\n\n      chown -R vitess /vt\n\n      while [ ! -e $mysql_socket ]; do echo \"[$(date)] waiting for $mysql_socket\"\n      ; sleep 1 ; done\n\n      su -p -s /bin/bash -c \"mysql -u vt_dba -S $mysql_socket -e ''CREATE DATABASE\n      IF NOT EXISTS vt_{{keyspace}}''\" vitess\n\n      su -p -s /bin/bash -c \"/vt/bin/vttablet -topo_implementation etcd -etcd_global_addrs\n      http://$ETCD_GLOBAL_SERVICE_HOST:$ETCD_GLOBAL_SERVICE_PORT -log_dir $VTDATAROOT/tmp\n      -alsologtostderr -port {{port}} -grpc_port {{grpc_port}} -service_map ''grpc-queryservice,grpc-tabletmanager,grpc-updatestream''\n      -binlog_player_protocol grpc -tablet-path {{alias}} -tablet_hostname $(hostname\n      -i) -init_keyspace {{keyspace}} -init_shard {{shard}} -target_tablet_type {{tablet_type}}\n      -mysqlctl_socket $VTDATAROOT/mysqlctl.sock -db-config-app-uname vt_app -db-config-app-dbname\n      vt_{{keyspace}} -db-config-app-charset utf8 -db-config-dba-uname vt_dba -db-config-dba-dbname\n      vt_{{keyspace}} -db-config-dba-charset utf8 -db-config-repl-uname vt_repl -db-config-repl-dbname\n      vt_{{keyspace}} -db-config-repl-charset utf8 -db-config-filtered-uname vt_filtered\n      -db-config-filtered-dbname vt_{{keyspace}} -db-config-filtered-charset utf8\n      -enable-rowcache -rowcache-bin /usr/bin/memcached -rowcache-socket $VTDATAROOT/{{tablet_subdir}}/memcache.sock\n      -health_check_interval 5s -restore_from_backup {{backup_flags}}\" vitess'\n  - name: mysql\n    image: vitess/lite:v2.0.0-alpha5\n    volumeMounts:\n    - name: syslog\n      mountPath: /dev/log\n    - name: vtdataroot\n      mountPath: /vt/vtdataroot\n    command:\n    - sh\n    - -c\n    - 'mkdir -p $VTDATAROOT/tmp && chown -R vitess /vt\n\n      su -p -c \"/vt/bin/mysqlctld -log_dir $VTDATAROOT/tmp -alsologtostderr -tablet_uid\n      {{uid}} -socket_file $VTDATAROOT/mysqlctl.sock -db-config-app-uname vt_app -db-config-app-dbname\n      vt_{{keyspace}} -db-config-app-charset utf8 -db-config-dba-uname vt_dba -db-config-dba-dbname\n      vt_{{keyspace}} -db-config-dba-charset utf8 -db-config-repl-uname vt_repl -db-config-repl-dbname\n      vt_{{keyspace}} -db-config-repl-charset utf8 -db-config-filtered-uname vt_filtered\n      -db-config-filtered-dbname vt_{{keyspace}} -db-config-filtered-charset utf8\n      -bootstrap_archive mysql-db-dir_10.0.13-MariaDB.tbz\" vitess'\n    env:\n    - name: EXTRA_MY_CNF\n      value: /vt/config/mycnf/master_mariadb.cnf\n  volumes:\n  - name: syslog\n    hostPath:\n      path: /dev/log\n  - name: vtdataroot\n    emptyDir: {}\n  - name: certs\n    hostPath:\n      path: /etc/ssl/certs\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbi3odg4f.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbi3odg4f.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbi3odg4f.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbi3odg4f.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbi3odg4f.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbi3odg4f.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbi3odg4f.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbi3odg4f.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/vitess/vttablet-pod-template.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: vttablet-{{uid}}\n  labels:\n    component: vttablet\n    keyspace: '{{keyspace}}'\n    shard: '{{shard_label}}'\n    tablet: '{{alias}}'\n    app: vitess\nspec:\n  containers:\n  - name: vttablet\n    image: vitess/lite:v2.0.0-alpha5\n    volumeMounts:\n    - name: syslog\n      mountPath: /dev/log\n    - name: vtdataroot\n      mountPath: /vt/vtdataroot\n    - name: certs\n      readOnly: true\n      mountPath: /etc/ssl/certs\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-b28qa2\n    resources:\n      limits:\n        memory: 1Gi\n        cpu: 500m\n    command:\n    - bash\n    - -c\n    - 'set -e\n\n      mysql_socket=\"$VTDATAROOT/{{tablet_subdir}}/mysql.sock\"\n\n      mkdir -p $VTDATAROOT/tmp\n\n      chown -R vitess /vt\n\n      while [ ! -e $mysql_socket ]; do echo \"[$(date)] waiting for $mysql_socket\"\n      ; sleep 1 ; done\n\n      su -p -s /bin/bash -c \"mysql -u vt_dba -S $mysql_socket -e ''CREATE DATABASE\n      IF NOT EXISTS vt_{{keyspace}}''\" vitess\n\n      su -p -s /bin/bash -c \"/vt/bin/vttablet -topo_implementation etcd -etcd_global_addrs\n      http://$ETCD_GLOBAL_SERVICE_HOST:$ETCD_GLOBAL_SERVICE_PORT -log_dir $VTDATAROOT/tmp\n      -alsologtostderr -port {{port}} -grpc_port {{grpc_port}} -service_map ''grpc-queryservice,grpc-tabletmanager,grpc-updatestream''\n      -binlog_player_protocol grpc -tablet-path {{alias}} -tablet_hostname $(hostname\n      -i) -init_keyspace {{keyspace}} -init_shard {{shard}} -target_tablet_type {{tablet_type}}\n      -mysqlctl_socket $VTDATAROOT/mysqlctl.sock -db-config-app-uname vt_app -db-config-app-dbname\n      vt_{{keyspace}} -db-config-app-charset utf8 -db-config-dba-uname vt_dba -db-config-dba-dbname\n      vt_{{keyspace}} -db-config-dba-charset utf8 -db-config-repl-uname vt_repl -db-config-repl-dbname\n      vt_{{keyspace}} -db-config-repl-charset utf8 -db-config-filtered-uname vt_filtered\n      -db-config-filtered-dbname vt_{{keyspace}} -db-config-filtered-charset utf8\n      -enable-rowcache -rowcache-bin /usr/bin/memcached -rowcache-socket $VTDATAROOT/{{tablet_subdir}}/memcache.sock\n      -health_check_interval 5s -restore_from_backup {{backup_flags}}\" vitess'\n  - name: mysql\n    image: vitess/lite:v2.0.0-alpha5\n    volumeMounts:\n    - name: syslog\n      mountPath: /dev/log\n    - name: vtdataroot\n      mountPath: /vt/vtdataroot\n    resources:\n      limits:\n        memory: 1Gi\n        cpu: 500m\n    command:\n    - sh\n    - -c\n    - 'mkdir -p $VTDATAROOT/tmp && chown -R vitess /vt\n\n      su -p -c \"/vt/bin/mysqlctld -log_dir $VTDATAROOT/tmp -alsologtostderr -tablet_uid\n      {{uid}} -socket_file $VTDATAROOT/mysqlctl.sock -db-config-app-uname vt_app -db-config-app-dbname\n      vt_{{keyspace}} -db-config-app-charset utf8 -db-config-dba-uname vt_dba -db-config-dba-dbname\n      vt_{{keyspace}} -db-config-dba-charset utf8 -db-config-repl-uname vt_repl -db-config-repl-dbname\n      vt_{{keyspace}} -db-config-repl-charset utf8 -db-config-filtered-uname vt_filtered\n      -db-config-filtered-dbname vt_{{keyspace}} -db-config-filtered-charset utf8\n      -bootstrap_archive mysql-db-dir_10.0.13-MariaDB.tbz\" vitess'\n    env:\n    - name: EXTRA_MY_CNF\n      value: /vt/config/mycnf/master_mariadb.cnf\n  volumes:\n  - name: syslog\n    hostPath:\n      path: /dev/log\n  - name: vtdataroot\n    emptyDir: {}\n  - name: certs\n    hostPath:\n      path: /etc/ssl/certs\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-zgh0rb\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphyf2hkwb.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphyf2hkwb.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphyf2hkwb.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphyf2hkwb.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphyf2hkwb.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"vttablet\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphyf2hkwb.yaml: (object: <no namespace>/vttablet-{{uid}} /v1, Kind=Pod) container \"mysql\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/rethinkdb/rc.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    db: rethinkdb\n  name: rethinkdb-rc\nspec:\n  replicas: 1\n  selector:\n    db: rethinkdb\n    role: replicas\n  template:\n    metadata:\n      labels:\n        db: rethinkdb\n        role: replicas\n    spec:\n      containers:\n      - image: registry.k8s.io/rethinkdb:1.16.0_1\n        name: rethinkdb\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 8080\n          name: admin-port\n        - containerPort: 28015\n          name: driver-port\n        - containerPort: 29015\n          name: cluster-port\n        volumeMounts:\n        - mountPath: /data/rethinkdb_data\n          name: rethinkdb-storage\n        securityContext:\n          privileged: true\n      volumes:\n      - name: rethinkdb-storage\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbxthvgkw.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbxthvgkw.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbxthvgkw.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbxthvgkw.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbxthvgkw.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbxthvgkw.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/rethinkdb/rc.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    db: rethinkdb\n  name: rethinkdb-rc\nspec:\n  replicas: 1\n  selector:\n    db: rethinkdb\n    role: replicas\n  template:\n    metadata:\n      labels:\n        db: rethinkdb\n        role: replicas\n    spec:\n      containers:\n      - image: registry.k8s.io/rethinkdb:1.16.0_1\n        name: rethinkdb\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - containerPort: 8080\n          name: admin-port\n        - containerPort: 28015\n          name: driver-port\n        - containerPort: 29015\n          name: cluster-port\n        volumeMounts:\n        - mountPath: /data/rethinkdb_data\n          name: rethinkdb-storage\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-sjjmfz\n      volumes:\n      - name: rethinkdb-storage\n        emptyDir: {}\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-ej6xmw\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1km89e2y.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1km89e2y.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1km89e2y.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1km89e2y.yaml: (object: <no namespace>/rethinkdb-rc /v1, Kind=ReplicationController) container \"rethinkdb\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cluster-dns/dns-frontend-pod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dns-frontend\n  labels:\n    name: dns-frontend\nspec:\n  containers:\n  - name: dns-frontend\n    image: registry.k8s.io/example-dns-frontend:v1\n    command:\n    - python\n    - client.py\n    - http://dns-backend.development.svc.cluster.local:8000\n    imagePullPolicy: Always\n    securityContext:\n      privileged: true\n  restartPolicy: Never\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp07mvghr8.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp07mvghr8.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp07mvghr8.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp07mvghr8.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp07mvghr8.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp07mvghr8.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cluster-dns/dns-frontend-pod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: dns-frontend\n  labels:\n    name: dns-frontend\nspec:\n  containers:\n  - name: dns-frontend\n    image: registry.k8s.io/example-dns-frontend:v1\n    command:\n    - python\n    - client.py\n    - http://dns-backend.development.svc.cluster.local:8000\n    imagePullPolicy: Always\n    volumeMounts:\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-dbsp85\n  restartPolicy: Never\n  volumes:\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-zhdldh\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsp4nkv0z.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsp4nkv0z.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsp4nkv0z.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsp4nkv0z.yaml: (object: <no namespace>/dns-frontend /v1, Kind=Pod) container \"dns-frontend\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/vsphere/vsphere-volume-pod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-vmdk\nspec:\n  containers:\n  - image: registry.k8s.io/test-webserver\n    name: test-container\n    volumeMounts:\n    - mountPath: /test-vmdk\n      name: test-volume\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test-volume\n    vsphereVolume:\n      volumePath: '[DatastoreName] volumes/myDisk'\n      fsType: ext4\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpj6jw7gmw.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpj6jw7gmw.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpj6jw7gmw.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpj6jw7gmw.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpj6jw7gmw.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpj6jw7gmw.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpj6jw7gmw.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/vsphere/vsphere-volume-pod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-vmdk\nspec:\n  containers:\n  - image: registry.k8s.io/test-webserver\n    name: test-container\n    volumeMounts:\n    - mountPath: /test-vmdk\n      name: test-volume\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-c5d9s4\n  volumes:\n  - name: test-volume\n    vsphereVolume:\n      volumePath: '[DatastoreName] volumes/myDisk'\n      fsType: ext4\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-nxrcxv\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfk3zinc0.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfk3zinc0.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfk3zinc0.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfk3zinc0.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfk3zinc0.yaml: (object: <no namespace>/test-vmdk /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/all-in-one/frontend.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google-samples/gb-frontend:v5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblsg94am.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblsg94am.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblsg94am.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblsg94am.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblsg94am.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpblsg94am.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/all-in-one/frontend.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google-samples/gb-frontend:v5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-g4ljcu\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-ikf5hc\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpid485k3q.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpid485k3q.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpid485k3q.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpid485k3q.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/portworx/portworx-volume-pvcscpod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pvpod\nspec:\n  containers:\n  - name: test-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - name: test-volume\n      mountPath: /test-portworx-volume\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test-volume\n    persistentVolumeClaim:\n      claimName: pvcsc001\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvn9u9kkc.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvn9u9kkc.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvn9u9kkc.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvn9u9kkc.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvn9u9kkc.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvn9u9kkc.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvn9u9kkc.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/portworx/portworx-volume-pvcscpod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pvpod\nspec:\n  containers:\n  - name: test-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - name: test-volume\n      mountPath: /test-portworx-volume\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-vc1t93\n  volumes:\n  - name: test-volume\n    persistentVolumeClaim:\n      claimName: pvcsc001\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-3wscip\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbcv1ws0h.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbcv1ws0h.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbcv1ws0h.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbcv1ws0h.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbcv1ws0h.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/all-in-one/guestbook-all-in-one.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-master\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: master\n      tier: backend\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: master\n        tier: backend\n    spec:\n      containers:\n      - name: master\n        image: registry.k8s.io/redis:e2e\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 6379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt1g_ostj.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt1g_ostj.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt1g_ostj.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt1g_ostj.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt1g_ostj.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/all-in-one/guestbook-all-in-one.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-master\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: master\n      tier: backend\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: master\n        tier: backend\n    spec:\n      containers:\n      - name: master\n        image: registry.k8s.io/redis:e2e\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 6379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-arhysm\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-a1ggzs\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphx7_4jzf.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphx7_4jzf.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphx7_4jzf.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/all-in-one/guestbook-all-in-one.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-replica\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: replica\n      tier: backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: replica\n        tier: backend\n    spec:\n      containers:\n      - name: replica\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpagjth1lq.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpagjth1lq.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpagjth1lq.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpagjth1lq.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpagjth1lq.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpagjth1lq.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/all-in-one/guestbook-all-in-one.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-replica\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: replica\n      tier: backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: replica\n        tier: backend\n    spec:\n      containers:\n      - name: replica\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-m4gro0\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-3r2oy6\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5xs24x85.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5xs24x85.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5xs24x85.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5xs24x85.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/all-in-one/guestbook-all-in-one.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google-samples/gb-frontend:v5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo9m3dwzd.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo9m3dwzd.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo9m3dwzd.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo9m3dwzd.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo9m3dwzd.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo9m3dwzd.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/all-in-one/guestbook-all-in-one.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google-samples/gb-frontend:v5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-51r887\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-jihf22\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxxalrhi6.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxxalrhi6.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxxalrhi6.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxxalrhi6.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/base/redis-ha/chart/upstream.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: Deployment\napiVersion: apps/v1\nmetadata:\n  name: argocd-redis-ha-haproxy\n  namespace: argocd\n  labels:\n    app: redis-ha\n    heritage: Helm\n    release: argocd\n    chart: redis-ha-4.33.2\nspec:\n  strategy:\n    type: RollingUpdate\n  revisionHistoryLimit: 1\n  replicas: 3\n  selector:\n    matchLabels:\n      app: redis-ha-haproxy\n      release: argocd\n  template:\n    metadata:\n      name: argocd-redis-ha-haproxy\n      labels:\n        app: redis-ha-haproxy\n        release: argocd\n      annotations:\n        prometheus.io/port: '9101'\n        prometheus.io/scrape: 'true'\n        prometheus.io/path: /metrics\n        checksum/config: cd6508bdf9819601c454d0cc491fb77a209e3a88761d92514d105b6681829953\n    spec:\n      serviceAccountName: argocd-redis-ha-haproxy\n      securityContext:\n        fsGroup: 99\n        runAsNonRoot: true\n        runAsUser: 99\n      automountServiceAccountToken: true\n      nodeSelector: {}\n      tolerations: null\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app: redis-ha-haproxy\n                release: argocd\n            topologyKey: kubernetes.io/hostname\n      initContainers:\n      - name: config-init\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        resources: {}\n        command:\n        - sh\n        args:\n        - /readonly/haproxy_init.sh\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - name: config-volume\n          mountPath: /readonly\n          readOnly: true\n        - name: data\n          mountPath: /data\n      containers:\n      - name: haproxy\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        ports:\n        - name: probe\n          containerPort: 8888\n        - name: redis\n          containerPort: 6379\n        - name: metrics-port\n          containerPort: 9101\n        resources: {}\n        volumeMounts:\n        - name: data\n          mountPath: /usr/local/etc/haproxy\n        - name: shared-socket\n          mountPath: /run/haproxy\n        lifecycle: {}\n      volumes:\n      - name: config-volume\n        configMap:\n          name: argocd-redis-ha-configmap\n      - name: shared-socket\n        emptyDir: {}\n      - name: data\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2_ln9_bw.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2_ln9_bw.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2_ln9_bw.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) serviceAccount \"argocd-redis-ha-haproxy\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2_ln9_bw.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2_ln9_bw.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2_ln9_bw.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2_ln9_bw.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2_ln9_bw.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2_ln9_bw.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 9 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/base/redis-ha/chart/upstream.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "kind: Deployment\napiVersion: apps/v1\nmetadata:\n  name: argocd-redis-ha-haproxy\n  namespace: argocd\n  labels:\n    app: redis-ha\n    heritage: Helm\n    release: argocd\n    chart: redis-ha-4.33.2\nspec:\n  strategy:\n    type: RollingUpdate\n  revisionHistoryLimit: 1\n  replicas: 3\n  selector:\n    matchLabels:\n      app: redis-ha-haproxy\n      release: argocd\n  template:\n    metadata:\n      name: argocd-redis-ha-haproxy\n      labels:\n        app: redis-ha-haproxy\n        release: argocd\n      annotations:\n        prometheus.io/port: '9101'\n        prometheus.io/scrape: 'true'\n        prometheus.io/path: /metrics\n        checksum/config: cd6508bdf9819601c454d0cc491fb77a209e3a88761d92514d105b6681829953\n    spec:\n      serviceAccountName: argocd-redis-ha-haproxy\n      securityContext:\n        fsGroup: 99\n        runAsNonRoot: true\n        runAsUser: 99\n      automountServiceAccountToken: true\n      nodeSelector: {}\n      tolerations: null\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app: redis-ha-haproxy\n                release: argocd\n            topologyKey: kubernetes.io/hostname\n      initContainers:\n      - name: config-init\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - /readonly/haproxy_init.sh\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - name: config-volume\n          mountPath: /readonly\n          readOnly: true\n        - name: data\n          mountPath: /data\n      containers:\n      - name: haproxy\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        ports:\n        - name: probe\n          containerPort: 8888\n        - name: redis\n          containerPort: 6379\n        - name: metrics-port\n          containerPort: 9101\n        volumeMounts:\n        - name: data\n          mountPath: /usr/local/etc/haproxy\n        - name: shared-socket\n          mountPath: /run/haproxy\n        lifecycle: {}\n      volumes:\n      - name: config-volume\n        configMap:\n          name: argocd-redis-ha-configmap\n      - name: shared-socket\n        emptyDir: {}\n      - name: data\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq8zp7yt6.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq8zp7yt6.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq8zp7yt6.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) serviceAccount \"argocd-redis-ha-haproxy\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq8zp7yt6.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq8zp7yt6.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq8zp7yt6.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq8zp7yt6.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/base/redis-ha/chart/upstream.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: Deployment\napiVersion: apps/v1\nmetadata:\n  name: argocd-redis-ha-haproxy\n  namespace: argocd\n  labels:\n    app: redis-ha\n    heritage: Helm\n    release: argocd\n    chart: redis-ha-4.33.2\nspec:\n  strategy:\n    type: RollingUpdate\n  revisionHistoryLimit: 1\n  replicas: 3\n  selector:\n    matchLabels:\n      app: redis-ha-haproxy\n      release: argocd\n  template:\n    metadata:\n      name: argocd-redis-ha-haproxy\n      labels:\n        app: redis-ha-haproxy\n        release: argocd\n      annotations:\n        prometheus.io/port: '9101'\n        prometheus.io/scrape: 'true'\n        prometheus.io/path: /metrics\n        checksum/config: cd6508bdf9819601c454d0cc491fb77a209e3a88761d92514d105b6681829953\n    spec:\n      serviceAccountName: argocd-redis-ha-haproxy\n      securityContext:\n        fsGroup: 99\n        runAsNonRoot: true\n        runAsUser: 99\n      automountServiceAccountToken: true\n      nodeSelector: {}\n      tolerations: null\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app: redis-ha-haproxy\n                release: argocd\n            topologyKey: kubernetes.io/hostname\n      initContainers:\n      - name: config-init\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        resources: {}\n        command:\n        - sh\n        args:\n        - /readonly/haproxy_init.sh\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - name: config-volume\n          mountPath: /readonly\n          readOnly: true\n        - name: data\n          mountPath: /data\n      containers:\n      - name: haproxy\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        ports:\n        - name: probe\n          containerPort: 8888\n        - name: redis\n          containerPort: 6379\n        - name: metrics-port\n          containerPort: 9101\n        resources: {}\n        volumeMounts:\n        - name: data\n          mountPath: /usr/local/etc/haproxy\n        - name: shared-socket\n          mountPath: /run/haproxy\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-xw0or0\n        lifecycle: {}\n      volumes:\n      - name: config-volume\n        configMap:\n          name: argocd-redis-ha-configmap\n      - name: shared-socket\n        emptyDir: {}\n      - name: data\n        emptyDir: {}\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-zytfz0\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplvcb6nxr.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplvcb6nxr.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplvcb6nxr.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) serviceAccount \"argocd-redis-ha-haproxy\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplvcb6nxr.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplvcb6nxr.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplvcb6nxr.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplvcb6nxr.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/base/redis-ha/chart/upstream.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "kind: Deployment\napiVersion: apps/v1\nmetadata:\n  name: argocd-redis-ha-haproxy\n  namespace: argocd\n  labels:\n    app: redis-ha\n    heritage: Helm\n    release: argocd\n    chart: redis-ha-4.33.2\nspec:\n  strategy:\n    type: RollingUpdate\n  revisionHistoryLimit: 1\n  replicas: 3\n  selector:\n    matchLabels:\n      app: redis-ha-haproxy\n      release: argocd\n  template:\n    metadata:\n      name: argocd-redis-ha-haproxy\n      labels:\n        app: redis-ha-haproxy\n        release: argocd\n      annotations:\n        prometheus.io/port: '9101'\n        prometheus.io/scrape: 'true'\n        prometheus.io/path: /metrics\n        checksum/config: cd6508bdf9819601c454d0cc491fb77a209e3a88761d92514d105b6681829953\n    spec:\n      serviceAccountName: argocd-redis-ha-haproxy\n      automountServiceAccountToken: true\n      nodeSelector: {}\n      tolerations: null\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app: redis-ha-haproxy\n                release: argocd\n            topologyKey: kubernetes.io/hostname\n      initContainers:\n      - name: config-init\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        resources: {}\n        command:\n        - sh\n        args:\n        - /readonly/haproxy_init.sh\n        volumeMounts:\n        - name: config-volume\n          mountPath: /readonly\n          readOnly: true\n        - name: data\n          mountPath: /data\n      containers:\n      - name: haproxy\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        ports:\n        - name: probe\n          containerPort: 8888\n        - name: redis\n          containerPort: 6379\n        - name: metrics-port\n          containerPort: 9101\n        resources: {}\n        volumeMounts:\n        - name: data\n          mountPath: /usr/local/etc/haproxy\n        - name: shared-socket\n          mountPath: /run/haproxy\n        lifecycle: {}\n      volumes:\n      - name: config-volume\n        configMap:\n          name: argocd-redis-ha-configmap\n      - name: shared-socket\n        emptyDir: {}\n      - name: data\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0wh1omrh.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0wh1omrh.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0wh1omrh.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) serviceAccount \"argocd-redis-ha-haproxy\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0wh1omrh.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0wh1omrh.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0wh1omrh.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0wh1omrh.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0wh1omrh.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0wh1omrh.yaml: (object: argocd/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 9 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/base/redis-ha/chart/upstream.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: argocd-redis-ha-server\n  namespace: argocd\n  labels:\n    argocd-redis-ha: replica\n    app: redis-ha\n    heritage: Helm\n    release: argocd\n    chart: redis-ha-4.33.2\n  annotations: {}\nspec:\n  selector:\n    matchLabels:\n      release: argocd\n      app: redis-ha\n  serviceName: argocd-redis-ha\n  replicas: 3\n  podManagementPolicy: OrderedReady\n  updateStrategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        checksum/init-config: bd30e83dfdad9912b6c1cc32a8c26d7d01429a0730f5ee7af380fb593e874d54\n      labels:\n        release: argocd\n        app: redis-ha\n        argocd-redis-ha: replica\n    spec:\n      terminationGracePeriodSeconds: 60\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app: redis-ha\n                release: argocd\n                argocd-redis-ha: replica\n            topologyKey: kubernetes.io/hostname\n      securityContext:\n        fsGroup: 1000\n        runAsNonRoot: true\n        runAsUser: 1000\n      serviceAccountName: argocd-redis-ha\n      automountServiceAccountToken: false\n      initContainers:\n      - name: config-init\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        resources: {}\n        command:\n        - sh\n        args:\n        - /readonly-config/init.sh\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          runAsUser: 1000\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        volumeMounts:\n        - name: config\n          mountPath: /readonly-config\n          readOnly: true\n        - name: data\n          mountPath: /data\n      containers:\n      - name: redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        command:\n        - redis-server\n        args:\n        - /data/conf/redis.conf\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          runAsUser: 1000\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        livenessProbe:\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_liveness.sh\n        readinessProbe:\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n        startupProbe:\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 3\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n        resources: {}\n        ports:\n        - name: redis\n          containerPort: 6379\n        volumeMounts:\n        - name: config\n          mountPath: /readonly-config\n          readOnly: true\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n        lifecycle:\n          preStop:\n            exec:\n              command:\n              - /bin/sh\n              - /readonly-config/trigger-failover-if-master.sh\n      - name: sentinel\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        command:\n        - redis-sentinel\n        args:\n        - /data/conf/sentinel.conf\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          runAsUser: 1000\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        livenessProbe:\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n        readinessProbe:\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          timeoutSeconds: 15\n          successThreshold: 3\n          failureThreshold: 5\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n        startupProbe:\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 3\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n        resources: {}\n        ports:\n        - name: sentinel\n          containerPort: 26379\n        volumeMounts:\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - /bin/sh\n              - -c\n              - sleep 30; redis-cli -p 26379 sentinel reset argocd\n      - name: split-brain-fix\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - /readonly-config/fix-split-brain.sh\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          runAsUser: 1000\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        resources: {}\n        volumeMounts:\n        - name: config\n          mountPath: /readonly-config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      volumes:\n      - name: config\n        configMap:\n          name: argocd-redis-ha-configmap\n      - name: health\n        configMap:\n          name: argocd-redis-ha-health-configmap\n          defaultMode: 493\n      - name: data\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0z47ihns.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0z47ihns.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0z47ihns.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0z47ihns.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0z47ihns.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) serviceAccount \"argocd-redis-ha\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0z47ihns.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0z47ihns.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0z47ihns.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0z47ihns.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0z47ihns.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0z47ihns.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0z47ihns.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0z47ihns.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0z47ihns.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0z47ihns.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 15 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/base/redis-ha/chart/upstream.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: argocd-redis-ha-server\n  namespace: argocd\n  labels:\n    argocd-redis-ha: replica\n    app: redis-ha\n    heritage: Helm\n    release: argocd\n    chart: redis-ha-4.33.2\n  annotations: {}\nspec:\n  selector:\n    matchLabels:\n      release: argocd\n      app: redis-ha\n  serviceName: argocd-redis-ha\n  replicas: 3\n  podManagementPolicy: OrderedReady\n  updateStrategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        checksum/init-config: bd30e83dfdad9912b6c1cc32a8c26d7d01429a0730f5ee7af380fb593e874d54\n      labels:\n        release: argocd\n        app: redis-ha\n        argocd-redis-ha: replica\n    spec:\n      terminationGracePeriodSeconds: 60\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app: redis-ha\n                release: argocd\n                argocd-redis-ha: replica\n            topologyKey: kubernetes.io/hostname\n      securityContext:\n        fsGroup: 1000\n        runAsNonRoot: true\n        runAsUser: 1000\n      serviceAccountName: argocd-redis-ha\n      automountServiceAccountToken: false\n      initContainers:\n      - name: config-init\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - /readonly-config/init.sh\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          runAsUser: 1000\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        volumeMounts:\n        - name: config\n          mountPath: /readonly-config\n          readOnly: true\n        - name: data\n          mountPath: /data\n      containers:\n      - name: redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        command:\n        - redis-server\n        args:\n        - /data/conf/redis.conf\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          runAsUser: 1000\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        livenessProbe:\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_liveness.sh\n        readinessProbe:\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n        startupProbe:\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 3\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n        ports:\n        - name: redis\n          containerPort: 6379\n        volumeMounts:\n        - name: config\n          mountPath: /readonly-config\n          readOnly: true\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n        lifecycle:\n          preStop:\n            exec:\n              command:\n              - /bin/sh\n              - /readonly-config/trigger-failover-if-master.sh\n      - name: sentinel\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        command:\n        - redis-sentinel\n        args:\n        - /data/conf/sentinel.conf\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          runAsUser: 1000\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        livenessProbe:\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n        readinessProbe:\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          timeoutSeconds: 15\n          successThreshold: 3\n          failureThreshold: 5\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n        startupProbe:\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 3\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n        ports:\n        - name: sentinel\n          containerPort: 26379\n        volumeMounts:\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - /bin/sh\n              - -c\n              - sleep 30; redis-cli -p 26379 sentinel reset argocd\n      - name: split-brain-fix\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - /readonly-config/fix-split-brain.sh\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          runAsUser: 1000\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        volumeMounts:\n        - name: config\n          mountPath: /readonly-config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      volumes:\n      - name: config\n        configMap:\n          name: argocd-redis-ha-configmap\n      - name: health\n        configMap:\n          name: argocd-redis-ha-health-configmap\n          defaultMode: 493\n      - name: data\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsfdrmdjz.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsfdrmdjz.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsfdrmdjz.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsfdrmdjz.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsfdrmdjz.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) serviceAccount \"argocd-redis-ha\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsfdrmdjz.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsfdrmdjz.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsfdrmdjz.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsfdrmdjz.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsfdrmdjz.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsfdrmdjz.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsfdrmdjz.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsfdrmdjz.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 13 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/base/redis-ha/chart/upstream.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: argocd-redis-ha-server\n  namespace: argocd\n  labels:\n    argocd-redis-ha: replica\n    app: redis-ha\n    heritage: Helm\n    release: argocd\n    chart: redis-ha-4.33.2\n  annotations: {}\nspec:\n  selector:\n    matchLabels:\n      release: argocd\n      app: redis-ha\n  serviceName: argocd-redis-ha\n  replicas: 3\n  podManagementPolicy: OrderedReady\n  updateStrategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        checksum/init-config: bd30e83dfdad9912b6c1cc32a8c26d7d01429a0730f5ee7af380fb593e874d54\n      labels:\n        release: argocd\n        app: redis-ha\n        argocd-redis-ha: replica\n    spec:\n      terminationGracePeriodSeconds: 60\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app: redis-ha\n                release: argocd\n                argocd-redis-ha: replica\n            topologyKey: kubernetes.io/hostname\n      securityContext:\n        fsGroup: 1000\n        runAsNonRoot: true\n        runAsUser: 1000\n      serviceAccountName: argocd-redis-ha\n      automountServiceAccountToken: false\n      initContainers:\n      - name: config-init\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        resources: {}\n        command:\n        - sh\n        args:\n        - /readonly-config/init.sh\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          runAsUser: 1000\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        volumeMounts:\n        - name: config\n          mountPath: /readonly-config\n          readOnly: true\n        - name: data\n          mountPath: /data\n      containers:\n      - name: redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        command:\n        - redis-server\n        args:\n        - /data/conf/redis.conf\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          runAsUser: 1000\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        livenessProbe:\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_liveness.sh\n        readinessProbe:\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n        startupProbe:\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 3\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n        resources: {}\n        ports:\n        - name: redis\n          containerPort: 6379\n        volumeMounts:\n        - name: config\n          mountPath: /readonly-config\n          readOnly: true\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-3qleg5\n        lifecycle:\n          preStop:\n            exec:\n              command:\n              - /bin/sh\n              - /readonly-config/trigger-failover-if-master.sh\n      - name: sentinel\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        command:\n        - redis-sentinel\n        args:\n        - /data/conf/sentinel.conf\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          runAsUser: 1000\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        livenessProbe:\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n        readinessProbe:\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          timeoutSeconds: 15\n          successThreshold: 3\n          failureThreshold: 5\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n        startupProbe:\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 3\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n        resources: {}\n        ports:\n        - name: sentinel\n          containerPort: 26379\n        volumeMounts:\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - /bin/sh\n              - -c\n              - sleep 30; redis-cli -p 26379 sentinel reset argocd\n      - name: split-brain-fix\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - /readonly-config/fix-split-brain.sh\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsNonRoot: true\n          runAsUser: 1000\n          seccompProfile:\n            type: RuntimeDefault\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        resources: {}\n        volumeMounts:\n        - name: config\n          mountPath: /readonly-config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      volumes:\n      - name: config\n        configMap:\n          name: argocd-redis-ha-configmap\n      - name: health\n        configMap:\n          name: argocd-redis-ha-health-configmap\n          defaultMode: 493\n      - name: data\n        emptyDir: {}\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-l16zab\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbwr6ci6r.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbwr6ci6r.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbwr6ci6r.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbwr6ci6r.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbwr6ci6r.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) serviceAccount \"argocd-redis-ha\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbwr6ci6r.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbwr6ci6r.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbwr6ci6r.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbwr6ci6r.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbwr6ci6r.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbwr6ci6r.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbwr6ci6r.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbwr6ci6r.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 13 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/base/redis-ha/chart/upstream.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: argocd-redis-ha-server\n  namespace: argocd\n  labels:\n    argocd-redis-ha: replica\n    app: redis-ha\n    heritage: Helm\n    release: argocd\n    chart: redis-ha-4.33.2\n  annotations: {}\nspec:\n  selector:\n    matchLabels:\n      release: argocd\n      app: redis-ha\n  serviceName: argocd-redis-ha\n  replicas: 3\n  podManagementPolicy: OrderedReady\n  updateStrategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        checksum/init-config: bd30e83dfdad9912b6c1cc32a8c26d7d01429a0730f5ee7af380fb593e874d54\n      labels:\n        release: argocd\n        app: redis-ha\n        argocd-redis-ha: replica\n    spec:\n      terminationGracePeriodSeconds: 60\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app: redis-ha\n                release: argocd\n                argocd-redis-ha: replica\n            topologyKey: kubernetes.io/hostname\n      serviceAccountName: argocd-redis-ha\n      automountServiceAccountToken: false\n      initContainers:\n      - name: config-init\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        resources: {}\n        command:\n        - sh\n        args:\n        - /readonly-config/init.sh\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        volumeMounts:\n        - name: config\n          mountPath: /readonly-config\n          readOnly: true\n        - name: data\n          mountPath: /data\n      containers:\n      - name: redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        command:\n        - redis-server\n        args:\n        - /data/conf/redis.conf\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        livenessProbe:\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_liveness.sh\n        readinessProbe:\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n        startupProbe:\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 3\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n        resources: {}\n        ports:\n        - name: redis\n          containerPort: 6379\n        volumeMounts:\n        - name: config\n          mountPath: /readonly-config\n          readOnly: true\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n        lifecycle:\n          preStop:\n            exec:\n              command:\n              - /bin/sh\n              - /readonly-config/trigger-failover-if-master.sh\n      - name: sentinel\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        command:\n        - redis-sentinel\n        args:\n        - /data/conf/sentinel.conf\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        livenessProbe:\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 5\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n        readinessProbe:\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          timeoutSeconds: 15\n          successThreshold: 3\n          failureThreshold: 5\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n        startupProbe:\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          timeoutSeconds: 15\n          successThreshold: 1\n          failureThreshold: 3\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n        resources: {}\n        ports:\n        - name: sentinel\n          containerPort: 26379\n        volumeMounts:\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - /bin/sh\n              - -c\n              - sleep 30; redis-cli -p 26379 sentinel reset argocd\n      - name: split-brain-fix\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        args:\n        - /readonly-config/fix-split-brain.sh\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              name: argocd-redis\n              key: auth\n        resources: {}\n        volumeMounts:\n        - name: config\n          mountPath: /readonly-config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      volumes:\n      - name: config\n        configMap:\n          name: argocd-redis-ha-configmap\n      - name: health\n        configMap:\n          name: argocd-redis-ha-health-configmap\n          defaultMode: 493\n      - name: data\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk2vqh0oc.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk2vqh0oc.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk2vqh0oc.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk2vqh0oc.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk2vqh0oc.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) serviceAccount \"argocd-redis-ha\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk2vqh0oc.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk2vqh0oc.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk2vqh0oc.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk2vqh0oc.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk2vqh0oc.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk2vqh0oc.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk2vqh0oc.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk2vqh0oc.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk2vqh0oc.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk2vqh0oc.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk2vqh0oc.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpk2vqh0oc.yaml: (object: argocd/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 17 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/flexvolume/deploy/ds.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n  name: flex-ds\nspec:\n  template:\n    metadata:\n      name: flex-deploy\n      labels:\n        app: flex-deploy\n    spec:\n      containers:\n      - image: <image_url>\n        name: flex-deploy\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /flexmnt\n          name: flexvolume-mount\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-vr9n8g\n      volumes:\n      - name: flexvolume-mount\n        hostPath:\n          path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-wyzvxt\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6ey0bnhf.yaml: (object: <no namespace>/flex-ds extensions/v1beta1, Kind=DaemonSet) disallowed API object found: extensions/v1beta1, Kind=DaemonSet (check: no-extensions-v1beta, remediation: Migrate using the apps/v1 API versions for the objects. Refer to https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/ for details.)\n\nError: found 1 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/flexvolume/deploy/ds.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n  name: flex-ds\nspec:\n  template:\n    metadata:\n      name: flex-deploy\n      labels:\n        app: flex-deploy\n    spec:\n      containers:\n      - image: <image_url>\n        name: flex-deploy\n        volumeMounts:\n        - mountPath: /flexmnt\n          name: flexvolume-mount\n      volumes:\n      - name: flexvolume-mount\n        hostPath:\n          path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7vlmpas5.yaml: (object: <no namespace>/flex-ds extensions/v1beta1, Kind=DaemonSet) disallowed API object found: extensions/v1beta1, Kind=DaemonSet (check: no-extensions-v1beta, remediation: Migrate using the apps/v1 API versions for the objects. Refer to https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/ for details.)\n\nError: found 1 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/redis-replica-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-replica\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: replica\n      tier: backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: replica\n        tier: backend\n    spec:\n      containers:\n      - name: slave\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwbbfcyik.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwbbfcyik.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"slave\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwbbfcyik.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"slave\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwbbfcyik.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"slave\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwbbfcyik.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"slave\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwbbfcyik.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"slave\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/redis-replica-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-replica\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: replica\n      tier: backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: replica\n        tier: backend\n    spec:\n      containers:\n      - name: slave\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-mmcqlq\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-imb8dk\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv_tstv4s.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv_tstv4s.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"slave\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv_tstv4s.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"slave\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpv_tstv4s.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"slave\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/newrelic/newrelic-daemonset.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: newrelic-agent\n  labels:\n    tier: monitoring\n    app: newrelic-agent\n    version: v1\nspec:\n  selector:\n    matchLabels:\n      name: newrelic\n  template:\n    metadata:\n      labels:\n        name: newrelic\n    spec:\n      hostPID: true\n      hostIPC: true\n      hostNetwork: true\n      containers:\n      - resources:\n          requests:\n            cpu: 0.15\n        securityContext:\n          privileged: true\n        env:\n        - name: NRSYSMOND_logfile\n          value: /var/log/nrsysmond.log\n        image: newrelic/nrsysmond\n        name: newrelic\n        command:\n        - bash\n        - -c\n        - source /etc/kube-newrelic/config && /usr/sbin/nrsysmond -E -F\n        volumeMounts:\n        - name: newrelic-config\n          mountPath: /etc/kube-newrelic\n          readOnly: true\n        - name: dev\n          mountPath: /dev\n        - name: run\n          mountPath: /var/run/docker.sock\n        - name: sys\n          mountPath: /sys\n        - name: log\n          mountPath: /var/log\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-g4dfwg\n      volumes:\n      - name: newrelic-config\n        secret:\n          secretName: newrelic-config\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: run\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: sys\n        hostPath:\n          path: /sys\n      - name: log\n        hostPath:\n          path: /var/log\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-w25e1d\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpicz0vkp2.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) host system directory \"/var/run/docker.sock\" is mounted on container \"newrelic\" (check: docker-sock, remediation: Ensure the Docker socket is not mounted inside any containers by removing the associated  Volume and VolumeMount in deployment yaml specification. If the Docker socket is mounted inside a container it could allow processes running within  the container to execute Docker commands which would effectively allow for full control of the host.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpicz0vkp2.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) resource shares host's IPC namespace (via hostIPC=true). (check: host-ipc, remediation: Ensure the host's IPC namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpicz0vkp2.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) resource shares host's network namespace (via hostNetwork=true). (check: host-network, remediation: Ensure the host's network namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpicz0vkp2.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) object shares the host's process namespace (via hostPID=true). (check: host-pid, remediation: Ensure the host's process namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpicz0vkp2.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) The container \"newrelic\" is using an invalid container image, \"newrelic/nrsysmond\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpicz0vkp2.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) container \"newrelic\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpicz0vkp2.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) container \"newrelic\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpicz0vkp2.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) container \"newrelic\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpicz0vkp2.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) container \"newrelic\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpicz0vkp2.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) host system directory \"/dev\" is mounted on container \"newrelic\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpicz0vkp2.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) host system directory \"/sys\" is mounted on container \"newrelic\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpicz0vkp2.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) container \"newrelic\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 12 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/newrelic/newrelic-daemonset.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: newrelic-agent\n  labels:\n    tier: monitoring\n    app: newrelic-agent\n    version: v1\nspec:\n  selector:\n    matchLabels:\n      name: newrelic\n  template:\n    metadata:\n      labels:\n        name: newrelic\n    spec:\n      hostPID: true\n      hostIPC: true\n      hostNetwork: true\n      containers:\n      - resources:\n          requests:\n            cpu: 0.15\n        env:\n        - name: NRSYSMOND_logfile\n          value: /var/log/nrsysmond.log\n        image: newrelic/nrsysmond\n        name: newrelic\n        command:\n        - bash\n        - -c\n        - source /etc/kube-newrelic/config && /usr/sbin/nrsysmond -E -F\n        volumeMounts:\n        - name: newrelic-config\n          mountPath: /etc/kube-newrelic\n          readOnly: true\n        - name: dev\n          mountPath: /dev\n        - name: run\n          mountPath: /var/run/docker.sock\n        - name: sys\n          mountPath: /sys\n        - name: log\n          mountPath: /var/log\n      volumes:\n      - name: newrelic-config\n        secret:\n          secretName: newrelic-config\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: run\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: sys\n        hostPath:\n          path: /sys\n      - name: log\n        hostPath:\n          path: /var/log\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdozsss8r.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) host system directory \"/var/run/docker.sock\" is mounted on container \"newrelic\" (check: docker-sock, remediation: Ensure the Docker socket is not mounted inside any containers by removing the associated  Volume and VolumeMount in deployment yaml specification. If the Docker socket is mounted inside a container it could allow processes running within  the container to execute Docker commands which would effectively allow for full control of the host.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdozsss8r.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) resource shares host's IPC namespace (via hostIPC=true). (check: host-ipc, remediation: Ensure the host's IPC namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdozsss8r.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) resource shares host's network namespace (via hostNetwork=true). (check: host-network, remediation: Ensure the host's network namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdozsss8r.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) object shares the host's process namespace (via hostPID=true). (check: host-pid, remediation: Ensure the host's process namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdozsss8r.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) The container \"newrelic\" is using an invalid container image, \"newrelic/nrsysmond\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdozsss8r.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) container \"newrelic\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdozsss8r.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) container \"newrelic\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdozsss8r.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) host system directory \"/dev\" is mounted on container \"newrelic\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdozsss8r.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) host system directory \"/sys\" is mounted on container \"newrelic\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdozsss8r.yaml: (object: <no namespace>/newrelic-agent apps/v1, Kind=DaemonSet) container \"newrelic\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 10 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/selenium/selenium-node-chrome-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: selenium-node-chrome\n  labels:\n    app: selenium-node-chrome\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: selenium-node-chrome\n  template:\n    metadata:\n      labels:\n        app: selenium-node-chrome\n    spec:\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n      containers:\n      - name: selenium-node-chrome\n        image: selenium/node-chrome:4.0\n        ports:\n        - containerPort: 5555\n        volumeMounts:\n        - mountPath: /dev/shm\n          name: dshm\n        env:\n        - name: SE_EVENT_BUS_HOST\n          value: selenium-hub\n        - name: SE_EVENT_BUS_SUBSCRIBE_PORT\n          value: '4443'\n        - name: SE_EVENT_BUS_PUBLISH_PORT\n          value: '4442'\n        resources:\n          limits:\n            memory: 1000Mi\n            cpu: '.5'\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkx61ljc1.yaml: (object: <no namespace>/selenium-node-chrome apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkx61ljc1.yaml: (object: <no namespace>/selenium-node-chrome apps/v1, Kind=Deployment) container \"selenium-node-chrome\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkx61ljc1.yaml: (object: <no namespace>/selenium-node-chrome apps/v1, Kind=Deployment) container \"selenium-node-chrome\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkx61ljc1.yaml: (object: <no namespace>/selenium-node-chrome apps/v1, Kind=Deployment) container \"selenium-node-chrome\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkx61ljc1.yaml: (object: <no namespace>/selenium-node-chrome apps/v1, Kind=Deployment) container \"selenium-node-chrome\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkx61ljc1.yaml: (object: <no namespace>/selenium-node-chrome apps/v1, Kind=Deployment) container \"selenium-node-chrome\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/selenium/selenium-node-chrome-deployment.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: selenium-node-chrome\n  labels:\n    app: selenium-node-chrome\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: selenium-node-chrome\n  template:\n    metadata:\n      labels:\n        app: selenium-node-chrome\n    spec:\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n      containers:\n      - name: selenium-node-chrome\n        image: selenium/node-chrome:4.0\n        ports:\n        - containerPort: 5555\n        volumeMounts:\n        - mountPath: /dev/shm\n          name: dshm\n        env:\n        - name: SE_EVENT_BUS_HOST\n          value: selenium-hub\n        - name: SE_EVENT_BUS_SUBSCRIBE_PORT\n          value: '4443'\n        - name: SE_EVENT_BUS_PUBLISH_PORT\n          value: '4442'\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8arn08v0.yaml: (object: <no namespace>/selenium-node-chrome apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8arn08v0.yaml: (object: <no namespace>/selenium-node-chrome apps/v1, Kind=Deployment) container \"selenium-node-chrome\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8arn08v0.yaml: (object: <no namespace>/selenium-node-chrome apps/v1, Kind=Deployment) container \"selenium-node-chrome\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8arn08v0.yaml: (object: <no namespace>/selenium-node-chrome apps/v1, Kind=Deployment) container \"selenium-node-chrome\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8arn08v0.yaml: (object: <no namespace>/selenium-node-chrome apps/v1, Kind=Deployment) container \"selenium-node-chrome\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/selenium/selenium-node-chrome-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: selenium-node-chrome\n  labels:\n    app: selenium-node-chrome\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: selenium-node-chrome\n  template:\n    metadata:\n      labels:\n        app: selenium-node-chrome\n    spec:\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-8snqaj\n          type: DirectoryOrCreate\n      containers:\n      - name: selenium-node-chrome\n        image: selenium/node-chrome:4.0\n        ports:\n        - containerPort: 5555\n        volumeMounts:\n        - mountPath: /dev/shm\n          name: dshm\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-omicc5\n        env:\n        - name: SE_EVENT_BUS_HOST\n          value: selenium-hub\n        - name: SE_EVENT_BUS_SUBSCRIBE_PORT\n          value: '4443'\n        - name: SE_EVENT_BUS_PUBLISH_PORT\n          value: '4442'\n        resources:\n          limits:\n            memory: 1000Mi\n            cpu: '.5'\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptju3ogse.yaml: (object: <no namespace>/selenium-node-chrome apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptju3ogse.yaml: (object: <no namespace>/selenium-node-chrome apps/v1, Kind=Deployment) container \"selenium-node-chrome\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptju3ogse.yaml: (object: <no namespace>/selenium-node-chrome apps/v1, Kind=Deployment) container \"selenium-node-chrome\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptju3ogse.yaml: (object: <no namespace>/selenium-node-chrome apps/v1, Kind=Deployment) container \"selenium-node-chrome\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cluster-dns/dns-backend-rc.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: dns-backend\n  labels:\n    name: dns-backend\nspec:\n  replicas: 1\n  selector:\n    name: dns-backend\n  template:\n    metadata:\n      labels:\n        name: dns-backend\n    spec:\n      containers:\n      - name: dns-backend\n        image: registry.k8s.io/example-dns-backend:v2\n        ports:\n        - name: backend-port\n          containerPort: 8000\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmak4g1mx.yaml: (object: <no namespace>/dns-backend /v1, Kind=ReplicationController) container \"dns-backend\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmak4g1mx.yaml: (object: <no namespace>/dns-backend /v1, Kind=ReplicationController) container \"dns-backend\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmak4g1mx.yaml: (object: <no namespace>/dns-backend /v1, Kind=ReplicationController) container \"dns-backend\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmak4g1mx.yaml: (object: <no namespace>/dns-backend /v1, Kind=ReplicationController) container \"dns-backend\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmak4g1mx.yaml: (object: <no namespace>/dns-backend /v1, Kind=ReplicationController) container \"dns-backend\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmak4g1mx.yaml: (object: <no namespace>/dns-backend /v1, Kind=ReplicationController) container \"dns-backend\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cluster-dns/dns-backend-rc.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: dns-backend\n  labels:\n    name: dns-backend\nspec:\n  replicas: 1\n  selector:\n    name: dns-backend\n  template:\n    metadata:\n      labels:\n        name: dns-backend\n    spec:\n      containers:\n      - name: dns-backend\n        image: registry.k8s.io/example-dns-backend:v2\n        ports:\n        - name: backend-port\n          containerPort: 8000\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-u0kcan\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-3dekco\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9p6hx061.yaml: (object: <no namespace>/dns-backend /v1, Kind=ReplicationController) container \"dns-backend\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9p6hx061.yaml: (object: <no namespace>/dns-backend /v1, Kind=ReplicationController) container \"dns-backend\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9p6hx061.yaml: (object: <no namespace>/dns-backend /v1, Kind=ReplicationController) container \"dns-backend\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9p6hx061.yaml: (object: <no namespace>/dns-backend /v1, Kind=ReplicationController) container \"dns-backend\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/volumes/rbd/rbd.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: rbd\nspec:\n  containers:\n  - image: kubernetes/pause\n    name: rbd-rw\n    volumeMounts:\n    - name: rbdpd\n      mountPath: /mnt/rbd\n    securityContext:\n      privileged: true\n  volumes:\n  - name: rbdpd\n    rbd:\n      monitors:\n      - 10.16.154.78:6789\n      - 10.16.154.82:6789\n      - 10.16.154.83:6789\n      pool: kube\n      image: foo\n      fsType: ext4\n      readOnly: true\n      user: admin\n      keyring: /etc/ceph/keyring\n      imageformat: '2'\n      imagefeatures: layering\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpujbxc46t.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) The container \"rbd-rw\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpujbxc46t.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpujbxc46t.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpujbxc46t.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpujbxc46t.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpujbxc46t.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpujbxc46t.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/volumes/rbd/rbd.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: rbd\nspec:\n  containers:\n  - image: kubernetes/pause\n    name: rbd-rw\n    volumeMounts:\n    - name: rbdpd\n      mountPath: /mnt/rbd\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-uxo48o\n  volumes:\n  - name: rbdpd\n    rbd:\n      monitors:\n      - 10.16.154.78:6789\n      - 10.16.154.82:6789\n      - 10.16.154.83:6789\n      pool: kube\n      image: foo\n      fsType: ext4\n      readOnly: true\n      user: admin\n      keyring: /etc/ceph/keyring\n      imageformat: '2'\n      imagefeatures: layering\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-b048wh\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpei1c7nop.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) The container \"rbd-rw\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpei1c7nop.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpei1c7nop.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpei1c7nop.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpei1c7nop.yaml: (object: <no namespace>/rbd /v1, Kind=Pod) container \"rbd-rw\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/redis/redis-sentinel-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: redis-sentinel\nspec:\n  replicas: 1\n  selector:\n    redis-sentinel: 'true'\n  template:\n    metadata:\n      labels:\n        name: redis-sentinel\n        redis-sentinel: 'true'\n        role: sentinel\n    spec:\n      containers:\n      - name: sentinel\n        image: registry.k8s.io/redis:v1\n        env:\n        - name: SENTINEL\n          value: 'true'\n        ports:\n        - containerPort: 26379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3h7dp6eq.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3h7dp6eq.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3h7dp6eq.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3h7dp6eq.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3h7dp6eq.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3h7dp6eq.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/redis/redis-sentinel-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: redis-sentinel\nspec:\n  replicas: 1\n  selector:\n    redis-sentinel: 'true'\n  template:\n    metadata:\n      labels:\n        name: redis-sentinel\n        redis-sentinel: 'true'\n        role: sentinel\n    spec:\n      containers:\n      - name: sentinel\n        image: registry.k8s.io/redis:v1\n        env:\n        - name: SENTINEL\n          value: 'true'\n        ports:\n        - containerPort: 26379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-f6yfx4\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-ibubcn\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkljn8th1.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkljn8th1.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkljn8th1.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkljn8th1.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/volumes/storageos/storageos-sc-pvcpod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: redis\n    role: master\n  name: test-storageos-redis-sc-pvc\nspec:\n  containers:\n  - name: master\n    image: kubernetes/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    resources:\n      limits:\n        cpu: '0.1'\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: redis-data\n    securityContext:\n      privileged: true\n  volumes:\n  - name: redis-data\n    persistentVolumeClaim:\n      claimName: fast0001\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp29o9ibb_.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp29o9ibb_.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp29o9ibb_.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp29o9ibb_.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp29o9ibb_.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp29o9ibb_.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/volumes/storageos/storageos-sc-pvcpod.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: redis\n    role: master\n  name: test-storageos-redis-sc-pvc\nspec:\n  containers:\n  - name: master\n    image: kubernetes/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: redis-data\n  volumes:\n  - name: redis-data\n    persistentVolumeClaim:\n      claimName: fast0001\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplou2z0w_.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplou2z0w_.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplou2z0w_.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplou2z0w_.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/volumes/storageos/storageos-sc-pvcpod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: redis\n    role: master\n  name: test-storageos-redis-sc-pvc\nspec:\n  containers:\n  - name: master\n    image: kubernetes/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    resources:\n      limits:\n        cpu: '0.1'\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: redis-data\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-o0ix51\n  volumes:\n  - name: redis-data\n    persistentVolumeClaim:\n      claimName: fast0001\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-d8fgbk\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnb8ratpp.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnb8ratpp.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnb8ratpp.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnb8ratpp.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/minio/minio-standalone-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio-deployment\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      volumes:\n      - name: storage\n        persistentVolumeClaim:\n          claimName: minio-pv-claim\n      containers:\n      - name: minio\n        image: minio/minio:latest\n        args:\n        - server\n        - /storage\n        env:\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          value: minio123\n        ports:\n        - containerPort: 9000\n          hostPort: 9000\n        volumeMounts:\n        - name: storage\n          mountPath: /storage\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxr4qjbnp.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) environment variable MINIO_SECRET_KEY in container \"minio\" found (check: env-var-secret, remediation: Do not use raw secrets in environment variables. Instead, either mount the secret as a file or use a secretKeyRef. Refer to https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxr4qjbnp.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) The container \"minio\" is using an invalid container image, \"minio/minio:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxr4qjbnp.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxr4qjbnp.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxr4qjbnp.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxr4qjbnp.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxr4qjbnp.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxr4qjbnp.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/minio/minio-standalone-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio-deployment\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      volumes:\n      - name: storage\n        persistentVolumeClaim:\n          claimName: minio-pv-claim\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-6uu0bf\n          type: DirectoryOrCreate\n      containers:\n      - name: minio\n        image: minio/minio:latest\n        args:\n        - server\n        - /storage\n        env:\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          value: minio123\n        ports:\n        - containerPort: 9000\n          hostPort: 9000\n        volumeMounts:\n        - name: storage\n          mountPath: /storage\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-c2zwj0\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnxa6lhe9.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) environment variable MINIO_SECRET_KEY in container \"minio\" found (check: env-var-secret, remediation: Do not use raw secrets in environment variables. Instead, either mount the secret as a file or use a secretKeyRef. Refer to https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnxa6lhe9.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) The container \"minio\" is using an invalid container image, \"minio/minio:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnxa6lhe9.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnxa6lhe9.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnxa6lhe9.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnxa6lhe9.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/elasticsearch/production_cluster/es-data-rc.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es-data\n  labels:\n    component: elasticsearch\n    role: data\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n        role: data\n    spec:\n      serviceAccount: elasticsearch\n      containers:\n      - name: es-data\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n          privileged: true\n        image: quay.io/pires/docker-elasticsearch-kubernetes:1.7.1-4\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: myesdb\n        - name: NODE_MASTER\n          value: 'false'\n        - name: HTTP_ENABLE\n          value: 'false'\n        ports:\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n      volumes:\n      - name: storage\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxz5vkpvh.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) serviceAccount is specified (elasticsearch), but this field is deprecated; use serviceAccountName instead (check: deprecated-service-account-field, remediation: Use the serviceAccountName field instead. If you must specify serviceAccount, ensure values for serviceAccount and serviceAccountName match.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxz5vkpvh.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxz5vkpvh.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxz5vkpvh.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) serviceAccount \"elasticsearch\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxz5vkpvh.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxz5vkpvh.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxz5vkpvh.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxz5vkpvh.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxz5vkpvh.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 9 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/elasticsearch/production_cluster/es-data-rc.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es-data\n  labels:\n    component: elasticsearch\n    role: data\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n        role: data\n    spec:\n      serviceAccount: elasticsearch\n      containers:\n      - name: es-data\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n        image: quay.io/pires/docker-elasticsearch-kubernetes:1.7.1-4\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: myesdb\n        - name: NODE_MASTER\n          value: 'false'\n        - name: HTTP_ENABLE\n          value: 'false'\n        ports:\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-bmboaa\n      volumes:\n      - name: storage\n        emptyDir: {}\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-f1iemi\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8vbkolrd.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) serviceAccount is specified (elasticsearch), but this field is deprecated; use serviceAccountName instead (check: deprecated-service-account-field, remediation: Use the serviceAccountName field instead. If you must specify serviceAccount, ensure values for serviceAccount and serviceAccountName match.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8vbkolrd.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8vbkolrd.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8vbkolrd.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) serviceAccount \"elasticsearch\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8vbkolrd.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8vbkolrd.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8vbkolrd.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/elasticsearch/production_cluster/es-data-rc.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es-data\n  labels:\n    component: elasticsearch\n    role: data\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n        role: data\n    spec:\n      serviceAccount: elasticsearch\n      containers:\n      - name: es-data\n        image: quay.io/pires/docker-elasticsearch-kubernetes:1.7.1-4\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: myesdb\n        - name: NODE_MASTER\n          value: 'false'\n        - name: HTTP_ENABLE\n          value: 'false'\n        ports:\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n      volumes:\n      - name: storage\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwyw9muh8.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) serviceAccount is specified (elasticsearch), but this field is deprecated; use serviceAccountName instead (check: deprecated-service-account-field, remediation: Use the serviceAccountName field instead. If you must specify serviceAccount, ensure values for serviceAccount and serviceAccountName match.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwyw9muh8.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwyw9muh8.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) serviceAccount \"elasticsearch\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwyw9muh8.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwyw9muh8.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwyw9muh8.yaml: (object: <no namespace>/es-data /v1, Kind=ReplicationController) container \"es-data\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/vitess/guestbook-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: guestbook\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        component: guestbook\n        app: vitess\n    spec:\n      containers:\n      - name: guestbook\n        image: vitess/guestbook:v2.0.0-alpha5\n        ports:\n        - name: http-server\n          containerPort: 8080\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 100m\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsbs3nitq.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsbs3nitq.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsbs3nitq.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsbs3nitq.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsbs3nitq.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsbs3nitq.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/vitess/guestbook-controller.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: guestbook\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        component: guestbook\n        app: vitess\n    spec:\n      containers:\n      - name: guestbook\n        image: vitess/guestbook:v2.0.0-alpha5\n        ports:\n        - name: http-server\n          containerPort: 8080\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo6i6pa6_.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo6i6pa6_.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo6i6pa6_.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo6i6pa6_.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo6i6pa6_.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/vitess/guestbook-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: guestbook\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        component: guestbook\n        app: vitess\n    spec:\n      containers:\n      - name: guestbook\n        image: vitess/guestbook:v2.0.0-alpha5\n        ports:\n        - name: http-server\n          containerPort: 8080\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 100m\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-i0tkh6\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-0p2cab\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp51swnh7y.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp51swnh7y.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp51swnh7y.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp51swnh7y.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/portworx/portworx-volume-pvcpod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pvpod\nspec:\n  containers:\n  - name: test-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - name: test-volume\n      mountPath: /test-portworx-volume\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test-volume\n    persistentVolumeClaim:\n      claimName: pvc0001\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp25o8ucug.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp25o8ucug.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp25o8ucug.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp25o8ucug.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp25o8ucug.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp25o8ucug.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp25o8ucug.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/portworx/portworx-volume-pvcpod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pvpod\nspec:\n  containers:\n  - name: test-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - name: test-volume\n      mountPath: /test-portworx-volume\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-1v7rv9\n  volumes:\n  - name: test-volume\n    persistentVolumeClaim:\n      claimName: pvc0001\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-8yxvsi\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprzm7vrfi.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprzm7vrfi.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprzm7vrfi.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprzm7vrfi.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprzm7vrfi.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/nodesjs-mongodb/mongo-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: mongo\n  name: mongo-controller\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: mongo\n    spec:\n      containers:\n      - image: mongo\n        name: mongo\n        ports:\n        - name: mongo\n          containerPort: 27017\n          hostPort: 27017\n        volumeMounts:\n        - name: mongo-persistent-storage\n          mountPath: /data/db\n        securityContext:\n          privileged: true\n      volumes:\n      - name: mongo-persistent-storage\n        gcePersistentDisk:\n          pdName: mongo-disk\n          fsType: ext4\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt0uvwhzn.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) The container \"mongo\" is using an invalid container image, \"mongo\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt0uvwhzn.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt0uvwhzn.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt0uvwhzn.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt0uvwhzn.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt0uvwhzn.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt0uvwhzn.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/nodesjs-mongodb/mongo-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: mongo\n  name: mongo-controller\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        name: mongo\n    spec:\n      containers:\n      - image: mongo\n        name: mongo\n        ports:\n        - name: mongo\n          containerPort: 27017\n          hostPort: 27017\n        volumeMounts:\n        - name: mongo-persistent-storage\n          mountPath: /data/db\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-329eep\n      volumes:\n      - name: mongo-persistent-storage\n        gcePersistentDisk:\n          pdName: mongo-disk\n          fsType: ext4\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-z3jg7s\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgw5kdgcb.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) The container \"mongo\" is using an invalid container image, \"mongo\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgw5kdgcb.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgw5kdgcb.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgw5kdgcb.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgw5kdgcb.yaml: (object: <no namespace>/mongo-controller /v1, Kind=ReplicationController) container \"mongo\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/explorer/pod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: explorer\nspec:\n  containers:\n  - name: explorer\n    image: registry.k8s.io/explorer:1.0\n    args:\n    - -port=8080\n    ports:\n    - containerPort: 8080\n      protocol: TCP\n    volumeMounts:\n    - mountPath: /mount/test-volume\n      name: test-volume\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test-volume\n    emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkky08suu.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkky08suu.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkky08suu.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkky08suu.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkky08suu.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkky08suu.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/explorer/pod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: explorer\nspec:\n  containers:\n  - name: explorer\n    image: registry.k8s.io/explorer:1.0\n    args:\n    - -port=8080\n    ports:\n    - containerPort: 8080\n      protocol: TCP\n    volumeMounts:\n    - mountPath: /mount/test-volume\n      name: test-volume\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-re91dc\n  volumes:\n  - name: test-volume\n    emptyDir: {}\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-ogpkbq\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_n4vd085.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_n4vd085.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_n4vd085.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_n4vd085.yaml: (object: <no namespace>/explorer /v1, Kind=Pod) container \"explorer\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/volumes/cephfs/cephfs-with-secret.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cephfs2\nspec:\n  containers:\n  - name: cephfs-rw\n    image: kubernetes/pause\n    volumeMounts:\n    - mountPath: /mnt/cephfs\n      name: cephfs\n    securityContext:\n      privileged: true\n  volumes:\n  - name: cephfs\n    cephfs:\n      monitors:\n      - 10.16.154.78:6789\n      - 10.16.154.82:6789\n      - 10.16.154.83:6789\n      user: admin\n      secretRef:\n        name: ceph-secret\n      readOnly: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5ot4yuzq.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) The container \"cephfs-rw\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5ot4yuzq.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5ot4yuzq.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5ot4yuzq.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5ot4yuzq.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5ot4yuzq.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5ot4yuzq.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/volumes/cephfs/cephfs-with-secret.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: cephfs2\nspec:\n  containers:\n  - name: cephfs-rw\n    image: kubernetes/pause\n    volumeMounts:\n    - mountPath: /mnt/cephfs\n      name: cephfs\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-5leirf\n  volumes:\n  - name: cephfs\n    cephfs:\n      monitors:\n      - 10.16.154.78:6789\n      - 10.16.154.82:6789\n      - 10.16.154.83:6789\n      user: admin\n      secretRef:\n        name: ceph-secret\n      readOnly: true\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-ph1qri\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpriyrp0m5.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) The container \"cephfs-rw\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpriyrp0m5.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpriyrp0m5.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpriyrp0m5.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpriyrp0m5.yaml: (object: <no namespace>/cephfs2 /v1, Kind=Pod) container \"cephfs-rw\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/azure_disk/claim/managed-disk/managed-ssd/pod-uses-managed-ssd.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-uses-managed-ssd-5g\n  labels:\n    name: storage\nspec:\n  containers:\n  - image: nginx\n    name: az-c-01\n    command:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> /mnt/managed/outfile; sleep 1; done\n    volumeMounts:\n    - name: managed01\n      mountPath: /mnt/managed\n    securityContext:\n      privileged: true\n  volumes:\n  - name: managed01\n    persistentVolumeClaim:\n      claimName: dd-managed-ssd-5g\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp568c9834.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) The container \"az-c-01\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp568c9834.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp568c9834.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp568c9834.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp568c9834.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp568c9834.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp568c9834.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/azure_disk/claim/managed-disk/managed-ssd/pod-uses-managed-ssd.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-uses-managed-ssd-5g\n  labels:\n    name: storage\nspec:\n  containers:\n  - image: nginx\n    name: az-c-01\n    command:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> /mnt/managed/outfile; sleep 1; done\n    volumeMounts:\n    - name: managed01\n      mountPath: /mnt/managed\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-gj41o9\n  volumes:\n  - name: managed01\n    persistentVolumeClaim:\n      claimName: dd-managed-ssd-5g\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-hxjuca\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpevgr3ki5.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) The container \"az-c-01\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpevgr3ki5.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpevgr3ki5.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpevgr3ki5.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpevgr3ki5.yaml: (object: <no namespace>/pod-uses-managed-ssd-5g /v1, Kind=Pod) container \"az-c-01\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/base/controller-deployment/argocd-repo-server-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: argocd-repo-server\nspec:\n  replicas: 2\n  template:\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-repo-server\n            topologyKey: kubernetes.io/hostname\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: topology.kubernetes.io/zone\n      containers:\n      - name: argocd-repo-server\n        args:\n        - /usr/local/bin/argocd-repo-server\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3obhtape.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"argocd-repo-server\" is using an invalid container image, \"\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3obhtape.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) object has no selector specified (check: mismatching-selector, remediation: Confirm that your deployment selector correctly matches the labels in its pod template.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3obhtape.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) anti-affinity's topology key does not match \"topology.kubernetes.io/zone\" (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3obhtape.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) pod's labels \"\" do not match with anti-affinity's labels \"app.kubernetes.io/name=argocd-repo-server\" (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3obhtape.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3obhtape.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3obhtape.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3obhtape.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3obhtape.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3obhtape.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 10 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/base/controller-deployment/argocd-repo-server-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: argocd-repo-server\nspec:\n  replicas: 2\n  template:\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-repo-server\n            topologyKey: kubernetes.io/hostname\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: topology.kubernetes.io/zone\n      containers:\n      - name: argocd-repo-server\n        args:\n        - /usr/local/bin/argocd-repo-server\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-nia2qy\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-2zy6k5\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_yuqq0ur.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"argocd-repo-server\" is using an invalid container image, \"\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_yuqq0ur.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) object has no selector specified (check: mismatching-selector, remediation: Confirm that your deployment selector correctly matches the labels in its pod template.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_yuqq0ur.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) anti-affinity's topology key does not match \"topology.kubernetes.io/zone\" (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_yuqq0ur.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) pod's labels \"\" do not match with anti-affinity's labels \"app.kubernetes.io/name=argocd-repo-server\" (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_yuqq0ur.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_yuqq0ur.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_yuqq0ur.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_yuqq0ur.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook/all-in-one/guestbook-all-in-one.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-master\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: master\n      tier: backend\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: master\n        tier: backend\n    spec:\n      containers:\n      - name: master\n        image: registry.k8s.io/redis:e2e\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 6379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzgpd4idj.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzgpd4idj.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzgpd4idj.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzgpd4idj.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzgpd4idj.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook/all-in-one/guestbook-all-in-one.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-master\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: master\n      tier: backend\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: master\n        tier: backend\n    spec:\n      containers:\n      - name: master\n        image: registry.k8s.io/redis:e2e\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        ports:\n        - containerPort: 6379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-79and5\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-tkccqz\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpquxnl7m9.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpquxnl7m9.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpquxnl7m9.yaml: (object: <no namespace>/redis-master apps/v1, Kind=Deployment) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook/all-in-one/guestbook-all-in-one.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-replica\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: replica\n      tier: backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: replica\n        tier: backend\n    spec:\n      containers:\n      - name: replica\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2034zls3.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2034zls3.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2034zls3.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2034zls3.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2034zls3.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2034zls3.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook/all-in-one/guestbook-all-in-one.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-replica\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: replica\n      tier: backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: replica\n        tier: backend\n    spec:\n      containers:\n      - name: replica\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-zsh8ml\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-5aus43\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2kuhd3ve.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2kuhd3ve.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2kuhd3ve.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2kuhd3ve.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook/all-in-one/guestbook-all-in-one.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google-samples/gb-frontend:v5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp37coc21k.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp37coc21k.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp37coc21k.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp37coc21k.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp37coc21k.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp37coc21k.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook/all-in-one/guestbook-all-in-one.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google-samples/gb-frontend:v5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-v8pyow\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-wpc1n9\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5jnn5yd1.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5jnn5yd1.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5jnn5yd1.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5jnn5yd1.yaml: (object: <no namespace>/frontend apps/v1, Kind=Deployment) container \"php-redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: applicationset-controller\n    app.kubernetes.io/name: argocd-applicationset-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-applicationset-controller\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-applicationset-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-applicationset-controller\n    spec:\n      containers:\n      - args:\n        - /usr/local/bin/argocd-applicationset-controller\n        env:\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_ANNOTATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.annotations\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_LABELS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.labels\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_LEADER_ELECTION\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.leader.election\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_POLICY_OVERRIDE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.policy.override\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.debug\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DRY_RUN\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.dryrun\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_PROGRESSIVE_SYNCS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.progressive.syncs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_TOKENREF_STRICT_MODE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.tokenref.strict.mode\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_CONCURRENT_RECONCILIATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.concurrent.reconciliations.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.allowed.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.webhook.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REQUEUE_AFTER\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.requeue.after\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: argocd-applicationset-controller\n        ports:\n        - containerPort: 7000\n          name: webhook\n        - containerPort: 8080\n          name: metrics\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-applicationset-controller\n      volumes:\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - configMap:\n          name: argocd-gpg-keys-cm\n        name: gpg-keys\n      - emptyDir: {}\n        name: gpg-keyring\n      - emptyDir: {}\n        name: tmp\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpps0i26rf.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) The container \"argocd-applicationset-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpps0i26rf.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) serviceAccount \"argocd-applicationset-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpps0i26rf.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpps0i26rf.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpps0i26rf.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpps0i26rf.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: applicationset-controller\n    app.kubernetes.io/name: argocd-applicationset-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-applicationset-controller\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-applicationset-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-applicationset-controller\n    spec:\n      containers:\n      - args:\n        - /usr/local/bin/argocd-applicationset-controller\n        env:\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_ANNOTATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.annotations\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_LABELS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.labels\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_LEADER_ELECTION\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.leader.election\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_POLICY_OVERRIDE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.policy.override\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.debug\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DRY_RUN\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.dryrun\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_PROGRESSIVE_SYNCS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.progressive.syncs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_TOKENREF_STRICT_MODE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.tokenref.strict.mode\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_CONCURRENT_RECONCILIATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.concurrent.reconciliations.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.allowed.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.webhook.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REQUEUE_AFTER\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.requeue.after\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: argocd-applicationset-controller\n        ports:\n        - containerPort: 7000\n          name: webhook\n        - containerPort: 8080\n          name: metrics\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-himnmj\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-applicationset-controller\n      volumes:\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - configMap:\n          name: argocd-gpg-keys-cm\n        name: gpg-keys\n      - emptyDir: {}\n        name: gpg-keyring\n      - emptyDir: {}\n        name: tmp\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-9k6r67\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptjigiazk.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) The container \"argocd-applicationset-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptjigiazk.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) serviceAccount \"argocd-applicationset-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptjigiazk.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptjigiazk.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: applicationset-controller\n    app.kubernetes.io/name: argocd-applicationset-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-applicationset-controller\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-applicationset-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-applicationset-controller\n    spec:\n      containers:\n      - args:\n        - /usr/local/bin/argocd-applicationset-controller\n        env:\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_ANNOTATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.annotations\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_LABELS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.global.preserved.labels\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_LEADER_ELECTION\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.leader.election\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_POLICY_OVERRIDE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.policy.override\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DEBUG\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.debug\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_DRY_RUN\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.dryrun\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_PROGRESSIVE_SYNCS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.progressive.syncs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_TOKENREF_STRICT_MODE\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.tokenref.strict.mode\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_CONCURRENT_RECONCILIATIONS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.concurrent.reconciliations.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.allowed.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.webhook.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_REQUEUE_AFTER\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.requeue.after\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: argocd-applicationset-controller\n        ports:\n        - containerPort: 7000\n          name: webhook\n        - containerPort: 8080\n          name: metrics\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-applicationset-controller\n      volumes:\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - configMap:\n          name: argocd-gpg-keys-cm\n        name: gpg-keys\n      - emptyDir: {}\n        name: gpg-keyring\n      - emptyDir: {}\n        name: tmp\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjyk_gfs_.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) The container \"argocd-applicationset-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjyk_gfs_.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjyk_gfs_.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) serviceAccount \"argocd-applicationset-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjyk_gfs_.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjyk_gfs_.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjyk_gfs_.yaml: (object: <no namespace>/argocd-applicationset-controller apps/v1, Kind=Deployment) container \"argocd-applicationset-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: dex-server\n    app.kubernetes.io/name: argocd-dex-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-dex-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-dex-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-dex-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - command:\n        - /shared/argocd-dex\n        - rundex\n        env:\n        - name: ARGOCD_DEX_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.disable.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        image: ghcr.io/dexidp/dex:v2.41.1\n        imagePullPolicy: Always\n        name: dex\n        ports:\n        - containerPort: 5556\n        - containerPort: 5557\n        - containerPort: 5558\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n        - mountPath: /tls\n          name: argocd-dex-server-tls\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /shared/argocd-dex\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: copyutil\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-dex-server\n      volumes:\n      - emptyDir: {}\n        name: static-files\n      - emptyDir: {}\n        name: dexconfig\n      - name: argocd-dex-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-dex-server-tls\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpyjwlp6of.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) The container \"copyutil\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpyjwlp6of.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) serviceAccount \"argocd-dex-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpyjwlp6of.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpyjwlp6of.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpyjwlp6of.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpyjwlp6of.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpyjwlp6of.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpyjwlp6of.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: dex-server\n    app.kubernetes.io/name: argocd-dex-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-dex-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-dex-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-dex-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - command:\n        - /shared/argocd-dex\n        - rundex\n        env:\n        - name: ARGOCD_DEX_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.disable.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        image: ghcr.io/dexidp/dex:v2.41.1\n        imagePullPolicy: Always\n        name: dex\n        ports:\n        - containerPort: 5556\n        - containerPort: 5557\n        - containerPort: 5558\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n        - mountPath: /tls\n          name: argocd-dex-server-tls\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-kkge09\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /shared/argocd-dex\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: copyutil\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-dex-server\n      volumes:\n      - emptyDir: {}\n        name: static-files\n      - emptyDir: {}\n        name: dexconfig\n      - name: argocd-dex-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-dex-server-tls\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-7iixco\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpoyysdkoo.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) The container \"copyutil\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpoyysdkoo.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) serviceAccount \"argocd-dex-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpoyysdkoo.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpoyysdkoo.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpoyysdkoo.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpoyysdkoo.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: dex-server\n    app.kubernetes.io/name: argocd-dex-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-dex-server\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-dex-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-dex-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - command:\n        - /shared/argocd-dex\n        - rundex\n        env:\n        - name: ARGOCD_DEX_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEX_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: dexserver.disable.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        image: ghcr.io/dexidp/dex:v2.41.1\n        imagePullPolicy: Always\n        name: dex\n        ports:\n        - containerPort: 5556\n        - containerPort: 5557\n        - containerPort: 5558\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n        - mountPath: /tls\n          name: argocd-dex-server-tls\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /shared/argocd-dex\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: copyutil\n        volumeMounts:\n        - mountPath: /shared\n          name: static-files\n        - mountPath: /tmp\n          name: dexconfig\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-dex-server\n      volumes:\n      - emptyDir: {}\n        name: static-files\n      - emptyDir: {}\n        name: dexconfig\n      - name: argocd-dex-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-dex-server-tls\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzr9aju.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) The container \"copyutil\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzr9aju.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzr9aju.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzr9aju.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) serviceAccount \"argocd-dex-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzr9aju.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzr9aju.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzr9aju.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzr9aju.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzr9aju.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"copyutil\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfqzr9aju.yaml: (object: <no namespace>/argocd-dex-server apps/v1, Kind=Deployment) container \"dex\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 10 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: notifications-controller\n    app.kubernetes.io/name: argocd-notifications-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-notifications-controller\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-notifications-controller\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-notifications-controller\n    spec:\n      containers:\n      - args:\n        - /usr/local/bin/argocd-notifications\n        env:\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_SELF_SERVICE_NOTIFICATION_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.selfservice.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          tcpSocket:\n            port: 9001\n        name: argocd-notifications-controller\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          privileged: true\n        volumeMounts:\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        workingDir: /app\n      nodeSelector:\n        kubernetes.io/os: linux\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      serviceAccountName: argocd-notifications-controller\n      volumes:\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxsluqkq_.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) The container \"argocd-notifications-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxsluqkq_.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" does not expose port 9001 for the TCPSocket (check: liveness-port, remediation: Check which ports you've exposed and ensure they match what you have specified in the liveness probe.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxsluqkq_.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) serviceAccount \"argocd-notifications-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxsluqkq_.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxsluqkq_.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxsluqkq_.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxsluqkq_.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: notifications-controller\n    app.kubernetes.io/name: argocd-notifications-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-notifications-controller\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-notifications-controller\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-notifications-controller\n    spec:\n      containers:\n      - args:\n        - /usr/local/bin/argocd-notifications\n        env:\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_SELF_SERVICE_NOTIFICATION_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.selfservice.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          tcpSocket:\n            port: 9001\n        name: argocd-notifications-controller\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-wisquu\n        workingDir: /app\n      nodeSelector:\n        kubernetes.io/os: linux\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      serviceAccountName: argocd-notifications-controller\n      volumes:\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-ki4t2b\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr54iyrjs.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) The container \"argocd-notifications-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr54iyrjs.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" does not expose port 9001 for the TCPSocket (check: liveness-port, remediation: Check which ports you've exposed and ensure they match what you have specified in the liveness probe.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr54iyrjs.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) serviceAccount \"argocd-notifications-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr54iyrjs.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr54iyrjs.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: notifications-controller\n    app.kubernetes.io/name: argocd-notifications-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-notifications-controller\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-notifications-controller\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-notifications-controller\n    spec:\n      containers:\n      - args:\n        - /usr/local/bin/argocd-notifications\n        env:\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_SELF_SERVICE_NOTIFICATION_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.selfservice.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_NOTIFICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: notificationscontroller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          tcpSocket:\n            port: 9001\n        name: argocd-notifications-controller\n        volumeMounts:\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        workingDir: /app\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-notifications-controller\n      volumes:\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpps3__m19.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) The container \"argocd-notifications-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpps3__m19.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" does not expose port 9001 for the TCPSocket (check: liveness-port, remediation: Check which ports you've exposed and ensure they match what you have specified in the liveness probe.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpps3__m19.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpps3__m19.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) serviceAccount \"argocd-notifications-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpps3__m19.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpps3__m19.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpps3__m19.yaml: (object: <no namespace>/argocd-notifications-controller apps/v1, Kind=Deployment) container \"argocd-notifications-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/name: argocd-redis-ha-haproxy\n    app.kubernetes.io/part-of: argocd\n  name: argocd-redis-ha-haproxy\nspec:\n  replicas: 3\n  revisionHistoryLimit: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis-ha-haproxy\n  strategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        checksum/config: cd6508bdf9819601c454d0cc491fb77a209e3a88761d92514d105b6681829953\n        prometheus.io/path: /metrics\n        prometheus.io/port: '9101'\n        prometheus.io/scrape: 'true'\n      labels:\n        app.kubernetes.io/name: argocd-redis-ha-haproxy\n      name: argocd-redis-ha-haproxy\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-redis-ha-haproxy\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: true\n      containers:\n      - env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle: {}\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        name: haproxy\n        ports:\n        - containerPort: 8888\n          name: probe\n        - containerPort: 6379\n          name: redis\n        - containerPort: 9101\n          name: metrics-port\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        volumeMounts:\n        - mountPath: /usr/local/etc/haproxy\n          name: data\n        - mountPath: /run/haproxy\n          name: shared-socket\n      initContainers:\n      - command:\n        - argocd\n        - admin\n        - redis-initial-password\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: IfNotPresent\n        name: secret-init\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n      - args:\n        - /readonly/haproxy_init.sh\n        command:\n        - sh\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        name: config-init\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /readonly\n          name: config-volume\n          readOnly: true\n        - mountPath: /data\n          name: data\n      securityContext:\n        fsGroup: 99\n        runAsNonRoot: true\n        runAsUser: 99\n      serviceAccountName: argocd-redis-ha-haproxy\n      volumes:\n      - configMap:\n          name: argocd-redis-ha-configmap\n        name: config-volume\n      - emptyDir: {}\n        name: shared-socket\n      - emptyDir: {}\n        name: data\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxzwr5dsb.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) The container \"secret-init\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxzwr5dsb.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) serviceAccount \"argocd-redis-ha-haproxy\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxzwr5dsb.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxzwr5dsb.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxzwr5dsb.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"secret-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxzwr5dsb.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxzwr5dsb.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxzwr5dsb.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"secret-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxzwr5dsb.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxzwr5dsb.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 10 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/name: argocd-redis-ha-haproxy\n    app.kubernetes.io/part-of: argocd\n  name: argocd-redis-ha-haproxy\nspec:\n  replicas: 3\n  revisionHistoryLimit: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis-ha-haproxy\n  strategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        checksum/config: cd6508bdf9819601c454d0cc491fb77a209e3a88761d92514d105b6681829953\n        prometheus.io/path: /metrics\n        prometheus.io/port: '9101'\n        prometheus.io/scrape: 'true'\n      labels:\n        app.kubernetes.io/name: argocd-redis-ha-haproxy\n      name: argocd-redis-ha-haproxy\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-redis-ha-haproxy\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: true\n      containers:\n      - env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle: {}\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        name: haproxy\n        ports:\n        - containerPort: 8888\n          name: probe\n        - containerPort: 6379\n          name: redis\n        - containerPort: 9101\n          name: metrics-port\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /usr/local/etc/haproxy\n          name: data\n        - mountPath: /run/haproxy\n          name: shared-socket\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-vmj9m9\n      initContainers:\n      - command:\n        - argocd\n        - admin\n        - redis-initial-password\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: IfNotPresent\n        name: secret-init\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n      - args:\n        - /readonly/haproxy_init.sh\n        command:\n        - sh\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        name: config-init\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /readonly\n          name: config-volume\n          readOnly: true\n        - mountPath: /data\n          name: data\n      securityContext:\n        fsGroup: 99\n        runAsNonRoot: true\n        runAsUser: 99\n      serviceAccountName: argocd-redis-ha-haproxy\n      volumes:\n      - configMap:\n          name: argocd-redis-ha-configmap\n        name: config-volume\n      - emptyDir: {}\n        name: shared-socket\n      - emptyDir: {}\n        name: data\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-dwk438\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkfc6l4pv.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) The container \"secret-init\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkfc6l4pv.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) serviceAccount \"argocd-redis-ha-haproxy\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkfc6l4pv.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"secret-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkfc6l4pv.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkfc6l4pv.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkfc6l4pv.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"secret-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkfc6l4pv.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkfc6l4pv.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/name: argocd-redis-ha-haproxy\n    app.kubernetes.io/part-of: argocd\n  name: argocd-redis-ha-haproxy\nspec:\n  replicas: 3\n  revisionHistoryLimit: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis-ha-haproxy\n  strategy:\n    type: RollingUpdate\n  template:\n    metadata:\n      annotations:\n        checksum/config: cd6508bdf9819601c454d0cc491fb77a209e3a88761d92514d105b6681829953\n        prometheus.io/path: /metrics\n        prometheus.io/port: '9101'\n        prometheus.io/scrape: 'true'\n      labels:\n        app.kubernetes.io/name: argocd-redis-ha-haproxy\n      name: argocd-redis-ha-haproxy\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-redis-ha-haproxy\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: true\n      containers:\n      - env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle: {}\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        name: haproxy\n        ports:\n        - containerPort: 8888\n          name: probe\n        - containerPort: 6379\n          name: redis\n        - containerPort: 9101\n          name: metrics-port\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: probe\n          initialDelaySeconds: 5\n          periodSeconds: 3\n        volumeMounts:\n        - mountPath: /usr/local/etc/haproxy\n          name: data\n        - mountPath: /run/haproxy\n          name: shared-socket\n      initContainers:\n      - command:\n        - argocd\n        - admin\n        - redis-initial-password\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: IfNotPresent\n        name: secret-init\n      - args:\n        - /readonly/haproxy_init.sh\n        command:\n        - sh\n        image: public.ecr.aws/docker/library/haproxy:3.0.8-alpine\n        imagePullPolicy: IfNotPresent\n        name: config-init\n        volumeMounts:\n        - mountPath: /readonly\n          name: config-volume\n          readOnly: true\n        - mountPath: /data\n          name: data\n      serviceAccountName: argocd-redis-ha-haproxy\n      volumes:\n      - configMap:\n          name: argocd-redis-ha-configmap\n        name: config-volume\n      - emptyDir: {}\n        name: shared-socket\n      - emptyDir: {}\n        name: data\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp55skqq79.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) The container \"secret-init\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp55skqq79.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"secret-init\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp55skqq79.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp55skqq79.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp55skqq79.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) serviceAccount \"argocd-redis-ha-haproxy\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp55skqq79.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"secret-init\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp55skqq79.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp55skqq79.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp55skqq79.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"secret-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp55skqq79.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp55skqq79.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp55skqq79.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"secret-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp55skqq79.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp55skqq79.yaml: (object: <no namespace>/argocd-redis-ha-haproxy apps/v1, Kind=Deployment) container \"haproxy\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 14 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: repo-server\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-repo-server\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-repo-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: topology.kubernetes.io/zone\n            weight: 100\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-repo-server\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: false\n      containers:\n      - args:\n        - /usr/local/bin/argocd-repo-server\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.metrics.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.minversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.maxversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.ciphers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.repo.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.max.combined.directory.manifests.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.tar.exclusions\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_USE_MANIFEST_GENERATE_PATHS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.use.manifest.generate.paths\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.allow.oob.symlinks\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.tar.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REVISION_CACHE_LOCK_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.revision.cache.lock.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.lsremote.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_REQUEST_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.request.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GRPC_MAX_SIZE_MB\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.grpc.max.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_INCLUDE_HIDDEN_DIRECTORIES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.include.hidden.directories\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: HELM_CACHE_HOME\n          value: /helm-working-dir\n        - name: HELM_CONFIG_HOME\n          value: /helm-working-dir\n        - name: HELM_DATA_HOME\n          value: /helm-working-dir\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz?full=true\n            port: 8084\n          initialDelaySeconds: 30\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: argocd-repo-server\n        ports:\n        - containerPort: 8081\n        - containerPort: 8084\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8084\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /helm-working-dir\n          name: helm-working-dir\n        - mountPath: /home/argocd/cmp-server/plugins\n          name: plugins\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /var/run/argocd/argocd-cmp-server\n        image: quay.io/argoproj/argocd:latest\n        name: copyutil\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /var/run/argocd\n          name: var-files\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-repo-server\n      volumes:\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - configMap:\n          name: argocd-gpg-keys-cm\n        name: gpg-keys\n      - emptyDir: {}\n        name: gpg-keyring\n      - emptyDir: {}\n        name: tmp\n      - emptyDir: {}\n        name: helm-working-dir\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - emptyDir: {}\n        name: var-files\n      - emptyDir: {}\n        name: plugins\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp486spr6e.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"copyutil\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp486spr6e.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"argocd-repo-server\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp486spr6e.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) serviceAccount \"argocd-repo-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp486spr6e.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp486spr6e.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp486spr6e.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp486spr6e.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp486spr6e.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp486spr6e.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 9 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: repo-server\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-repo-server\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-repo-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: topology.kubernetes.io/zone\n            weight: 100\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-repo-server\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: false\n      containers:\n      - args:\n        - /usr/local/bin/argocd-repo-server\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.metrics.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.minversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.maxversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.ciphers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.repo.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.max.combined.directory.manifests.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.tar.exclusions\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_USE_MANIFEST_GENERATE_PATHS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.use.manifest.generate.paths\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.allow.oob.symlinks\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.tar.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REVISION_CACHE_LOCK_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.revision.cache.lock.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.lsremote.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_REQUEST_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.request.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GRPC_MAX_SIZE_MB\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.grpc.max.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_INCLUDE_HIDDEN_DIRECTORIES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.include.hidden.directories\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: HELM_CACHE_HOME\n          value: /helm-working-dir\n        - name: HELM_CONFIG_HOME\n          value: /helm-working-dir\n        - name: HELM_DATA_HOME\n          value: /helm-working-dir\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz?full=true\n            port: 8084\n          initialDelaySeconds: 30\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: argocd-repo-server\n        ports:\n        - containerPort: 8081\n        - containerPort: 8084\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8084\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /helm-working-dir\n          name: helm-working-dir\n        - mountPath: /home/argocd/cmp-server/plugins\n          name: plugins\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-nsrhny\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /var/run/argocd/argocd-cmp-server\n        image: quay.io/argoproj/argocd:latest\n        name: copyutil\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /var/run/argocd\n          name: var-files\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-repo-server\n      volumes:\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - configMap:\n          name: argocd-gpg-keys-cm\n        name: gpg-keys\n      - emptyDir: {}\n        name: gpg-keyring\n      - emptyDir: {}\n        name: tmp\n      - emptyDir: {}\n        name: helm-working-dir\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - emptyDir: {}\n        name: var-files\n      - emptyDir: {}\n        name: plugins\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-rtw7hv\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpruk6gwyl.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"copyutil\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpruk6gwyl.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"argocd-repo-server\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpruk6gwyl.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) serviceAccount \"argocd-repo-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpruk6gwyl.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpruk6gwyl.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpruk6gwyl.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpruk6gwyl.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: repo-server\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-repo-server\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-repo-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: topology.kubernetes.io/zone\n            weight: 100\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-repo-server\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: false\n      containers:\n      - args:\n        - /usr/local/bin/argocd-repo-server\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.metrics.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.minversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.maxversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.tls.ciphers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.repo.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.max.combined.directory.manifests.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.tar.exclusions\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_PLUGIN_USE_MANIFEST_GENERATE_PATHS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.plugin.use.manifest.generate.paths\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.allow.oob.symlinks\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.tar.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.streamed.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.disable.helm.manifest.max.extracted.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REVISION_CACHE_LOCK_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.revision.cache.lock.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_MODULES_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.enable.git.submodule\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.lsremote.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GIT_REQUEST_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.git.request.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_GRPC_MAX_SIZE_MB\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.grpc.max.size\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_REPO_SERVER_INCLUDE_HIDDEN_DIRECTORIES\n          valueFrom:\n            configMapKeyRef:\n              key: reposerver.include.hidden.directories\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: HELM_CACHE_HOME\n          value: /helm-working-dir\n        - name: HELM_CONFIG_HOME\n          value: /helm-working-dir\n        - name: HELM_DATA_HOME\n          value: /helm-working-dir\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz?full=true\n            port: 8084\n          initialDelaySeconds: 30\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: argocd-repo-server\n        ports:\n        - containerPort: 8081\n        - containerPort: 8084\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8084\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/gpg/source\n          name: gpg-keys\n        - mountPath: /app/config/gpg/keys\n          name: gpg-keyring\n        - mountPath: /app/config/reposerver/tls\n          name: argocd-repo-server-tls\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /helm-working-dir\n          name: helm-working-dir\n        - mountPath: /home/argocd/cmp-server/plugins\n          name: plugins\n      initContainers:\n      - command:\n        - /bin/cp\n        - -n\n        - /usr/local/bin/argocd\n        - /var/run/argocd/argocd-cmp-server\n        image: quay.io/argoproj/argocd:latest\n        name: copyutil\n        volumeMounts:\n        - mountPath: /var/run/argocd\n          name: var-files\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-repo-server\n      volumes:\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - configMap:\n          name: argocd-gpg-keys-cm\n        name: gpg-keys\n      - emptyDir: {}\n        name: gpg-keyring\n      - emptyDir: {}\n        name: tmp\n      - emptyDir: {}\n        name: helm-working-dir\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - emptyDir: {}\n        name: var-files\n      - emptyDir: {}\n        name: plugins\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxwa5qrb6.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"copyutil\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxwa5qrb6.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) The container \"argocd-repo-server\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxwa5qrb6.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxwa5qrb6.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxwa5qrb6.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) serviceAccount \"argocd-repo-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxwa5qrb6.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxwa5qrb6.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxwa5qrb6.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxwa5qrb6.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxwa5qrb6.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"copyutil\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxwa5qrb6.yaml: (object: <no namespace>/argocd-repo-server apps/v1, Kind=Deployment) container \"argocd-repo-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 11 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: server\n    app.kubernetes.io/name: argocd-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-server\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-server\n              topologyKey: topology.kubernetes.io/zone\n            weight: 100\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-server\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - args:\n        - /usr/local/bin/argocd-server\n        env:\n        - name: ARGOCD_API_SERVER_REPLICAS\n          value: '2'\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_SERVER_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: server.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_BASEHREF\n          valueFrom:\n            configMapKeyRef:\n              key: server.basehref\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ROOTPATH\n          valueFrom:\n            configMapKeyRef:\n              key: server.rootpath\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: server.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: server.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DISABLE_AUTH\n          valueFrom:\n            configMapKeyRef:\n              key: server.disable.auth\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_GZIP\n          valueFrom:\n            configMapKeyRef:\n              key: server.enable.gzip\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_X_FRAME_OPTIONS\n          valueFrom:\n            configMapKeyRef:\n              key: server.x.frame.options\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_CONTENT_SECURITY_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: server.content.security.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.minversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.maxversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.ciphers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_CONNECTION_STATUS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.connection.status.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OIDC_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.oidc.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOGIN_ATTEMPTS_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.login.attempts.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_STATIC_ASSETS\n          valueFrom:\n            configMapKeyRef:\n              key: server.staticassets\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_MAX_COOKIE_NUMBER\n          valueFrom:\n            configMapKeyRef:\n              key: server.http.cookie.maxnumber\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: server.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_METRICS_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: server.metrics.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_PROXY_EXTENSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.enable.proxy.extension\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              key: server.k8sclient.retry.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              key: server.k8sclient.retry.base.backoff\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_API_CONTENT_TYPES\n          valueFrom:\n            configMapKeyRef:\n              key: server.api.content.types\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: server.webhook.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.allowed.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: hydrator.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SYNC_WITH_REPLACE_ALLOWED\n          valueFrom:\n            configMapKeyRef:\n              key: server.sync.replace.allowed\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: 8080\n          initialDelaySeconds: 3\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: argocd-server\n        ports:\n        - containerPort: 8080\n        - containerPort: 8083\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 3\n          periodSeconds: 30\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/server/tls\n          name: argocd-repo-server-tls\n        - mountPath: /app/config/dex/tls\n          name: argocd-dex-server-tls\n        - mountPath: /home/argocd\n          name: plugins-home\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /home/argocd/params\n          name: argocd-cmd-params-cm\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-server\n      volumes:\n      - emptyDir: {}\n        name: plugins-home\n      - emptyDir: {}\n        name: tmp\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - name: argocd-dex-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-dex-server-tls\n      - configMap:\n          items:\n          - key: server.profile.enabled\n            path: profiler.enabled\n          name: argocd-cmd-params-cm\n          optional: true\n        name: argocd-cmd-params-cm\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkon0apif.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) The container \"argocd-server\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkon0apif.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) serviceAccount \"argocd-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkon0apif.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkon0apif.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkon0apif.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkon0apif.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: server\n    app.kubernetes.io/name: argocd-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-server\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-server\n              topologyKey: topology.kubernetes.io/zone\n            weight: 100\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-server\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - args:\n        - /usr/local/bin/argocd-server\n        env:\n        - name: ARGOCD_API_SERVER_REPLICAS\n          value: '2'\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_SERVER_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: server.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_BASEHREF\n          valueFrom:\n            configMapKeyRef:\n              key: server.basehref\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ROOTPATH\n          valueFrom:\n            configMapKeyRef:\n              key: server.rootpath\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: server.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: server.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DISABLE_AUTH\n          valueFrom:\n            configMapKeyRef:\n              key: server.disable.auth\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_GZIP\n          valueFrom:\n            configMapKeyRef:\n              key: server.enable.gzip\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_X_FRAME_OPTIONS\n          valueFrom:\n            configMapKeyRef:\n              key: server.x.frame.options\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_CONTENT_SECURITY_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: server.content.security.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.minversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.maxversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.ciphers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_CONNECTION_STATUS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.connection.status.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OIDC_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.oidc.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOGIN_ATTEMPTS_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.login.attempts.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_STATIC_ASSETS\n          valueFrom:\n            configMapKeyRef:\n              key: server.staticassets\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_MAX_COOKIE_NUMBER\n          valueFrom:\n            configMapKeyRef:\n              key: server.http.cookie.maxnumber\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: server.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_METRICS_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: server.metrics.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_PROXY_EXTENSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.enable.proxy.extension\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              key: server.k8sclient.retry.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              key: server.k8sclient.retry.base.backoff\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_API_CONTENT_TYPES\n          valueFrom:\n            configMapKeyRef:\n              key: server.api.content.types\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: server.webhook.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.allowed.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: hydrator.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SYNC_WITH_REPLACE_ALLOWED\n          valueFrom:\n            configMapKeyRef:\n              key: server.sync.replace.allowed\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: 8080\n          initialDelaySeconds: 3\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: argocd-server\n        ports:\n        - containerPort: 8080\n        - containerPort: 8083\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 3\n          periodSeconds: 30\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/server/tls\n          name: argocd-repo-server-tls\n        - mountPath: /app/config/dex/tls\n          name: argocd-dex-server-tls\n        - mountPath: /home/argocd\n          name: plugins-home\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /home/argocd/params\n          name: argocd-cmd-params-cm\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-1fgx9u\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-server\n      volumes:\n      - emptyDir: {}\n        name: plugins-home\n      - emptyDir: {}\n        name: tmp\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - name: argocd-dex-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-dex-server-tls\n      - configMap:\n          items:\n          - key: server.profile.enabled\n            path: profiler.enabled\n          name: argocd-cmd-params-cm\n          optional: true\n        name: argocd-cmd-params-cm\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-1cpgxp\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_w5izslz.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) The container \"argocd-server\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_w5izslz.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) serviceAccount \"argocd-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_w5izslz.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_w5izslz.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.kubernetes.io/component: server\n    app.kubernetes.io/name: argocd-server\n    app.kubernetes.io/part-of: argocd\n  name: argocd-server\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-server\n              topologyKey: topology.kubernetes.io/zone\n            weight: 100\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-server\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - args:\n        - /usr/local/bin/argocd-server\n        env:\n        - name: ARGOCD_API_SERVER_REPLICAS\n          value: '2'\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_SERVER_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: server.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_BASEHREF\n          valueFrom:\n            configMapKeyRef:\n              key: server.basehref\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ROOTPATH\n          valueFrom:\n            configMapKeyRef:\n              key: server.rootpath\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: server.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOG_LEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: server.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DISABLE_AUTH\n          valueFrom:\n            configMapKeyRef:\n              key: server.disable.auth\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_GZIP\n          valueFrom:\n            configMapKeyRef:\n              key: server.enable.gzip\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_X_FRAME_OPTIONS\n          valueFrom:\n            configMapKeyRef:\n              key: server.x.frame.options\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_CONTENT_SECURITY_POLICY\n          valueFrom:\n            configMapKeyRef:\n              key: server.content.security.policy\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: server.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_DEX_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: server.dex.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MIN_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.minversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_MAX_VERSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.maxversion\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_TLS_CIPHERS\n          valueFrom:\n            configMapKeyRef:\n              key: server.tls.ciphers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_CONNECTION_STATUS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.connection.status.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OIDC_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.oidc.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LOGIN_ATTEMPTS_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.login.attempts.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_STATIC_ASSETS\n          valueFrom:\n            configMapKeyRef:\n              key: server.staticassets\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: server.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_MAX_COOKIE_NUMBER\n          valueFrom:\n            configMapKeyRef:\n              key: server.http.cookie.maxnumber\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: server.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_METRICS_LISTEN_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: server.metrics.listen.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_ENABLE_PROXY_EXTENSION\n          valueFrom:\n            configMapKeyRef:\n              key: server.enable.proxy.extension\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              key: server.k8sclient.retry.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              key: server.k8sclient.retry.base.backoff\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_API_CONTENT_TYPES\n          valueFrom:\n            configMapKeyRef:\n              key: server.api.content.types\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SERVER_WEBHOOK_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: server.webhook.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.new.git.file.globbing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.scm.root.ca.path\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.allowed.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS\n          valueFrom:\n            configMapKeyRef:\n              key: applicationsetcontroller.enable.scm.providers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: hydrator.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_SYNC_WITH_REPLACE_ALLOWED\n          valueFrom:\n            configMapKeyRef:\n              key: server.sync.replace.allowed\n              name: argocd-cmd-params-cm\n              optional: true\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        livenessProbe:\n          httpGet:\n            path: /healthz?full=true\n            port: 8080\n          initialDelaySeconds: 3\n          periodSeconds: 30\n          timeoutSeconds: 5\n        name: argocd-server\n        ports:\n        - containerPort: 8080\n        - containerPort: 8083\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 3\n          periodSeconds: 30\n        volumeMounts:\n        - mountPath: /app/config/ssh\n          name: ssh-known-hosts\n        - mountPath: /app/config/tls\n          name: tls-certs\n        - mountPath: /app/config/server/tls\n          name: argocd-repo-server-tls\n        - mountPath: /app/config/dex/tls\n          name: argocd-dex-server-tls\n        - mountPath: /home/argocd\n          name: plugins-home\n        - mountPath: /tmp\n          name: tmp\n        - mountPath: /home/argocd/params\n          name: argocd-cmd-params-cm\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-server\n      volumes:\n      - emptyDir: {}\n        name: plugins-home\n      - emptyDir: {}\n        name: tmp\n      - configMap:\n          name: argocd-ssh-known-hosts-cm\n        name: ssh-known-hosts\n      - configMap:\n          name: argocd-tls-certs-cm\n        name: tls-certs\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - name: argocd-dex-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-dex-server-tls\n      - configMap:\n          items:\n          - key: server.profile.enabled\n            path: profiler.enabled\n          name: argocd-cmd-params-cm\n          optional: true\n        name: argocd-cmd-params-cm\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxkaerofh.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) The container \"argocd-server\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxkaerofh.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxkaerofh.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) serviceAccount \"argocd-server\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxkaerofh.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxkaerofh.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxkaerofh.yaml: (object: <no namespace>/argocd-server apps/v1, Kind=Deployment) container \"argocd-server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: application-controller\n    app.kubernetes.io/name: argocd-application-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-application-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-application-controller\n  serviceName: argocd-application-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-application-controller\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-application-controller\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - args:\n        - /usr/local/bin/argocd-application-controller\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_CONTROLLER_REPLICAS\n          value: '1'\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_HARD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.hard.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_RECONCILIATION_JITTER\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation.jitter\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_ERROR_GRACE_PERIOD_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.error.grace.period.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_STATUS_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.status.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OPERATION_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.operation.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_METRICS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.metrics.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_FACTOR\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.factor\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_CAP_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.cap.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SYNC_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.sync.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_PERSIST_RESOURCE_HEALTH\n          valueFrom:\n            configMapKeyRef:\n              key: controller.resource.health.persist\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CONTROLLER_SHARDING_ALGORITHM\n          valueFrom:\n            configMapKeyRef:\n              key: controller.sharding.algorithm\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_KUBECTL_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.kubectl.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              key: controller.k8sclient.retry.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              key: controller.k8sclient.retry.base.backoff\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SERVER_SIDE_DIFF\n          valueFrom:\n            configMapKeyRef:\n              key: controller.diff.server.side\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_IGNORE_NORMALIZER_JQ_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.ignore.normalizer.jq.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: hydrator.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_BATCH_EVENTS_PROCESSING\n          valueFrom:\n            configMapKeyRef:\n              key: controller.cluster.cache.batch.events.processing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_EVENTS_PROCESSING_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.cluster.cache.events.processing.interval\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: KUBECACHEDIR\n          value: /tmp/kubecache\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: argocd-application-controller\n        ports:\n        - containerPort: 8082\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8082\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        volumeMounts:\n        - mountPath: /app/config/controller/tls\n          name: argocd-repo-server-tls\n        - mountPath: /home/argocd\n          name: argocd-home\n        - mountPath: /home/argocd/params\n          name: argocd-cmd-params-cm\n        - mountPath: /tmp\n          name: argocd-application-controller-tmp\n        workingDir: /home/argocd\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-application-controller\n      volumes:\n      - emptyDir: {}\n        name: argocd-home\n      - emptyDir: {}\n        name: argocd-application-controller-tmp\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - configMap:\n          items:\n          - key: controller.profile.enabled\n            path: profiler.enabled\n          name: argocd-cmd-params-cm\n          optional: true\n        name: argocd-cmd-params-cm\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpes76rorv.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) The container \"argocd-application-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpes76rorv.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) serviceAccount \"argocd-application-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpes76rorv.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpes76rorv.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpes76rorv.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpes76rorv.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: application-controller\n    app.kubernetes.io/name: argocd-application-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-application-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-application-controller\n  serviceName: argocd-application-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-application-controller\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-application-controller\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - args:\n        - /usr/local/bin/argocd-application-controller\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_CONTROLLER_REPLICAS\n          value: '1'\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_HARD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.hard.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_RECONCILIATION_JITTER\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation.jitter\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_ERROR_GRACE_PERIOD_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.error.grace.period.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_STATUS_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.status.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OPERATION_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.operation.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_METRICS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.metrics.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_FACTOR\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.factor\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_CAP_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.cap.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SYNC_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.sync.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_PERSIST_RESOURCE_HEALTH\n          valueFrom:\n            configMapKeyRef:\n              key: controller.resource.health.persist\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CONTROLLER_SHARDING_ALGORITHM\n          valueFrom:\n            configMapKeyRef:\n              key: controller.sharding.algorithm\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_KUBECTL_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.kubectl.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              key: controller.k8sclient.retry.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              key: controller.k8sclient.retry.base.backoff\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SERVER_SIDE_DIFF\n          valueFrom:\n            configMapKeyRef:\n              key: controller.diff.server.side\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_IGNORE_NORMALIZER_JQ_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.ignore.normalizer.jq.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: hydrator.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_BATCH_EVENTS_PROCESSING\n          valueFrom:\n            configMapKeyRef:\n              key: controller.cluster.cache.batch.events.processing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_EVENTS_PROCESSING_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.cluster.cache.events.processing.interval\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: KUBECACHEDIR\n          value: /tmp/kubecache\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: argocd-application-controller\n        ports:\n        - containerPort: 8082\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8082\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /app/config/controller/tls\n          name: argocd-repo-server-tls\n        - mountPath: /home/argocd\n          name: argocd-home\n        - mountPath: /home/argocd/params\n          name: argocd-cmd-params-cm\n        - mountPath: /tmp\n          name: argocd-application-controller-tmp\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-2trhvw\n        workingDir: /home/argocd\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-application-controller\n      volumes:\n      - emptyDir: {}\n        name: argocd-home\n      - emptyDir: {}\n        name: argocd-application-controller-tmp\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - configMap:\n          items:\n          - key: controller.profile.enabled\n            path: profiler.enabled\n          name: argocd-cmd-params-cm\n          optional: true\n        name: argocd-cmd-params-cm\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-hmo5zh\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjrm_t7vk.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) The container \"argocd-application-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjrm_t7vk.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) serviceAccount \"argocd-application-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjrm_t7vk.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpjrm_t7vk.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: application-controller\n    app.kubernetes.io/name: argocd-application-controller\n    app.kubernetes.io/part-of: argocd\n  name: argocd-application-controller\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-application-controller\n  serviceName: argocd-application-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-application-controller\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-application-controller\n              topologyKey: kubernetes.io/hostname\n            weight: 100\n          - podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/part-of: argocd\n              topologyKey: kubernetes.io/hostname\n            weight: 5\n      containers:\n      - args:\n        - /usr/local/bin/argocd-application-controller\n        env:\n        - name: REDIS_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        - name: ARGOCD_CONTROLLER_REPLICAS\n          value: '1'\n        - name: ARGOCD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_HARD_RECONCILIATION_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.hard.reconciliation\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_RECONCILIATION_JITTER\n          valueFrom:\n            configMapKeyRef:\n              key: timeout.reconciliation.jitter\n              name: argocd-cm\n              optional: true\n        - name: ARGOCD_REPO_ERROR_GRACE_PERIOD_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.error.grace.period.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: repo.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_STATUS_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.status.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OPERATION_PROCESSORS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.operation.processors\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGFORMAT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.format\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_LOGLEVEL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.log.level\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_LOG_FORMAT_TIMESTAMP\n          valueFrom:\n            configMapKeyRef:\n              key: log.format.timestamp\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_METRICS_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.metrics.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_TIMEOUT_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_FACTOR\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.factor\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_BACKOFF_CAP_SECONDS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.self.heal.backoff.cap.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SYNC_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.sync.timeout.seconds\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_PLAINTEXT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.plaintext\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_STRICT_TLS\n          valueFrom:\n            configMapKeyRef:\n              key: controller.repo.server.strict.tls\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_PERSIST_RESOURCE_HEALTH\n          valueFrom:\n            configMapKeyRef:\n              key: controller.resource.health.persist\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APP_STATE_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.app.state.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_SERVER\n          valueFrom:\n            configMapKeyRef:\n              key: redis.server\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDIS_COMPRESSION\n          valueFrom:\n            configMapKeyRef:\n              key: redis.compression\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: REDISDB\n          valueFrom:\n            configMapKeyRef:\n              key: redis.db\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_DEFAULT_CACHE_EXPIRATION\n          valueFrom:\n            configMapKeyRef:\n              key: controller.default.cache.expiration\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ADDRESS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.address\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_INSECURE\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.insecure\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_HEADERS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.headers\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ATTRS\n          valueFrom:\n            configMapKeyRef:\n              key: otlp.attrs\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_NAMESPACES\n          valueFrom:\n            configMapKeyRef:\n              key: application.namespaces\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CONTROLLER_SHARDING_ALGORITHM\n          valueFrom:\n            configMapKeyRef:\n              key: controller.sharding.algorithm\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_KUBECTL_PARALLELISM_LIMIT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.kubectl.parallelism.limit\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_MAX\n          valueFrom:\n            configMapKeyRef:\n              key: controller.k8sclient.retry.max\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF\n          valueFrom:\n            configMapKeyRef:\n              key: controller.k8sclient.retry.base.backoff\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_APPLICATION_CONTROLLER_SERVER_SIDE_DIFF\n          valueFrom:\n            configMapKeyRef:\n              key: controller.diff.server.side\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_IGNORE_NORMALIZER_JQ_TIMEOUT\n          valueFrom:\n            configMapKeyRef:\n              key: controller.ignore.normalizer.jq.timeout\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_HYDRATOR_ENABLED\n          valueFrom:\n            configMapKeyRef:\n              key: hydrator.enabled\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_BATCH_EVENTS_PROCESSING\n          valueFrom:\n            configMapKeyRef:\n              key: controller.cluster.cache.batch.events.processing\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: ARGOCD_CLUSTER_CACHE_EVENTS_PROCESSING_INTERVAL\n          valueFrom:\n            configMapKeyRef:\n              key: controller.cluster.cache.events.processing.interval\n              name: argocd-cmd-params-cm\n              optional: true\n        - name: KUBECACHEDIR\n          value: /tmp/kubecache\n        image: quay.io/argoproj/argocd:latest\n        imagePullPolicy: Always\n        name: argocd-application-controller\n        ports:\n        - containerPort: 8082\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8082\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        volumeMounts:\n        - mountPath: /app/config/controller/tls\n          name: argocd-repo-server-tls\n        - mountPath: /home/argocd\n          name: argocd-home\n        - mountPath: /home/argocd/params\n          name: argocd-cmd-params-cm\n        - mountPath: /tmp\n          name: argocd-application-controller-tmp\n        workingDir: /home/argocd\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: argocd-application-controller\n      volumes:\n      - emptyDir: {}\n        name: argocd-home\n      - emptyDir: {}\n        name: argocd-application-controller-tmp\n      - name: argocd-repo-server-tls\n        secret:\n          items:\n          - key: tls.crt\n            path: tls.crt\n          - key: tls.key\n            path: tls.key\n          - key: ca.crt\n            path: ca.crt\n          optional: true\n          secretName: argocd-repo-server-tls\n      - configMap:\n          items:\n          - key: controller.profile.enabled\n            path: profiler.enabled\n          name: argocd-cmd-params-cm\n          optional: true\n        name: argocd-cmd-params-cm\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpf11isa3_.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) The container \"argocd-application-controller\" is using an invalid container image, \"quay.io/argoproj/argocd:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpf11isa3_.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpf11isa3_.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) serviceAccount \"argocd-application-controller\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpf11isa3_.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpf11isa3_.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpf11isa3_.yaml: (object: <no namespace>/argocd-application-controller apps/v1, Kind=StatefulSet) container \"argocd-application-controller\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/name: argocd-redis-ha\n    app.kubernetes.io/part-of: argocd\n  name: argocd-redis-ha-server\nspec:\n  podManagementPolicy: OrderedReady\n  replicas: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis-ha\n  serviceName: argocd-redis-ha\n  template:\n    metadata:\n      annotations:\n        checksum/init-config: bd30e83dfdad9912b6c1cc32a8c26d7d01429a0730f5ee7af380fb593e874d54\n      labels:\n        app.kubernetes.io/name: argocd-redis-ha\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-redis-ha\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: false\n      containers:\n      - args:\n        - /data/conf/redis.conf\n        command:\n        - redis-server\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle:\n          preStop:\n            exec:\n              command:\n              - /bin/sh\n              - /readonly-config/trigger-failover-if-master.sh\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        name: redis\n        ports:\n        - containerPort: 6379\n          name: redis\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n          privileged: true\n        startupProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 15\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n      - args:\n        - /data/conf/sentinel.conf\n        command:\n        - redis-sentinel\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - /bin/sh\n              - -c\n              - sleep 30; redis-cli -p 26379 sentinel reset argocd\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        name: sentinel\n        ports:\n        - containerPort: 26379\n          name: sentinel\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 3\n          timeoutSeconds: 15\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        startupProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 15\n        volumeMounts:\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n      - args:\n        - /readonly-config/fix-split-brain.sh\n        command:\n        - sh\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        name: split-brain-fix\n        resources: {}\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      initContainers:\n      - args:\n        - /readonly-config/init.sh\n        command:\n        - sh\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        name: config-init\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      securityContext:\n        fsGroup: 1000\n        runAsNonRoot: true\n        runAsUser: 1000\n      serviceAccountName: argocd-redis-ha\n      terminationGracePeriodSeconds: 60\n      volumes:\n      - configMap:\n          name: argocd-redis-ha-configmap\n        name: config\n      - configMap:\n          defaultMode: 493\n          name: argocd-redis-ha-health-configmap\n        name: health\n      - emptyDir: {}\n        name: data\n  updateStrategy:\n    type: RollingUpdate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuxdf5zw5.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) serviceAccount \"argocd-redis-ha\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuxdf5zw5.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuxdf5zw5.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuxdf5zw5.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuxdf5zw5.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuxdf5zw5.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuxdf5zw5.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuxdf5zw5.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuxdf5zw5.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuxdf5zw5.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpuxdf5zw5.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 11 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/name: argocd-redis-ha\n    app.kubernetes.io/part-of: argocd\n  name: argocd-redis-ha-server\nspec:\n  podManagementPolicy: OrderedReady\n  replicas: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis-ha\n  serviceName: argocd-redis-ha\n  template:\n    metadata:\n      annotations:\n        checksum/init-config: bd30e83dfdad9912b6c1cc32a8c26d7d01429a0730f5ee7af380fb593e874d54\n      labels:\n        app.kubernetes.io/name: argocd-redis-ha\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-redis-ha\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: false\n      containers:\n      - args:\n        - /data/conf/redis.conf\n        command:\n        - redis-server\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle:\n          preStop:\n            exec:\n              command:\n              - /bin/sh\n              - /readonly-config/trigger-failover-if-master.sh\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        name: redis\n        ports:\n        - containerPort: 6379\n          name: redis\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        startupProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 15\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n      - args:\n        - /data/conf/sentinel.conf\n        command:\n        - redis-sentinel\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - /bin/sh\n              - -c\n              - sleep 30; redis-cli -p 26379 sentinel reset argocd\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        name: sentinel\n        ports:\n        - containerPort: 26379\n          name: sentinel\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 3\n          timeoutSeconds: 15\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        startupProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 15\n        volumeMounts:\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n      - args:\n        - /readonly-config/fix-split-brain.sh\n        command:\n        - sh\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        name: split-brain-fix\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      initContainers:\n      - args:\n        - /readonly-config/init.sh\n        command:\n        - sh\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        name: config-init\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      securityContext:\n        fsGroup: 1000\n        runAsNonRoot: true\n        runAsUser: 1000\n      serviceAccountName: argocd-redis-ha\n      terminationGracePeriodSeconds: 60\n      volumes:\n      - configMap:\n          name: argocd-redis-ha-configmap\n        name: config\n      - configMap:\n          defaultMode: 493\n          name: argocd-redis-ha-health-configmap\n        name: health\n      - emptyDir: {}\n        name: data\n  updateStrategy:\n    type: RollingUpdate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5xr83194.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) serviceAccount \"argocd-redis-ha\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5xr83194.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5xr83194.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5xr83194.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5xr83194.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5xr83194.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5xr83194.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5xr83194.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5xr83194.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 9 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/name: argocd-redis-ha\n    app.kubernetes.io/part-of: argocd\n  name: argocd-redis-ha-server\nspec:\n  podManagementPolicy: OrderedReady\n  replicas: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis-ha\n  serviceName: argocd-redis-ha\n  template:\n    metadata:\n      annotations:\n        checksum/init-config: bd30e83dfdad9912b6c1cc32a8c26d7d01429a0730f5ee7af380fb593e874d54\n      labels:\n        app.kubernetes.io/name: argocd-redis-ha\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-redis-ha\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: false\n      containers:\n      - args:\n        - /data/conf/redis.conf\n        command:\n        - redis-server\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle:\n          preStop:\n            exec:\n              command:\n              - /bin/sh\n              - /readonly-config/trigger-failover-if-master.sh\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        name: redis\n        ports:\n        - containerPort: 6379\n          name: redis\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        startupProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 15\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-a4qnaf\n      - args:\n        - /data/conf/sentinel.conf\n        command:\n        - redis-sentinel\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - /bin/sh\n              - -c\n              - sleep 30; redis-cli -p 26379 sentinel reset argocd\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        name: sentinel\n        ports:\n        - containerPort: 26379\n          name: sentinel\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 3\n          timeoutSeconds: 15\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        startupProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 15\n        volumeMounts:\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n      - args:\n        - /readonly-config/fix-split-brain.sh\n        command:\n        - sh\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        name: split-brain-fix\n        resources: {}\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      initContainers:\n      - args:\n        - /readonly-config/init.sh\n        command:\n        - sh\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        name: config-init\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      securityContext:\n        fsGroup: 1000\n        runAsNonRoot: true\n        runAsUser: 1000\n      serviceAccountName: argocd-redis-ha\n      terminationGracePeriodSeconds: 60\n      volumes:\n      - configMap:\n          name: argocd-redis-ha-configmap\n        name: config\n      - configMap:\n          defaultMode: 493\n          name: argocd-redis-ha-health-configmap\n        name: health\n      - emptyDir: {}\n        name: data\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-7bfhmt\n          type: DirectoryOrCreate\n  updateStrategy:\n    type: RollingUpdate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqw9t280r.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) serviceAccount \"argocd-redis-ha\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqw9t280r.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqw9t280r.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqw9t280r.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqw9t280r.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqw9t280r.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqw9t280r.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqw9t280r.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqw9t280r.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 9 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/argo-cd/manifests/ha/namespace-install.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: redis\n    app.kubernetes.io/name: argocd-redis-ha\n    app.kubernetes.io/part-of: argocd\n  name: argocd-redis-ha-server\nspec:\n  podManagementPolicy: OrderedReady\n  replicas: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-redis-ha\n  serviceName: argocd-redis-ha\n  template:\n    metadata:\n      annotations:\n        checksum/init-config: bd30e83dfdad9912b6c1cc32a8c26d7d01429a0730f5ee7af380fb593e874d54\n      labels:\n        app.kubernetes.io/name: argocd-redis-ha\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/name: argocd-redis-ha\n            topologyKey: kubernetes.io/hostname\n      automountServiceAccountToken: false\n      containers:\n      - args:\n        - /data/conf/redis.conf\n        command:\n        - redis-server\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle:\n          preStop:\n            exec:\n              command:\n              - /bin/sh\n              - /readonly-config/trigger-failover-if-master.sh\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        name: redis\n        ports:\n        - containerPort: 6379\n          name: redis\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        startupProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/redis_readiness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 15\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n      - args:\n        - /data/conf/sentinel.conf\n        command:\n        - redis-sentinel\n        env:\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        lifecycle:\n          postStart:\n            exec:\n              command:\n              - /bin/sh\n              - -c\n              - sleep 30; redis-cli -p 26379 sentinel reset argocd\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 1\n          timeoutSeconds: 15\n        name: sentinel\n        ports:\n        - containerPort: 26379\n          name: sentinel\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 5\n          initialDelaySeconds: 30\n          periodSeconds: 15\n          successThreshold: 3\n          timeoutSeconds: 15\n        startupProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - /health/sentinel_liveness.sh\n          failureThreshold: 3\n          initialDelaySeconds: 5\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 15\n        volumeMounts:\n        - mountPath: /data\n          name: data\n        - mountPath: /health\n          name: health\n      - args:\n        - /readonly-config/fix-split-brain.sh\n        command:\n        - sh\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        name: split-brain-fix\n        resources: {}\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      initContainers:\n      - args:\n        - /readonly-config/init.sh\n        command:\n        - sh\n        env:\n        - name: SENTINEL_ID_0\n          value: 3c0d9c0320bb34888c2df5757c718ce6ca992ce6\n        - name: SENTINEL_ID_1\n          value: 40000915ab58c3fa8fd888fb8b24711944e6cbb4\n        - name: SENTINEL_ID_2\n          value: 2bbec7894d954a8af3bb54d13eaec53cb024e2ca\n        - name: AUTH\n          valueFrom:\n            secretKeyRef:\n              key: auth\n              name: argocd-redis\n        image: public.ecr.aws/docker/library/redis:7.2.7-alpine\n        imagePullPolicy: IfNotPresent\n        name: config-init\n        volumeMounts:\n        - mountPath: /readonly-config\n          name: config\n          readOnly: true\n        - mountPath: /data\n          name: data\n      serviceAccountName: argocd-redis-ha\n      terminationGracePeriodSeconds: 60\n      volumes:\n      - configMap:\n          name: argocd-redis-ha-configmap\n        name: config\n      - configMap:\n          defaultMode: 493\n          name: argocd-redis-ha-health-configmap\n        name: health\n      - emptyDir: {}\n        name: data\n  updateStrategy:\n    type: RollingUpdate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_prq43kv.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_prq43kv.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_prq43kv.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_prq43kv.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_prq43kv.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) serviceAccount \"argocd-redis-ha\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_prq43kv.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_prq43kv.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_prq43kv.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_prq43kv.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_prq43kv.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_prq43kv.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_prq43kv.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_prq43kv.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_prq43kv.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"config-init\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_prq43kv.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_prq43kv.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_prq43kv.yaml: (object: <no namespace>/argocd-redis-ha-server apps/v1, Kind=StatefulSet) container \"split-brain-fix\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 17 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/vsphere/simple-statefulset.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: web\n  labels:\n    app: nginx\nspec:\n  serviceName: nginx\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 14\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: registry.k8s.io/nginx-slim:0.8\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n        securityContext:\n          privileged: true\n  volumeClaimTemplates:\n  - metadata:\n      name: www\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 1Gi\n      storageClassName: thin-disk\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprxm9adzn.yaml: (object: <no namespace>/web apps/v1, Kind=StatefulSet) object has 14 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprxm9adzn.yaml: (object: <no namespace>/web apps/v1, Kind=StatefulSet) container \"nginx\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprxm9adzn.yaml: (object: <no namespace>/web apps/v1, Kind=StatefulSet) container \"nginx\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprxm9adzn.yaml: (object: <no namespace>/web apps/v1, Kind=StatefulSet) container \"nginx\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprxm9adzn.yaml: (object: <no namespace>/web apps/v1, Kind=StatefulSet) container \"nginx\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprxm9adzn.yaml: (object: <no namespace>/web apps/v1, Kind=StatefulSet) container \"nginx\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprxm9adzn.yaml: (object: <no namespace>/web apps/v1, Kind=StatefulSet) container \"nginx\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/vsphere/simple-statefulset.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: web\n  labels:\n    app: nginx\nspec:\n  serviceName: nginx\n  selector:\n    matchLabels:\n      app: nginx\n  replicas: 14\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: registry.k8s.io/nginx-slim:0.8\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-z7apeo\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-03daai\n          type: DirectoryOrCreate\n  volumeClaimTemplates:\n  - metadata:\n      name: www\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 1Gi\n      storageClassName: thin-disk\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr26m1zsx.yaml: (object: <no namespace>/web apps/v1, Kind=StatefulSet) object has 14 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr26m1zsx.yaml: (object: <no namespace>/web apps/v1, Kind=StatefulSet) container \"nginx\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr26m1zsx.yaml: (object: <no namespace>/web apps/v1, Kind=StatefulSet) container \"nginx\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr26m1zsx.yaml: (object: <no namespace>/web apps/v1, Kind=StatefulSet) container \"nginx\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr26m1zsx.yaml: (object: <no namespace>/web apps/v1, Kind=StatefulSet) container \"nginx\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/persistent-volume-provisioning/rbd/pod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: server\nspec:\n  replicas: 1\n  selector:\n    role: server\n  template:\n    metadata:\n      labels:\n        role: server\n    spec:\n      containers:\n      - name: server\n        image: nginx\n        volumeMounts:\n        - mountPath: /var/lib/www/html\n          name: mypvc\n        securityContext:\n          privileged: true\n      volumes:\n      - name: mypvc\n        persistentVolumeClaim:\n          claimName: claim1\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp14r1v29f.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) The container \"server\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp14r1v29f.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp14r1v29f.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp14r1v29f.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp14r1v29f.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp14r1v29f.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp14r1v29f.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/persistent-volume-provisioning/rbd/pod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: server\nspec:\n  replicas: 1\n  selector:\n    role: server\n  template:\n    metadata:\n      labels:\n        role: server\n    spec:\n      containers:\n      - name: server\n        image: nginx\n        volumeMounts:\n        - mountPath: /var/lib/www/html\n          name: mypvc\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-f9wju8\n      volumes:\n      - name: mypvc\n        persistentVolumeClaim:\n          claimName: claim1\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-hd1ccr\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5to7q20y.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) The container \"server\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5to7q20y.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5to7q20y.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5to7q20y.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp5to7q20y.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/selenium/selenium-node-firefox-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: selenium-node-firefox\n  labels:\n    app: selenium-node-firefox\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: selenium-node-firefox\n  template:\n    metadata:\n      labels:\n        app: selenium-node-firefox\n    spec:\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n      containers:\n      - name: selenium-node-firefox\n        image: selenium/node-firefox:4.0\n        ports:\n        - containerPort: 5555\n        volumeMounts:\n        - mountPath: /dev/shm\n          name: dshm\n        env:\n        - name: SE_EVENT_BUS_HOST\n          value: selenium-hub\n        - name: SE_EVENT_BUS_SUBSCRIBE_PORT\n          value: '4443'\n        - name: SE_EVENT_BUS_PUBLISH_PORT\n          value: '4442'\n        resources:\n          limits:\n            memory: 1000Mi\n            cpu: '.5'\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7skpdrqx.yaml: (object: <no namespace>/selenium-node-firefox apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7skpdrqx.yaml: (object: <no namespace>/selenium-node-firefox apps/v1, Kind=Deployment) container \"selenium-node-firefox\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7skpdrqx.yaml: (object: <no namespace>/selenium-node-firefox apps/v1, Kind=Deployment) container \"selenium-node-firefox\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7skpdrqx.yaml: (object: <no namespace>/selenium-node-firefox apps/v1, Kind=Deployment) container \"selenium-node-firefox\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7skpdrqx.yaml: (object: <no namespace>/selenium-node-firefox apps/v1, Kind=Deployment) container \"selenium-node-firefox\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7skpdrqx.yaml: (object: <no namespace>/selenium-node-firefox apps/v1, Kind=Deployment) container \"selenium-node-firefox\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/selenium/selenium-node-firefox-deployment.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: selenium-node-firefox\n  labels:\n    app: selenium-node-firefox\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: selenium-node-firefox\n  template:\n    metadata:\n      labels:\n        app: selenium-node-firefox\n    spec:\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n      containers:\n      - name: selenium-node-firefox\n        image: selenium/node-firefox:4.0\n        ports:\n        - containerPort: 5555\n        volumeMounts:\n        - mountPath: /dev/shm\n          name: dshm\n        env:\n        - name: SE_EVENT_BUS_HOST\n          value: selenium-hub\n        - name: SE_EVENT_BUS_SUBSCRIBE_PORT\n          value: '4443'\n        - name: SE_EVENT_BUS_PUBLISH_PORT\n          value: '4442'\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptk0lp30r.yaml: (object: <no namespace>/selenium-node-firefox apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptk0lp30r.yaml: (object: <no namespace>/selenium-node-firefox apps/v1, Kind=Deployment) container \"selenium-node-firefox\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptk0lp30r.yaml: (object: <no namespace>/selenium-node-firefox apps/v1, Kind=Deployment) container \"selenium-node-firefox\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptk0lp30r.yaml: (object: <no namespace>/selenium-node-firefox apps/v1, Kind=Deployment) container \"selenium-node-firefox\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptk0lp30r.yaml: (object: <no namespace>/selenium-node-firefox apps/v1, Kind=Deployment) container \"selenium-node-firefox\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/selenium/selenium-node-firefox-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: selenium-node-firefox\n  labels:\n    app: selenium-node-firefox\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: selenium-node-firefox\n  template:\n    metadata:\n      labels:\n        app: selenium-node-firefox\n    spec:\n      volumes:\n      - name: dshm\n        emptyDir:\n          medium: Memory\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-7g4gsv\n          type: DirectoryOrCreate\n      containers:\n      - name: selenium-node-firefox\n        image: selenium/node-firefox:4.0\n        ports:\n        - containerPort: 5555\n        volumeMounts:\n        - mountPath: /dev/shm\n          name: dshm\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-8qbya4\n        env:\n        - name: SE_EVENT_BUS_HOST\n          value: selenium-hub\n        - name: SE_EVENT_BUS_SUBSCRIBE_PORT\n          value: '4443'\n        - name: SE_EVENT_BUS_PUBLISH_PORT\n          value: '4442'\n        resources:\n          limits:\n            memory: 1000Mi\n            cpu: '.5'\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpajspb6mj.yaml: (object: <no namespace>/selenium-node-firefox apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpajspb6mj.yaml: (object: <no namespace>/selenium-node-firefox apps/v1, Kind=Deployment) container \"selenium-node-firefox\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpajspb6mj.yaml: (object: <no namespace>/selenium-node-firefox apps/v1, Kind=Deployment) container \"selenium-node-firefox\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpajspb6mj.yaml: (object: <no namespace>/selenium-node-firefox apps/v1, Kind=Deployment) container \"selenium-node-firefox\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cpu-manager/exclusive-1.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-1\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-1\n    resources:\n      requests:\n        cpu: 1\n        memory: 256M\n      limits:\n        cpu: 1\n        memory: 256M\n    securityContext:\n      privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfbqq0a3d.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) The container \"exclusive-1\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfbqq0a3d.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) container \"exclusive-1\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfbqq0a3d.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) container \"exclusive-1\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfbqq0a3d.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) container \"exclusive-1\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfbqq0a3d.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) container \"exclusive-1\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cpu-manager/exclusive-1.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-1\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-1\n    resources:\n      requests:\n        cpu: 1\n        memory: 256M\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3nmsbtgr.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) The container \"exclusive-1\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3nmsbtgr.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) container \"exclusive-1\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3nmsbtgr.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) container \"exclusive-1\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3nmsbtgr.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) container \"exclusive-1\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cpu-manager/exclusive-1.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-1\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-1\n    resources:\n      requests:\n        cpu: 1\n        memory: 256M\n      limits:\n        cpu: 1\n        memory: 256M\n    volumeMounts:\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-6oczul\n  volumes:\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-ju0ly4\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmps8wb0qst.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) The container \"exclusive-1\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmps8wb0qst.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) container \"exclusive-1\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmps8wb0qst.yaml: (object: <no namespace>/exclusive-1 /v1, Kind=Pod) container \"exclusive-1\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/minio/minio-standalone-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio-deployment\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      volumes:\n      - name: storage\n        persistentVolumeClaim:\n          claimName: minio-pv-claim\n      containers:\n      - name: minio\n        image: minio/minio:latest\n        args:\n        - server\n        - /storage\n        env:\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          value: minio123\n        ports:\n        - containerPort: 9000\n          hostPort: 9000\n        volumeMounts:\n        - name: storage\n          mountPath: /storage\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvrbk68ou.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) environment variable MINIO_SECRET_KEY in container \"minio\" found (check: env-var-secret, remediation: Do not use raw secrets in environment variables. Instead, either mount the secret as a file or use a secretKeyRef. Refer to https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvrbk68ou.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) The container \"minio\" is using an invalid container image, \"minio/minio:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvrbk68ou.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvrbk68ou.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvrbk68ou.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvrbk68ou.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvrbk68ou.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvrbk68ou.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/minio/minio-standalone-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio-deployment\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      volumes:\n      - name: storage\n        persistentVolumeClaim:\n          claimName: minio-pv-claim\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-a855sa\n          type: DirectoryOrCreate\n      containers:\n      - name: minio\n        image: minio/minio:latest\n        args:\n        - server\n        - /storage\n        env:\n        - name: MINIO_ACCESS_KEY\n          value: minio\n        - name: MINIO_SECRET_KEY\n          value: minio123\n        ports:\n        - containerPort: 9000\n          hostPort: 9000\n        volumeMounts:\n        - name: storage\n          mountPath: /storage\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-lqaajv\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8b1pih5d.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) environment variable MINIO_SECRET_KEY in container \"minio\" found (check: env-var-secret, remediation: Do not use raw secrets in environment variables. Instead, either mount the secret as a file or use a secretKeyRef. Refer to https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8b1pih5d.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) The container \"minio\" is using an invalid container image, \"minio/minio:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8b1pih5d.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8b1pih5d.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8b1pih5d.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8b1pih5d.yaml: (object: <no namespace>/minio-deployment apps/v1, Kind=Deployment) container \"minio\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/nodesjs-mongodb/web-controller-demo.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: web\n  name: web-controller\nspec:\n  replicas: 2\n  selector:\n    name: web\n  template:\n    metadata:\n      labels:\n        name: web\n    spec:\n      containers:\n      - image: node:0.10.40\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - cd /home && git clone https://github.com/ijason/NodeJS-Sample-App.git demo\n          && cd demo/EmployeeDB/ && npm install && sed -i -- 's/localhost/mongo/g'\n          app.js && node app.js\n        name: web\n        ports:\n        - containerPort: 3000\n          name: http-server\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3cmqxsav.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3cmqxsav.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3cmqxsav.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3cmqxsav.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3cmqxsav.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3cmqxsav.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3cmqxsav.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/nodesjs-mongodb/web-controller-demo.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: web\n  name: web-controller\nspec:\n  replicas: 2\n  selector:\n    name: web\n  template:\n    metadata:\n      labels:\n        name: web\n    spec:\n      containers:\n      - image: node:0.10.40\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - cd /home && git clone https://github.com/ijason/NodeJS-Sample-App.git demo\n          && cd demo/EmployeeDB/ && npm install && sed -i -- 's/localhost/mongo/g'\n          app.js && node app.js\n        name: web\n        ports:\n        - containerPort: 3000\n          name: http-server\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-k45410\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-ik68lg\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp18yb4_do.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp18yb4_do.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp18yb4_do.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp18yb4_do.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp18yb4_do.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/azure_file/azure-2.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: azure-2\nspec:\n  containers:\n  - image: kubernetes/pause\n    name: azure-2\n    volumeMounts:\n    - name: azure\n      mountPath: /mnt/azure\n    securityContext:\n      privileged: true\n  volumes:\n  - name: azure\n    persistentVolumeClaim:\n      claimName: sample-storage-claim\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwyp31a8d.yaml: (object: <no namespace>/azure-2 /v1, Kind=Pod) The container \"azure-2\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwyp31a8d.yaml: (object: <no namespace>/azure-2 /v1, Kind=Pod) container \"azure-2\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwyp31a8d.yaml: (object: <no namespace>/azure-2 /v1, Kind=Pod) container \"azure-2\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwyp31a8d.yaml: (object: <no namespace>/azure-2 /v1, Kind=Pod) container \"azure-2\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwyp31a8d.yaml: (object: <no namespace>/azure-2 /v1, Kind=Pod) container \"azure-2\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwyp31a8d.yaml: (object: <no namespace>/azure-2 /v1, Kind=Pod) container \"azure-2\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwyp31a8d.yaml: (object: <no namespace>/azure-2 /v1, Kind=Pod) container \"azure-2\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/azure_file/azure-2.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: azure-2\nspec:\n  containers:\n  - image: kubernetes/pause\n    name: azure-2\n    volumeMounts:\n    - name: azure\n      mountPath: /mnt/azure\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-fchzhm\n  volumes:\n  - name: azure\n    persistentVolumeClaim:\n      claimName: sample-storage-claim\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-qwdsi5\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphokocxus.yaml: (object: <no namespace>/azure-2 /v1, Kind=Pod) The container \"azure-2\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphokocxus.yaml: (object: <no namespace>/azure-2 /v1, Kind=Pod) container \"azure-2\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphokocxus.yaml: (object: <no namespace>/azure-2 /v1, Kind=Pod) container \"azure-2\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphokocxus.yaml: (object: <no namespace>/azure-2 /v1, Kind=Pod) container \"azure-2\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphokocxus.yaml: (object: <no namespace>/azure-2 /v1, Kind=Pod) container \"azure-2\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/all-in-one/redis-replica.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-replica\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: replica\n      tier: backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: replica\n        tier: backend\n    spec:\n      containers:\n      - name: replica\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwevfhvs2.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwevfhvs2.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwevfhvs2.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwevfhvs2.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwevfhvs2.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpwevfhvs2.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/guestbook/all-in-one/redis-replica.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-replica\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: replica\n      tier: backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: replica\n        tier: backend\n    spec:\n      containers:\n      - name: replica\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-nw39nr\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-7gj98r\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvhozch4s.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvhozch4s.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvhozch4s.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvhozch4s.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/volumes/storageos/storageos-sc-pvcpod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: redis\n    role: master\n  name: test-storageos-redis-sc-pvc\nspec:\n  containers:\n  - name: master\n    image: kubernetes/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    resources:\n      limits:\n        cpu: '0.1'\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: redis-data\n    securityContext:\n      privileged: true\n  volumes:\n  - name: redis-data\n    persistentVolumeClaim:\n      claimName: fast0001\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp95d_ijs8.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp95d_ijs8.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp95d_ijs8.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp95d_ijs8.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp95d_ijs8.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp95d_ijs8.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/volumes/storageos/storageos-sc-pvcpod.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: redis\n    role: master\n  name: test-storageos-redis-sc-pvc\nspec:\n  containers:\n  - name: master\n    image: kubernetes/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: redis-data\n  volumes:\n  - name: redis-data\n    persistentVolumeClaim:\n      claimName: fast0001\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx5fbpx2f.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx5fbpx2f.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx5fbpx2f.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx5fbpx2f.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/volumes/storageos/storageos-sc-pvcpod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    name: redis\n    role: master\n  name: test-storageos-redis-sc-pvc\nspec:\n  containers:\n  - name: master\n    image: kubernetes/redis:v1\n    env:\n    - name: MASTER\n      value: 'true'\n    ports:\n    - containerPort: 6379\n    resources:\n      limits:\n        cpu: '0.1'\n    volumeMounts:\n    - mountPath: /redis-master-data\n      name: redis-data\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-3cv2ug\n  volumes:\n  - name: redis-data\n    persistentVolumeClaim:\n      claimName: fast0001\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-t8qbq9\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz5cgkola.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz5cgkola.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz5cgkola.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz5cgkola.yaml: (object: <no namespace>/test-storageos-redis-sc-pvc /v1, Kind=Pod) container \"master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/azure_file/azure.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: azure\nspec:\n  containers:\n  - image: kubernetes/pause\n    name: azure\n    volumeMounts:\n    - name: azure\n      mountPath: /mnt/azure\n    securityContext:\n      privileged: true\n  volumes:\n  - name: azure\n    azureFile:\n      secretName: azure-secret\n      shareName: k8stest\n      readOnly: false\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvbavf9qg.yaml: (object: <no namespace>/azure /v1, Kind=Pod) The container \"azure\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvbavf9qg.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvbavf9qg.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvbavf9qg.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvbavf9qg.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvbavf9qg.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvbavf9qg.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/azure_file/azure.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: azure\nspec:\n  containers:\n  - image: kubernetes/pause\n    name: azure\n    volumeMounts:\n    - name: azure\n      mountPath: /mnt/azure\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-phhtgr\n  volumes:\n  - name: azure\n    azureFile:\n      secretName: azure-secret\n      shareName: k8stest\n      readOnly: false\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-g3rhqs\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr7bhf_6n.yaml: (object: <no namespace>/azure /v1, Kind=Pod) The container \"azure\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr7bhf_6n.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr7bhf_6n.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr7bhf_6n.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpr7bhf_6n.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/flexvolume/nginx-nfs.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-nfs\n  namespace: default\nspec:\n  containers:\n  - name: nginx-nfs\n    image: nginx\n    volumeMounts:\n    - name: test\n      mountPath: /data\n    ports:\n    - containerPort: 80\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test\n    flexVolume:\n      driver: k8s/nfs\n      fsType: nfs\n      options:\n        server: 172.16.0.25\n        share: dws_nas_scratch\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0ir9pthw.yaml: (object: default/nginx-nfs /v1, Kind=Pod) The container \"nginx-nfs\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0ir9pthw.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0ir9pthw.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0ir9pthw.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0ir9pthw.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0ir9pthw.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0ir9pthw.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/flexvolume/nginx-nfs.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-nfs\n  namespace: default\nspec:\n  containers:\n  - name: nginx-nfs\n    image: nginx\n    volumeMounts:\n    - name: test\n      mountPath: /data\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-ihgd5l\n    ports:\n    - containerPort: 80\n  volumes:\n  - name: test\n    flexVolume:\n      driver: k8s/nfs\n      fsType: nfs\n      options:\n        server: 172.16.0.25\n        share: dws_nas_scratch\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-tmtpdl\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcvs2z1by.yaml: (object: default/nginx-nfs /v1, Kind=Pod) The container \"nginx-nfs\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcvs2z1by.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcvs2z1by.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcvs2z1by.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcvs2z1by.yaml: (object: default/nginx-nfs /v1, Kind=Pod) container \"nginx-nfs\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/mysql-wordpress-pd/mysql-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wordpress-mysql\n  labels:\n    app: wordpress\nspec:\n  selector:\n    matchLabels:\n      app: wordpress\n      tier: mysql\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app: wordpress\n        tier: mysql\n    spec:\n      containers:\n      - image: mysql:8.0\n        name: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-pass\n              key: password\n        - name: MYSQL_DATABASE\n          value: wordpress\n        - name: MYSQL_USER\n          value: wordpress\n        - name: MYSQL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-pass\n              key: password\n        ports:\n        - containerPort: 3306\n          name: mysql\n        volumeMounts:\n        - name: mysql-persistent-storage\n          mountPath: /var/lib/mysql\n        securityContext:\n          privileged: true\n      volumes:\n      - name: mysql-persistent-storage\n        persistentVolumeClaim:\n          claimName: mysql-pv-claim\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa817u02c.yaml: (object: <no namespace>/wordpress-mysql apps/v1, Kind=Deployment) container \"mysql\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa817u02c.yaml: (object: <no namespace>/wordpress-mysql apps/v1, Kind=Deployment) container \"mysql\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa817u02c.yaml: (object: <no namespace>/wordpress-mysql apps/v1, Kind=Deployment) container \"mysql\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa817u02c.yaml: (object: <no namespace>/wordpress-mysql apps/v1, Kind=Deployment) container \"mysql\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa817u02c.yaml: (object: <no namespace>/wordpress-mysql apps/v1, Kind=Deployment) container \"mysql\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpa817u02c.yaml: (object: <no namespace>/wordpress-mysql apps/v1, Kind=Deployment) container \"mysql\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/mysql-wordpress-pd/mysql-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wordpress-mysql\n  labels:\n    app: wordpress\nspec:\n  selector:\n    matchLabels:\n      app: wordpress\n      tier: mysql\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app: wordpress\n        tier: mysql\n    spec:\n      containers:\n      - image: mysql:8.0\n        name: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-pass\n              key: password\n        - name: MYSQL_DATABASE\n          value: wordpress\n        - name: MYSQL_USER\n          value: wordpress\n        - name: MYSQL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-pass\n              key: password\n        ports:\n        - containerPort: 3306\n          name: mysql\n        volumeMounts:\n        - name: mysql-persistent-storage\n          mountPath: /var/lib/mysql\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-stc6ox\n      volumes:\n      - name: mysql-persistent-storage\n        persistentVolumeClaim:\n          claimName: mysql-pv-claim\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-n8epxo\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi7d4qe0p.yaml: (object: <no namespace>/wordpress-mysql apps/v1, Kind=Deployment) container \"mysql\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi7d4qe0p.yaml: (object: <no namespace>/wordpress-mysql apps/v1, Kind=Deployment) container \"mysql\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi7d4qe0p.yaml: (object: <no namespace>/wordpress-mysql apps/v1, Kind=Deployment) container \"mysql\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpi7d4qe0p.yaml: (object: <no namespace>/wordpress-mysql apps/v1, Kind=Deployment) container \"mysql\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/vitess/guestbook-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: guestbook\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        component: guestbook\n        app: vitess\n    spec:\n      containers:\n      - name: guestbook\n        image: vitess/guestbook:v2.0.0-alpha5\n        ports:\n        - name: http-server\n          containerPort: 8080\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 100m\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqelutizk.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqelutizk.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqelutizk.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqelutizk.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqelutizk.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqelutizk.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/vitess/guestbook-controller.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: guestbook\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        component: guestbook\n        app: vitess\n    spec:\n      containers:\n      - name: guestbook\n        image: vitess/guestbook:v2.0.0-alpha5\n        ports:\n        - name: http-server\n          containerPort: 8080\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpc7oqp3wt.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpc7oqp3wt.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpc7oqp3wt.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpc7oqp3wt.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpc7oqp3wt.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/vitess/guestbook-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: guestbook\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        component: guestbook\n        app: vitess\n    spec:\n      containers:\n      - name: guestbook\n        image: vitess/guestbook:v2.0.0-alpha5\n        ports:\n        - name: http-server\n          containerPort: 8080\n        resources:\n          limits:\n            memory: 128Mi\n            cpu: 100m\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-wvwh4e\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-jwvglt\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplog2iyhz.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplog2iyhz.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplog2iyhz.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmplog2iyhz.yaml: (object: <no namespace>/guestbook /v1, Kind=ReplicationController) container \"guestbook\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/azure_disk/claim/blob-based-disk/account-specified-hdd/pod-uses-account-hdd.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-uses-account-hdd-5g\n  labels:\n    name: storage\nspec:\n  containers:\n  - image: nginx\n    name: az-c-01\n    command:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> /mnt/blobdisk/outfile; sleep 1; done\n    volumeMounts:\n    - name: blobdisk01\n      mountPath: /mnt/blobdisk\n    securityContext:\n      privileged: true\n  volumes:\n  - name: blobdisk01\n    persistentVolumeClaim:\n      claimName: pv-dd-account-hdd-5g\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0mlix3hu.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) The container \"az-c-01\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0mlix3hu.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0mlix3hu.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0mlix3hu.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0mlix3hu.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0mlix3hu.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0mlix3hu.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/azure_disk/claim/blob-based-disk/account-specified-hdd/pod-uses-account-hdd.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-uses-account-hdd-5g\n  labels:\n    name: storage\nspec:\n  containers:\n  - image: nginx\n    name: az-c-01\n    command:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> /mnt/blobdisk/outfile; sleep 1; done\n    volumeMounts:\n    - name: blobdisk01\n      mountPath: /mnt/blobdisk\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-arf9q5\n  volumes:\n  - name: blobdisk01\n    persistentVolumeClaim:\n      claimName: pv-dd-account-hdd-5g\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-11fvn4\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmwa5iah4.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) The container \"az-c-01\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmwa5iah4.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmwa5iah4.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmwa5iah4.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmwa5iah4.yaml: (object: <no namespace>/pod-uses-account-hdd-5g /v1, Kind=Pod) container \"az-c-01\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/mysql-galera/pxc-node2.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: pxc-node2\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        node: pxc-node2\n        unit: pxc-cluster\n    spec:\n      containers:\n      - resources:\n          limits:\n            cpu: 0.3\n        image: capttofu/percona_xtradb_cluster_5_6:beta\n        name: pxc-node2\n        ports:\n        - containerPort: 3306\n        - containerPort: 4444\n        - containerPort: 4567\n        - containerPort: 4568\n        env:\n        - name: GALERA_CLUSTER\n          value: 'true'\n        - name: WSREP_CLUSTER_ADDRESS\n          value: gcomm://\n        - name: WSREP_SST_USER\n          value: sst\n        - name: WSREP_SST_PASSWORD\n          value: sst\n        - name: MYSQL_USER\n          value: mysql\n        - name: MYSQL_PASSWORD\n          value: mysql\n        - name: MYSQL_ROOT_PASSWORD\n          value: c-krit\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptht8o87n.yaml: (object: <no namespace>/pxc-node2 /v1, Kind=ReplicationController) container \"pxc-node2\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptht8o87n.yaml: (object: <no namespace>/pxc-node2 /v1, Kind=ReplicationController) container \"pxc-node2\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptht8o87n.yaml: (object: <no namespace>/pxc-node2 /v1, Kind=ReplicationController) container \"pxc-node2\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptht8o87n.yaml: (object: <no namespace>/pxc-node2 /v1, Kind=ReplicationController) container \"pxc-node2\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptht8o87n.yaml: (object: <no namespace>/pxc-node2 /v1, Kind=ReplicationController) container \"pxc-node2\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptht8o87n.yaml: (object: <no namespace>/pxc-node2 /v1, Kind=ReplicationController) container \"pxc-node2\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/mysql-galera/pxc-node2.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: pxc-node2\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        node: pxc-node2\n        unit: pxc-cluster\n    spec:\n      containers:\n      - image: capttofu/percona_xtradb_cluster_5_6:beta\n        name: pxc-node2\n        ports:\n        - containerPort: 3306\n        - containerPort: 4444\n        - containerPort: 4567\n        - containerPort: 4568\n        env:\n        - name: GALERA_CLUSTER\n          value: 'true'\n        - name: WSREP_CLUSTER_ADDRESS\n          value: gcomm://\n        - name: WSREP_SST_USER\n          value: sst\n        - name: WSREP_SST_PASSWORD\n          value: sst\n        - name: MYSQL_USER\n          value: mysql\n        - name: MYSQL_PASSWORD\n          value: mysql\n        - name: MYSQL_ROOT_PASSWORD\n          value: c-krit\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbhl6nxhn.yaml: (object: <no namespace>/pxc-node2 /v1, Kind=ReplicationController) container \"pxc-node2\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbhl6nxhn.yaml: (object: <no namespace>/pxc-node2 /v1, Kind=ReplicationController) container \"pxc-node2\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbhl6nxhn.yaml: (object: <no namespace>/pxc-node2 /v1, Kind=ReplicationController) container \"pxc-node2\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpbhl6nxhn.yaml: (object: <no namespace>/pxc-node2 /v1, Kind=ReplicationController) container \"pxc-node2\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/mysql-galera/pxc-node2.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: pxc-node2\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        node: pxc-node2\n        unit: pxc-cluster\n    spec:\n      containers:\n      - resources:\n          limits:\n            cpu: 0.3\n        image: capttofu/percona_xtradb_cluster_5_6:beta\n        name: pxc-node2\n        ports:\n        - containerPort: 3306\n        - containerPort: 4444\n        - containerPort: 4567\n        - containerPort: 4568\n        env:\n        - name: GALERA_CLUSTER\n          value: 'true'\n        - name: WSREP_CLUSTER_ADDRESS\n          value: gcomm://\n        - name: WSREP_SST_USER\n          value: sst\n        - name: WSREP_SST_PASSWORD\n          value: sst\n        - name: MYSQL_USER\n          value: mysql\n        - name: MYSQL_PASSWORD\n          value: mysql\n        - name: MYSQL_ROOT_PASSWORD\n          value: c-krit\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-qb9c2v\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-ttt3ej\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdsv7ycaz.yaml: (object: <no namespace>/pxc-node2 /v1, Kind=ReplicationController) container \"pxc-node2\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdsv7ycaz.yaml: (object: <no namespace>/pxc-node2 /v1, Kind=ReplicationController) container \"pxc-node2\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdsv7ycaz.yaml: (object: <no namespace>/pxc-node2 /v1, Kind=ReplicationController) container \"pxc-node2\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpdsv7ycaz.yaml: (object: <no namespace>/pxc-node2 /v1, Kind=ReplicationController) container \"pxc-node2\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook/legacy/frontend-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: frontend\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google_samples/gb-frontend:v4\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzqqn5y5a.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzqqn5y5a.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) container \"php-redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzqqn5y5a.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) container \"php-redis\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzqqn5y5a.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) container \"php-redis\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzqqn5y5a.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) container \"php-redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzqqn5y5a.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) container \"php-redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook/legacy/frontend-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: frontend\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: php-redis\n        image: gcr.io/google_samples/gb-frontend:v4\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-e3ybm8\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-xzx20a\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8u7hsmy0.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) object has 3 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8u7hsmy0.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) container \"php-redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8u7hsmy0.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) container \"php-redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp8u7hsmy0.yaml: (object: <no namespace>/frontend /v1, Kind=ReplicationController) container \"php-redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/podsecuritypolicy/rbac/pod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  labels:\n    name: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    ports:\n    - containerPort: 80\n    securityContext:\n      privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprewb4690.yaml: (object: <no namespace>/nginx /v1, Kind=Pod) The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprewb4690.yaml: (object: <no namespace>/nginx /v1, Kind=Pod) container \"nginx\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprewb4690.yaml: (object: <no namespace>/nginx /v1, Kind=Pod) container \"nginx\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprewb4690.yaml: (object: <no namespace>/nginx /v1, Kind=Pod) container \"nginx\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprewb4690.yaml: (object: <no namespace>/nginx /v1, Kind=Pod) container \"nginx\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprewb4690.yaml: (object: <no namespace>/nginx /v1, Kind=Pod) container \"nginx\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmprewb4690.yaml: (object: <no namespace>/nginx /v1, Kind=Pod) container \"nginx\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/podsecuritypolicy/rbac/pod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  labels:\n    name: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    ports:\n    - containerPort: 80\n    volumeMounts:\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-n9oa0j\n  volumes:\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-pzpx5h\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkzef1ck7.yaml: (object: <no namespace>/nginx /v1, Kind=Pod) The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkzef1ck7.yaml: (object: <no namespace>/nginx /v1, Kind=Pod) container \"nginx\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkzef1ck7.yaml: (object: <no namespace>/nginx /v1, Kind=Pod) container \"nginx\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkzef1ck7.yaml: (object: <no namespace>/nginx /v1, Kind=Pod) container \"nginx\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkzef1ck7.yaml: (object: <no namespace>/nginx /v1, Kind=Pod) container \"nginx\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/sysdig-cloud/sysdig-daemonset.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: sysdig-agent\n  labels:\n    app: sysdig-agent\nspec:\n  selector:\n    matchLabels:\n      name: sysdig-agent\n  template:\n    metadata:\n      labels:\n        name: sysdig-agent\n    spec:\n      volumes:\n      - name: docker-sock\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: dev-vol\n        hostPath:\n          path: /dev\n      - name: proc-vol\n        hostPath:\n          path: /proc\n      - name: boot-vol\n        hostPath:\n          path: /boot\n      - name: modules-vol\n        hostPath:\n          path: /lib/modules\n      - name: usr-vol\n        hostPath:\n          path: /usr\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-wv89ac\n          type: DirectoryOrCreate\n      hostNetwork: true\n      hostPID: true\n      containers:\n      - name: sysdig-agent\n        image: sysdig/agent\n        securityContext:\n          privileged: true\n        env:\n        - name: ACCESS_KEY\n          value: 8312341g-5678-abcd-4a2b2c-33bcsd655\n        volumeMounts:\n        - mountPath: /host/var/run/docker.sock\n          name: docker-sock\n          readOnly: false\n        - mountPath: /host/dev\n          name: dev-vol\n          readOnly: false\n        - mountPath: /host/proc\n          name: proc-vol\n          readOnly: true\n        - mountPath: /host/boot\n          name: boot-vol\n          readOnly: true\n        - mountPath: /host/lib/modules\n          name: modules-vol\n          readOnly: true\n        - mountPath: /host/usr\n          name: usr-vol\n          readOnly: true\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-f2uu8f\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4f4tkwpi.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) host system directory \"/var/run/docker.sock\" is mounted on container \"sysdig-agent\" (check: docker-sock, remediation: Ensure the Docker socket is not mounted inside any containers by removing the associated  Volume and VolumeMount in deployment yaml specification. If the Docker socket is mounted inside a container it could allow processes running within  the container to execute Docker commands which would effectively allow for full control of the host.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4f4tkwpi.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) resource shares host's network namespace (via hostNetwork=true). (check: host-network, remediation: Ensure the host's network namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4f4tkwpi.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) object shares the host's process namespace (via hostPID=true). (check: host-pid, remediation: Ensure the host's process namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4f4tkwpi.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) The container \"sysdig-agent\" is using an invalid container image, \"sysdig/agent\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4f4tkwpi.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) container \"sysdig-agent\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4f4tkwpi.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) container \"sysdig-agent\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4f4tkwpi.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) container \"sysdig-agent\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4f4tkwpi.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) container \"sysdig-agent\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4f4tkwpi.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) host system directory \"/dev\" is mounted on container \"sysdig-agent\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4f4tkwpi.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) host system directory \"/proc\" is mounted on container \"sysdig-agent\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4f4tkwpi.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) host system directory \"/boot\" is mounted on container \"sysdig-agent\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4f4tkwpi.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) host system directory \"/usr\" is mounted on container \"sysdig-agent\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4f4tkwpi.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) container \"sysdig-agent\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp4f4tkwpi.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) container \"sysdig-agent\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 14 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/sysdig-cloud/sysdig-daemonset.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: sysdig-agent\n  labels:\n    app: sysdig-agent\nspec:\n  selector:\n    matchLabels:\n      name: sysdig-agent\n  template:\n    metadata:\n      labels:\n        name: sysdig-agent\n    spec:\n      volumes:\n      - name: docker-sock\n        hostPath:\n          path: /var/run/docker.sock\n          type: Socket\n      - name: dev-vol\n        hostPath:\n          path: /dev\n      - name: proc-vol\n        hostPath:\n          path: /proc\n      - name: boot-vol\n        hostPath:\n          path: /boot\n      - name: modules-vol\n        hostPath:\n          path: /lib/modules\n      - name: usr-vol\n        hostPath:\n          path: /usr\n      hostNetwork: true\n      hostPID: true\n      containers:\n      - name: sysdig-agent\n        image: sysdig/agent\n        env:\n        - name: ACCESS_KEY\n          value: 8312341g-5678-abcd-4a2b2c-33bcsd655\n        volumeMounts:\n        - mountPath: /host/var/run/docker.sock\n          name: docker-sock\n          readOnly: false\n        - mountPath: /host/dev\n          name: dev-vol\n          readOnly: false\n        - mountPath: /host/proc\n          name: proc-vol\n          readOnly: true\n        - mountPath: /host/boot\n          name: boot-vol\n          readOnly: true\n        - mountPath: /host/lib/modules\n          name: modules-vol\n          readOnly: true\n        - mountPath: /host/usr\n          name: usr-vol\n          readOnly: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcthb4hth.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) host system directory \"/var/run/docker.sock\" is mounted on container \"sysdig-agent\" (check: docker-sock, remediation: Ensure the Docker socket is not mounted inside any containers by removing the associated  Volume and VolumeMount in deployment yaml specification. If the Docker socket is mounted inside a container it could allow processes running within  the container to execute Docker commands which would effectively allow for full control of the host.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcthb4hth.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) resource shares host's network namespace (via hostNetwork=true). (check: host-network, remediation: Ensure the host's network namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcthb4hth.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) object shares the host's process namespace (via hostPID=true). (check: host-pid, remediation: Ensure the host's process namespace is not shared.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcthb4hth.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) The container \"sysdig-agent\" is using an invalid container image, \"sysdig/agent\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcthb4hth.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) container \"sysdig-agent\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcthb4hth.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) container \"sysdig-agent\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcthb4hth.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) host system directory \"/dev\" is mounted on container \"sysdig-agent\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcthb4hth.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) host system directory \"/proc\" is mounted on container \"sysdig-agent\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcthb4hth.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) host system directory \"/boot\" is mounted on container \"sysdig-agent\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcthb4hth.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) host system directory \"/usr\" is mounted on container \"sysdig-agent\" (check: sensitive-host-mounts, remediation: Ensure sensitive host system directories are not mounted in containers by removing those Volumes and VolumeMounts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcthb4hth.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) container \"sysdig-agent\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpcthb4hth.yaml: (object: <no namespace>/sysdig-agent apps/v1, Kind=DaemonSet) container \"sysdig-agent\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 12 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook-go/redis-master-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: redis-master\n  labels:\n    app: redis\n    role: master\nspec:\n  replicas: 1\n  selector:\n    app: redis\n    role: master\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: master\n    spec:\n      containers:\n      - name: redis-master\n        image: redis\n        ports:\n        - name: redis-server\n          containerPort: 6379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxgdfo5b_.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) The container \"redis-master\" is using an invalid container image, \"redis\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxgdfo5b_.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxgdfo5b_.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxgdfo5b_.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxgdfo5b_.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxgdfo5b_.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxgdfo5b_.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook-go/redis-master-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: redis-master\n  labels:\n    app: redis\n    role: master\nspec:\n  replicas: 1\n  selector:\n    app: redis\n    role: master\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: master\n    spec:\n      containers:\n      - name: redis-master\n        image: redis\n        ports:\n        - name: redis-server\n          containerPort: 6379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-qzjypu\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-844meq\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpshkqztew.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) The container \"redis-master\" is using an invalid container image, \"redis\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpshkqztew.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpshkqztew.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpshkqztew.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpshkqztew.yaml: (object: <no namespace>/redis-master /v1, Kind=ReplicationController) container \"redis-master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/rethinkdb/admin-pod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    db: rethinkdb\n    role: admin\n  name: rethinkdb-admin\nspec:\n  containers:\n  - image: registry.k8s.io/rethinkdb:1.16.0_1\n    name: rethinkdb\n    env:\n    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    ports:\n    - containerPort: 8080\n      name: admin-port\n    - containerPort: 28015\n      name: driver-port\n    - containerPort: 29015\n      name: cluster-port\n    volumeMounts:\n    - mountPath: /data/rethinkdb_data\n      name: rethinkdb-storage\n    securityContext:\n      privileged: true\n  volumes:\n  - name: rethinkdb-storage\n    emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0hkyy4u7.yaml: (object: <no namespace>/rethinkdb-admin /v1, Kind=Pod) container \"rethinkdb\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0hkyy4u7.yaml: (object: <no namespace>/rethinkdb-admin /v1, Kind=Pod) container \"rethinkdb\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0hkyy4u7.yaml: (object: <no namespace>/rethinkdb-admin /v1, Kind=Pod) container \"rethinkdb\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0hkyy4u7.yaml: (object: <no namespace>/rethinkdb-admin /v1, Kind=Pod) container \"rethinkdb\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0hkyy4u7.yaml: (object: <no namespace>/rethinkdb-admin /v1, Kind=Pod) container \"rethinkdb\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0hkyy4u7.yaml: (object: <no namespace>/rethinkdb-admin /v1, Kind=Pod) container \"rethinkdb\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/rethinkdb/admin-pod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    db: rethinkdb\n    role: admin\n  name: rethinkdb-admin\nspec:\n  containers:\n  - image: registry.k8s.io/rethinkdb:1.16.0_1\n    name: rethinkdb\n    env:\n    - name: POD_NAMESPACE\n      valueFrom:\n        fieldRef:\n          fieldPath: metadata.namespace\n    ports:\n    - containerPort: 8080\n      name: admin-port\n    - containerPort: 28015\n      name: driver-port\n    - containerPort: 29015\n      name: cluster-port\n    volumeMounts:\n    - mountPath: /data/rethinkdb_data\n      name: rethinkdb-storage\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-isn3y5\n  volumes:\n  - name: rethinkdb-storage\n    emptyDir: {}\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-oi4yzh\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpyd345911.yaml: (object: <no namespace>/rethinkdb-admin /v1, Kind=Pod) container \"rethinkdb\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpyd345911.yaml: (object: <no namespace>/rethinkdb-admin /v1, Kind=Pod) container \"rethinkdb\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpyd345911.yaml: (object: <no namespace>/rethinkdb-admin /v1, Kind=Pod) container \"rethinkdb\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpyd345911.yaml: (object: <no namespace>/rethinkdb-admin /v1, Kind=Pod) container \"rethinkdb\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/azure_disk/claim/blob-based-disk/shared-ssd/pod-uses-shared-ssd.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-uses-shared-ssd-5g\n  labels:\n    name: storage\nspec:\n  containers:\n  - image: nginx\n    name: az-c-01\n    command:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> /mnt/blobdisk/outfile; sleep 1; done\n    volumeMounts:\n    - name: blobdisk01\n      mountPath: /mnt/blobdisk\n    securityContext:\n      privileged: true\n  volumes:\n  - name: blobdisk01\n    persistentVolumeClaim:\n      claimName: pv-dd-shared-ssd-5g\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfr91btyb.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) The container \"az-c-01\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfr91btyb.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfr91btyb.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfr91btyb.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfr91btyb.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfr91btyb.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfr91btyb.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/azure_disk/claim/blob-based-disk/shared-ssd/pod-uses-shared-ssd.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: Pod\napiVersion: v1\nmetadata:\n  name: pod-uses-shared-ssd-5g\n  labels:\n    name: storage\nspec:\n  containers:\n  - image: nginx\n    name: az-c-01\n    command:\n    - /bin/sh\n    - -c\n    - while true; do echo $(date) >> /mnt/blobdisk/outfile; sleep 1; done\n    volumeMounts:\n    - name: blobdisk01\n      mountPath: /mnt/blobdisk\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-dz3is9\n  volumes:\n  - name: blobdisk01\n    persistentVolumeClaim:\n      claimName: pv-dd-shared-ssd-5g\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-ls4nk3\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpemp2g0u5.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) The container \"az-c-01\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpemp2g0u5.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpemp2g0u5.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpemp2g0u5.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpemp2g0u5.yaml: (object: <no namespace>/pod-uses-shared-ssd-5g /v1, Kind=Pod) container \"az-c-01\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/portworx/portworx-volume-pod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-portworx-volume-pod\nspec:\n  containers:\n  - image: registry.k8s.io/test-webserver\n    name: test-container\n    volumeMounts:\n    - mountPath: /test-portworx-volume\n      name: test-volume\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test-volume\n    portworxVolume:\n      volumeID: vol1\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxfn01i7m.yaml: (object: <no namespace>/test-portworx-volume-pod /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxfn01i7m.yaml: (object: <no namespace>/test-portworx-volume-pod /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxfn01i7m.yaml: (object: <no namespace>/test-portworx-volume-pod /v1, Kind=Pod) container \"test-container\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxfn01i7m.yaml: (object: <no namespace>/test-portworx-volume-pod /v1, Kind=Pod) container \"test-container\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxfn01i7m.yaml: (object: <no namespace>/test-portworx-volume-pod /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxfn01i7m.yaml: (object: <no namespace>/test-portworx-volume-pod /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpxfn01i7m.yaml: (object: <no namespace>/test-portworx-volume-pod /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/portworx/portworx-volume-pod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-portworx-volume-pod\nspec:\n  containers:\n  - image: registry.k8s.io/test-webserver\n    name: test-container\n    volumeMounts:\n    - mountPath: /test-portworx-volume\n      name: test-volume\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-vno5mb\n  volumes:\n  - name: test-volume\n    portworxVolume:\n      volumeID: vol1\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-271r40\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2nbv2405.yaml: (object: <no namespace>/test-portworx-volume-pod /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2nbv2405.yaml: (object: <no namespace>/test-portworx-volume-pod /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2nbv2405.yaml: (object: <no namespace>/test-portworx-volume-pod /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2nbv2405.yaml: (object: <no namespace>/test-portworx-volume-pod /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2nbv2405.yaml: (object: <no namespace>/test-portworx-volume-pod /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cpu-manager/exclusive-3.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-3\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-3\n    resources:\n      requests:\n        cpu: 3\n        memory: 256M\n      limits:\n        cpu: 3\n        memory: 256M\n    securityContext:\n      privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppi3b4jm1.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) The container \"exclusive-3\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppi3b4jm1.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) container \"exclusive-3\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppi3b4jm1.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) container \"exclusive-3\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppi3b4jm1.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) container \"exclusive-3\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppi3b4jm1.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) container \"exclusive-3\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cpu-manager/exclusive-3.yaml",
    "modifications": [
      "remove_resource_limits"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-3\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-3\n    resources:\n      requests:\n        cpu: 3\n        memory: 256M\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmbypewlq.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) The container \"exclusive-3\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmbypewlq.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) container \"exclusive-3\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmbypewlq.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) container \"exclusive-3\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmbypewlq.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) container \"exclusive-3\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/cpu-manager/exclusive-3.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: exclusive-3\nspec:\n  containers:\n  - image: quay.io/connordoyle/cpuset-visualizer\n    name: exclusive-3\n    resources:\n      requests:\n        cpu: 3\n        memory: 256M\n      limits:\n        cpu: 3\n        memory: 256M\n    volumeMounts:\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-gwqppg\n  volumes:\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-5faw7x\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uaji1iy.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) The container \"exclusive-3\" is using an invalid container image, \"quay.io/connordoyle/cpuset-visualizer\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uaji1iy.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) container \"exclusive-3\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0uaji1iy.yaml: (object: <no namespace>/exclusive-3 /v1, Kind=Pod) container \"exclusive-3\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/hazelcast/hazelcast-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hazelcast\n  labels:\n    name: hazelcast\nspec:\n  selector:\n    matchLabels:\n      name: hazelcast\n  template:\n    metadata:\n      labels:\n        name: hazelcast\n    spec:\n      containers:\n      - name: hazelcast\n        image: quay.io/pires/hazelcast-kubernetes:3.8_1\n        imagePullPolicy: Always\n        env:\n        - name: DNS_DOMAIN\n          value: cluster.local\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - name: hazelcast\n          containerPort: 5701\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe3mhqal9.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe3mhqal9.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe3mhqal9.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe3mhqal9.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe3mhqal9.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe3mhqal9.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/storage/hazelcast/hazelcast-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hazelcast\n  labels:\n    name: hazelcast\nspec:\n  selector:\n    matchLabels:\n      name: hazelcast\n  template:\n    metadata:\n      labels:\n        name: hazelcast\n    spec:\n      containers:\n      - name: hazelcast\n        image: quay.io/pires/hazelcast-kubernetes:3.8_1\n        imagePullPolicy: Always\n        env:\n        - name: DNS_DOMAIN\n          value: cluster.local\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        ports:\n        - name: hazelcast\n          containerPort: 5701\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-cup6o5\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-fvp6ex\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpp7mtr66p.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpp7mtr66p.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpp7mtr66p.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpp7mtr66p.yaml: (object: <no namespace>/hazelcast apps/v1, Kind=Deployment) container \"hazelcast\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook/redis-replica-deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-replica\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: replica\n      tier: backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: replica\n        tier: backend\n    spec:\n      containers:\n      - name: slave\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq2vlgaz7.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq2vlgaz7.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"slave\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq2vlgaz7.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"slave\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq2vlgaz7.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"slave\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq2vlgaz7.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"slave\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpq2vlgaz7.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"slave\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook/redis-replica-deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-replica\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: replica\n      tier: backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: replica\n        tier: backend\n    spec:\n      containers:\n      - name: slave\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-7e2kus\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-pjz70r\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6ltyyth1.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6ltyyth1.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"slave\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6ltyyth1.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"slave\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp6ltyyth1.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"slave\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/newrelic-infrastructure/newrelic-infra-daemonset.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n  name: newrelic-infra-agent\n  labels:\n    tier: monitoring\n    app: newrelic-infra-agent\n    version: v1\nspec:\n  template:\n    metadata:\n      labels:\n        name: newrelic\n    spec:\n      hostPID: true\n      hostIPC: true\n      hostNetwork: true\n      containers:\n      - resources:\n          requests:\n            cpu: 0.15\n        securityContext:\n          privileged: true\n        image: newrelic/infrastructure\n        name: newrelic\n        command:\n        - bash\n        - -c\n        - source /etc/kube-nr-infra/config && /usr/bin/newrelic-infra\n        volumeMounts:\n        - name: newrelic-config\n          mountPath: /etc/kube-nr-infra\n          readOnly: true\n        - name: dev\n          mountPath: /dev\n        - name: run\n          mountPath: /var/run/docker.sock\n        - name: log\n          mountPath: /var/log\n        - name: host-root\n          mountPath: /host\n          readOnly: true\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-75oc5j\n      volumes:\n      - name: newrelic-config\n        secret:\n          secretName: newrelic-config\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: run\n        hostPath:\n          path: /var/run/docker.sock\n      - name: log\n        hostPath:\n          path: /var/log\n      - name: host-root\n        hostPath:\n          path: /\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-kyawzj\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2bczukfv.yaml: (object: <no namespace>/newrelic-infra-agent extensions/v1beta1, Kind=DaemonSet) disallowed API object found: extensions/v1beta1, Kind=DaemonSet (check: no-extensions-v1beta, remediation: Migrate using the apps/v1 API versions for the objects. Refer to https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/ for details.)\n\nError: found 1 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/newrelic-infrastructure/newrelic-infra-daemonset.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n  name: newrelic-infra-agent\n  labels:\n    tier: monitoring\n    app: newrelic-infra-agent\n    version: v1\nspec:\n  template:\n    metadata:\n      labels:\n        name: newrelic\n    spec:\n      hostPID: true\n      hostIPC: true\n      hostNetwork: true\n      containers:\n      - resources:\n          requests:\n            cpu: 0.15\n        image: newrelic/infrastructure\n        name: newrelic\n        command:\n        - bash\n        - -c\n        - source /etc/kube-nr-infra/config && /usr/bin/newrelic-infra\n        volumeMounts:\n        - name: newrelic-config\n          mountPath: /etc/kube-nr-infra\n          readOnly: true\n        - name: dev\n          mountPath: /dev\n        - name: run\n          mountPath: /var/run/docker.sock\n        - name: log\n          mountPath: /var/log\n        - name: host-root\n          mountPath: /host\n          readOnly: true\n      volumes:\n      - name: newrelic-config\n        secret:\n          secretName: newrelic-config\n      - name: dev\n        hostPath:\n          path: /dev\n      - name: run\n        hostPath:\n          path: /var/run/docker.sock\n      - name: log\n        hostPath:\n          path: /var/log\n      - name: host-root\n        hostPath:\n          path: /\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp3zogv9nz.yaml: (object: <no namespace>/newrelic-infra-agent extensions/v1beta1, Kind=DaemonSet) disallowed API object found: extensions/v1beta1, Kind=DaemonSet (check: no-extensions-v1beta, remediation: Migrate using the apps/v1 API versions for the objects. Refer to https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/ for details.)\n\nError: found 1 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/flexvolume/deploy/ds.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n  name: flex-ds\nspec:\n  template:\n    metadata:\n      name: flex-deploy\n      labels:\n        app: flex-deploy\n    spec:\n      containers:\n      - image: <image_url>\n        name: flex-deploy\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - mountPath: /flexmnt\n          name: flexvolume-mount\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-dw4mcg\n      volumes:\n      - name: flexvolume-mount\n        hostPath:\n          path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-zik12x\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpsoia6vmy.yaml: (object: <no namespace>/flex-ds extensions/v1beta1, Kind=DaemonSet) disallowed API object found: extensions/v1beta1, Kind=DaemonSet (check: no-extensions-v1beta, remediation: Migrate using the apps/v1 API versions for the objects. Refer to https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/ for details.)\n\nError: found 1 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/flexvolume/deploy/ds.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n  name: flex-ds\nspec:\n  template:\n    metadata:\n      name: flex-deploy\n      labels:\n        app: flex-deploy\n    spec:\n      containers:\n      - image: <image_url>\n        name: flex-deploy\n        volumeMounts:\n        - mountPath: /flexmnt\n          name: flexvolume-mount\n      volumes:\n      - name: flexvolume-mount\n        hostPath:\n          path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpnk2x8532.yaml: (object: <no namespace>/flex-ds extensions/v1beta1, Kind=DaemonSet) disallowed API object found: extensions/v1beta1, Kind=DaemonSet (check: no-extensions-v1beta, remediation: Migrate using the apps/v1 API versions for the objects. Refer to https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/ for details.)\n\nError: found 1 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/scaleio/pod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-0\nspec:\n  containers:\n  - image: registry.k8s.io/test-webserver\n    name: pod-0\n    volumeMounts:\n    - mountPath: /test-pd\n      name: vol-0\n    securityContext:\n      privileged: true\n  volumes:\n  - name: vol-0\n    scaleIO:\n      gateway: https://localhost:443/api\n      system: scaleio\n      protectionDoamin: pd01\n      storagePool: sp01\n      volumeName: vol-0\n      secretRef:\n        name: sio-secret\n      fsType: xfs\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpj5p2o_wz.yaml: (object: <no namespace>/pod-0 /v1, Kind=Pod) The container \"pod-0\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpj5p2o_wz.yaml: (object: <no namespace>/pod-0 /v1, Kind=Pod) container \"pod-0\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpj5p2o_wz.yaml: (object: <no namespace>/pod-0 /v1, Kind=Pod) container \"pod-0\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpj5p2o_wz.yaml: (object: <no namespace>/pod-0 /v1, Kind=Pod) container \"pod-0\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpj5p2o_wz.yaml: (object: <no namespace>/pod-0 /v1, Kind=Pod) container \"pod-0\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpj5p2o_wz.yaml: (object: <no namespace>/pod-0 /v1, Kind=Pod) container \"pod-0\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpj5p2o_wz.yaml: (object: <no namespace>/pod-0 /v1, Kind=Pod) container \"pod-0\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/scaleio/pod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-0\nspec:\n  containers:\n  - image: registry.k8s.io/test-webserver\n    name: pod-0\n    volumeMounts:\n    - mountPath: /test-pd\n      name: vol-0\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-ls27yj\n  volumes:\n  - name: vol-0\n    scaleIO:\n      gateway: https://localhost:443/api\n      system: scaleio\n      protectionDoamin: pd01\n      storagePool: sp01\n      volumeName: vol-0\n      secretRef:\n        name: sio-secret\n      fsType: xfs\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-p6snel\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp86xyomgq.yaml: (object: <no namespace>/pod-0 /v1, Kind=Pod) The container \"pod-0\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp86xyomgq.yaml: (object: <no namespace>/pod-0 /v1, Kind=Pod) container \"pod-0\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp86xyomgq.yaml: (object: <no namespace>/pod-0 /v1, Kind=Pod) container \"pod-0\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp86xyomgq.yaml: (object: <no namespace>/pod-0 /v1, Kind=Pod) container \"pod-0\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp86xyomgq.yaml: (object: <no namespace>/pod-0 /v1, Kind=Pod) container \"pod-0\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/https-nginx/nginx-app.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: my-nginx\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      volumes:\n      - name: secret-volume\n        secret:\n          secretName: nginxsecret\n      - name: configmap-volume\n        configMap:\n          name: nginxconfigmap\n      containers:\n      - name: nginxhttps\n        image: ymqytw/nginxhttps:1.5\n        command:\n        - /home/auto-reload-nginx.sh\n        ports:\n        - containerPort: 443\n        - containerPort: 80\n        livenessProbe:\n          httpGet:\n            path: /index.html\n            port: 80\n          initialDelaySeconds: 30\n          timeoutSeconds: 1\n        volumeMounts:\n        - mountPath: /etc/nginx/ssl\n          name: secret-volume\n        - mountPath: /etc/nginx/conf.d\n          name: configmap-volume\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqlryvvex.yaml: (object: <no namespace>/my-nginx /v1, Kind=ReplicationController) container \"nginxhttps\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqlryvvex.yaml: (object: <no namespace>/my-nginx /v1, Kind=ReplicationController) container \"nginxhttps\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqlryvvex.yaml: (object: <no namespace>/my-nginx /v1, Kind=ReplicationController) container \"nginxhttps\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqlryvvex.yaml: (object: <no namespace>/my-nginx /v1, Kind=ReplicationController) container \"nginxhttps\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqlryvvex.yaml: (object: <no namespace>/my-nginx /v1, Kind=ReplicationController) container \"nginxhttps\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqlryvvex.yaml: (object: <no namespace>/my-nginx /v1, Kind=ReplicationController) container \"nginxhttps\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/https-nginx/nginx-app.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: my-nginx\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      volumes:\n      - name: secret-volume\n        secret:\n          secretName: nginxsecret\n      - name: configmap-volume\n        configMap:\n          name: nginxconfigmap\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-z46v3e\n          type: DirectoryOrCreate\n      containers:\n      - name: nginxhttps\n        image: ymqytw/nginxhttps:1.5\n        command:\n        - /home/auto-reload-nginx.sh\n        ports:\n        - containerPort: 443\n        - containerPort: 80\n        livenessProbe:\n          httpGet:\n            path: /index.html\n            port: 80\n          initialDelaySeconds: 30\n          timeoutSeconds: 1\n        volumeMounts:\n        - mountPath: /etc/nginx/ssl\n          name: secret-volume\n        - mountPath: /etc/nginx/conf.d\n          name: configmap-volume\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-ufz405\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmjjb_mme.yaml: (object: <no namespace>/my-nginx /v1, Kind=ReplicationController) container \"nginxhttps\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmjjb_mme.yaml: (object: <no namespace>/my-nginx /v1, Kind=ReplicationController) container \"nginxhttps\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmjjb_mme.yaml: (object: <no namespace>/my-nginx /v1, Kind=ReplicationController) container \"nginxhttps\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmjjb_mme.yaml: (object: <no namespace>/my-nginx /v1, Kind=ReplicationController) container \"nginxhttps\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/flocker/flocker-pod-with-rc.yml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: flocker-ghost\n  labels:\n    purpose: demo\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: flocker-ghost\n    spec:\n      containers:\n      - name: flocker-ghost\n        image: ghost:0.7.1\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 2368\n          hostPort: 80\n          protocol: TCP\n        volumeMounts:\n        - name: ghost-data\n          mountPath: /var/lib/ghost\n        securityContext:\n          privileged: true\n      volumes:\n      - name: ghost-data\n        flocker:\n          datasetName: my-flocker-vol\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmputtkzm9_.yaml: (object: <no namespace>/flocker-ghost /v1, Kind=ReplicationController) container \"flocker-ghost\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmputtkzm9_.yaml: (object: <no namespace>/flocker-ghost /v1, Kind=ReplicationController) container \"flocker-ghost\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmputtkzm9_.yaml: (object: <no namespace>/flocker-ghost /v1, Kind=ReplicationController) container \"flocker-ghost\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmputtkzm9_.yaml: (object: <no namespace>/flocker-ghost /v1, Kind=ReplicationController) container \"flocker-ghost\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmputtkzm9_.yaml: (object: <no namespace>/flocker-ghost /v1, Kind=ReplicationController) container \"flocker-ghost\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmputtkzm9_.yaml: (object: <no namespace>/flocker-ghost /v1, Kind=ReplicationController) container \"flocker-ghost\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/flocker/flocker-pod-with-rc.yml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: flocker-ghost\n  labels:\n    purpose: demo\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: flocker-ghost\n    spec:\n      containers:\n      - name: flocker-ghost\n        image: ghost:0.7.1\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 2368\n          hostPort: 80\n          protocol: TCP\n        volumeMounts:\n        - name: ghost-data\n          mountPath: /var/lib/ghost\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-9fo0mw\n      volumes:\n      - name: ghost-data\n        flocker:\n          datasetName: my-flocker-vol\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-zani6q\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt9tceabl.yaml: (object: <no namespace>/flocker-ghost /v1, Kind=ReplicationController) container \"flocker-ghost\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt9tceabl.yaml: (object: <no namespace>/flocker-ghost /v1, Kind=ReplicationController) container \"flocker-ghost\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt9tceabl.yaml: (object: <no namespace>/flocker-ghost /v1, Kind=ReplicationController) container \"flocker-ghost\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpt9tceabl.yaml: (object: <no namespace>/flocker-ghost /v1, Kind=ReplicationController) container \"flocker-ghost\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/javaee/mysql-pod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mysql-pod\n  labels:\n    name: mysql-pod\n    context: docker-k8s-lab\nspec:\n  containers:\n  - name: mysql\n    image: mysql:latest\n    env:\n    - name: MYSQL_USER\n      value: mysql\n    - name: MYSQL_PASSWORD\n      value: mysql\n    - name: MYSQL_DATABASE\n      value: sample\n    - name: MYSQL_ROOT_PASSWORD\n      value: supersecret\n    ports:\n    - containerPort: 3306\n    securityContext:\n      privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmewtylpw.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) The container \"mysql\" is using an invalid container image, \"mysql:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmewtylpw.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmewtylpw.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmewtylpw.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmewtylpw.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmewtylpw.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmewtylpw.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/javaee/mysql-pod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: mysql-pod\n  labels:\n    name: mysql-pod\n    context: docker-k8s-lab\nspec:\n  containers:\n  - name: mysql\n    image: mysql:latest\n    env:\n    - name: MYSQL_USER\n      value: mysql\n    - name: MYSQL_PASSWORD\n      value: mysql\n    - name: MYSQL_DATABASE\n      value: sample\n    - name: MYSQL_ROOT_PASSWORD\n      value: supersecret\n    ports:\n    - containerPort: 3306\n    volumeMounts:\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-migktp\n  volumes:\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-uscwyb\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp74uw6wu5.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) The container \"mysql\" is using an invalid container image, \"mysql:latest\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp74uw6wu5.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp74uw6wu5.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp74uw6wu5.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp74uw6wu5.yaml: (object: <no namespace>/mysql-pod /v1, Kind=Pod) container \"mysql\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/spark/zeppelin-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: zeppelin-controller\nspec:\n  replicas: 1\n  selector:\n    component: zeppelin\n  template:\n    metadata:\n      labels:\n        component: zeppelin\n    spec:\n      containers:\n      - name: zeppelin\n        image: registry.k8s.io/zeppelin:v0.5.6_v1\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1z5jxht8.yaml: (object: <no namespace>/zeppelin-controller /v1, Kind=ReplicationController) container \"zeppelin\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1z5jxht8.yaml: (object: <no namespace>/zeppelin-controller /v1, Kind=ReplicationController) container \"zeppelin\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1z5jxht8.yaml: (object: <no namespace>/zeppelin-controller /v1, Kind=ReplicationController) container \"zeppelin\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1z5jxht8.yaml: (object: <no namespace>/zeppelin-controller /v1, Kind=ReplicationController) container \"zeppelin\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp1z5jxht8.yaml: (object: <no namespace>/zeppelin-controller /v1, Kind=ReplicationController) container \"zeppelin\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/spark/zeppelin-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: zeppelin-controller\nspec:\n  replicas: 1\n  selector:\n    component: zeppelin\n  template:\n    metadata:\n      labels:\n        component: zeppelin\n    spec:\n      containers:\n      - name: zeppelin\n        image: registry.k8s.io/zeppelin:v0.5.6_v1\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            cpu: 100m\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-9mgmen\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-tl3q17\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpesy3av04.yaml: (object: <no namespace>/zeppelin-controller /v1, Kind=ReplicationController) container \"zeppelin\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpesy3av04.yaml: (object: <no namespace>/zeppelin-controller /v1, Kind=ReplicationController) container \"zeppelin\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpesy3av04.yaml: (object: <no namespace>/zeppelin-controller /v1, Kind=ReplicationController) container \"zeppelin\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/elasticsearch/production_cluster/es-master-rc.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es-master\n  labels:\n    component: elasticsearch\n    role: master\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n        role: master\n    spec:\n      serviceAccount: elasticsearch\n      containers:\n      - name: es-master\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n          privileged: true\n        image: quay.io/pires/docker-elasticsearch-kubernetes:1.7.1-4\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: myesdb\n        - name: NODE_MASTER\n          value: 'true'\n        - name: NODE_DATA\n          value: 'false'\n        - name: HTTP_ENABLE\n          value: 'false'\n        ports:\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n      volumes:\n      - name: storage\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzskhphmv.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) serviceAccount is specified (elasticsearch), but this field is deprecated; use serviceAccountName instead (check: deprecated-service-account-field, remediation: Use the serviceAccountName field instead. If you must specify serviceAccount, ensure values for serviceAccount and serviceAccountName match.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzskhphmv.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzskhphmv.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzskhphmv.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) serviceAccount \"elasticsearch\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzskhphmv.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzskhphmv.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzskhphmv.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzskhphmv.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpzskhphmv.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 9 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/elasticsearch/production_cluster/es-master-rc.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es-master\n  labels:\n    component: elasticsearch\n    role: master\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n        role: master\n    spec:\n      serviceAccount: elasticsearch\n      containers:\n      - name: es-master\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n        image: quay.io/pires/docker-elasticsearch-kubernetes:1.7.1-4\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: myesdb\n        - name: NODE_MASTER\n          value: 'true'\n        - name: NODE_DATA\n          value: 'false'\n        - name: HTTP_ENABLE\n          value: 'false'\n        ports:\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-y0btpo\n      volumes:\n      - name: storage\n        emptyDir: {}\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-nvatu1\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkktai028.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) serviceAccount is specified (elasticsearch), but this field is deprecated; use serviceAccountName instead (check: deprecated-service-account-field, remediation: Use the serviceAccountName field instead. If you must specify serviceAccount, ensure values for serviceAccount and serviceAccountName match.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkktai028.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkktai028.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkktai028.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) serviceAccount \"elasticsearch\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkktai028.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkktai028.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpkktai028.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/elasticsearch/production_cluster/es-master-rc.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es-master\n  labels:\n    component: elasticsearch\n    role: master\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n        role: master\n    spec:\n      serviceAccount: elasticsearch\n      containers:\n      - name: es-master\n        image: quay.io/pires/docker-elasticsearch-kubernetes:1.7.1-4\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: myesdb\n        - name: NODE_MASTER\n          value: 'true'\n        - name: NODE_DATA\n          value: 'false'\n        - name: HTTP_ENABLE\n          value: 'false'\n        ports:\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n      volumes:\n      - name: storage\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqs8czpza.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) serviceAccount is specified (elasticsearch), but this field is deprecated; use serviceAccountName instead (check: deprecated-service-account-field, remediation: Use the serviceAccountName field instead. If you must specify serviceAccount, ensure values for serviceAccount and serviceAccountName match.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqs8czpza.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqs8czpza.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) serviceAccount \"elasticsearch\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqs8czpza.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqs8czpza.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqs8czpza.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/spark/spark-worker-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: spark-worker-controller\nspec:\n  replicas: 2\n  selector:\n    component: spark-worker\n  template:\n    metadata:\n      labels:\n        component: spark-worker\n    spec:\n      containers:\n      - name: spark-worker\n        image: registry.k8s.io/spark:1.5.2_v1\n        command:\n        - /start-worker\n        ports:\n        - containerPort: 8081\n        resources:\n          requests:\n            cpu: 100m\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7pk9rqcg.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7pk9rqcg.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) container \"spark-worker\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7pk9rqcg.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) container \"spark-worker\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7pk9rqcg.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) container \"spark-worker\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7pk9rqcg.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) container \"spark-worker\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7pk9rqcg.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) container \"spark-worker\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/spark/spark-worker-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: spark-worker-controller\nspec:\n  replicas: 2\n  selector:\n    component: spark-worker\n  template:\n    metadata:\n      labels:\n        component: spark-worker\n    spec:\n      containers:\n      - name: spark-worker\n        image: registry.k8s.io/spark:1.5.2_v1\n        command:\n        - /start-worker\n        ports:\n        - containerPort: 8081\n        resources:\n          requests:\n            cpu: 100m\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-i1w7hw\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-thgfac\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpu6je2wr5.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpu6je2wr5.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) container \"spark-worker\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpu6je2wr5.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) container \"spark-worker\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpu6je2wr5.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) container \"spark-worker\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/spark/spark-ui-proxy-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: spark-ui-proxy-controller\nspec:\n  replicas: 1\n  selector:\n    component: spark-ui-proxy\n  template:\n    metadata:\n      labels:\n        component: spark-ui-proxy\n    spec:\n      containers:\n      - name: spark-ui-proxy\n        image: elsonrodriguez/spark-ui-proxy:1.0\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n        args:\n        - spark-master:8080\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 80\n          initialDelaySeconds: 120\n          timeoutSeconds: 5\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqbo6ynvi.yaml: (object: <no namespace>/spark-ui-proxy-controller /v1, Kind=ReplicationController) container \"spark-ui-proxy\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqbo6ynvi.yaml: (object: <no namespace>/spark-ui-proxy-controller /v1, Kind=ReplicationController) container \"spark-ui-proxy\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqbo6ynvi.yaml: (object: <no namespace>/spark-ui-proxy-controller /v1, Kind=ReplicationController) container \"spark-ui-proxy\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqbo6ynvi.yaml: (object: <no namespace>/spark-ui-proxy-controller /v1, Kind=ReplicationController) container \"spark-ui-proxy\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpqbo6ynvi.yaml: (object: <no namespace>/spark-ui-proxy-controller /v1, Kind=ReplicationController) container \"spark-ui-proxy\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/spark/spark-ui-proxy-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: spark-ui-proxy-controller\nspec:\n  replicas: 1\n  selector:\n    component: spark-ui-proxy\n  template:\n    metadata:\n      labels:\n        component: spark-ui-proxy\n    spec:\n      containers:\n      - name: spark-ui-proxy\n        image: elsonrodriguez/spark-ui-proxy:1.0\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: 100m\n        args:\n        - spark-master:8080\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 80\n          initialDelaySeconds: 120\n          timeoutSeconds: 5\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-li5fkw\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-7b9eaz\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmposya0gjr.yaml: (object: <no namespace>/spark-ui-proxy-controller /v1, Kind=ReplicationController) container \"spark-ui-proxy\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmposya0gjr.yaml: (object: <no namespace>/spark-ui-proxy-controller /v1, Kind=ReplicationController) container \"spark-ui-proxy\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmposya0gjr.yaml: (object: <no namespace>/spark-ui-proxy-controller /v1, Kind=ReplicationController) container \"spark-ui-proxy\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 3 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/vsphere/deployment.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: deployment\nspec:\n  selector:\n    matchLabels:\n      app: redis\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis\n        volumeMounts:\n        - name: vmfs-vmdk-storage\n          mountPath: /data/\n        securityContext:\n          privileged: true\n      volumes:\n      - name: vmfs-vmdk-storage\n        vsphereVolume:\n          volumePath: '[Datastore] volumes/testdir'\n          fsType: ext4\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpc9hpgl2d.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) The container \"redis\" is using an invalid container image, \"redis\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpc9hpgl2d.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpc9hpgl2d.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpc9hpgl2d.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpc9hpgl2d.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpc9hpgl2d.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpc9hpgl2d.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/vsphere/deployment.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: deployment\nspec:\n  selector:\n    matchLabels:\n      app: redis\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis\n        volumeMounts:\n        - name: vmfs-vmdk-storage\n          mountPath: /data/\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-osanxv\n      volumes:\n      - name: vmfs-vmdk-storage\n        vsphereVolume:\n          volumePath: '[Datastore] volumes/testdir'\n          fsType: ext4\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-0iq63i\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd6a35u9q.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) The container \"redis\" is using an invalid container image, \"redis\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd6a35u9q.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd6a35u9q.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd6a35u9q.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd6a35u9q.yaml: (object: <no namespace>/deployment apps/v1, Kind=Deployment) container \"redis\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook/all-in-one/redis-replica.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-replica\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: replica\n      tier: backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: replica\n        tier: backend\n    spec:\n      containers:\n      - name: replica\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpshv16edd.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpshv16edd.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpshv16edd.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpshv16edd.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpshv16edd.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpshv16edd.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/guestbook/all-in-one/redis-replica.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis-replica\nspec:\n  selector:\n    matchLabels:\n      app: redis\n      role: replica\n      tier: backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: redis\n        role: replica\n        tier: backend\n    spec:\n      containers:\n      - name: replica\n        image: gcr.io/google_samples/gb-redisslave:v1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 6379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-x8y480\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-sv4yr0\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0kf0xfv5.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0kf0xfv5.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0kf0xfv5.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp0kf0xfv5.yaml: (object: <no namespace>/redis-replica apps/v1, Kind=Deployment) container \"replica\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/flexvolume/nginx.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  namespace: default\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - name: test\n      mountPath: /data\n    ports:\n    - containerPort: 80\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test\n    flexVolume:\n      driver: kubernetes.io/lvm\n      fsType: ext4\n      options:\n        volumeID: vol1\n        size: 1000m\n        volumegroup: kube_vg\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe8ki6q0z.yaml: (object: default/nginx /v1, Kind=Pod) The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe8ki6q0z.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe8ki6q0z.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe8ki6q0z.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe8ki6q0z.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe8ki6q0z.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpe8ki6q0z.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/flexvolume/nginx.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  namespace: default\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n    - name: test\n      mountPath: /data\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-fvmryu\n    ports:\n    - containerPort: 80\n  volumes:\n  - name: test\n    flexVolume:\n      driver: kubernetes.io/lvm\n      fsType: ext4\n      options:\n        volumeID: vol1\n        size: 1000m\n        volumegroup: kube_vg\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-i93hik\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz0v8gto6.yaml: (object: default/nginx /v1, Kind=Pod) The container \"nginx\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz0v8gto6.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz0v8gto6.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz0v8gto6.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz0v8gto6.yaml: (object: default/nginx /v1, Kind=Pod) container \"nginx\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/spark/spark-worker-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: spark-worker-controller\nspec:\n  replicas: 2\n  selector:\n    component: spark-worker\n  template:\n    metadata:\n      labels:\n        component: spark-worker\n    spec:\n      containers:\n      - name: spark-worker\n        image: registry.k8s.io/spark:1.5.2_v1\n        command:\n        - /start-worker\n        ports:\n        - containerPort: 8081\n        resources:\n          requests:\n            cpu: 100m\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2lgnr0c1.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2lgnr0c1.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) container \"spark-worker\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2lgnr0c1.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) container \"spark-worker\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2lgnr0c1.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) container \"spark-worker\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2lgnr0c1.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) container \"spark-worker\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp2lgnr0c1.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) container \"spark-worker\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/spark/spark-worker-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "kind: ReplicationController\napiVersion: v1\nmetadata:\n  name: spark-worker-controller\nspec:\n  replicas: 2\n  selector:\n    component: spark-worker\n  template:\n    metadata:\n      labels:\n        component: spark-worker\n    spec:\n      containers:\n      - name: spark-worker\n        image: registry.k8s.io/spark:1.5.2_v1\n        command:\n        - /start-worker\n        ports:\n        - containerPort: 8081\n        resources:\n          requests:\n            cpu: 100m\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-0bu0l8\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-781gb6\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvdo0ef4x.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvdo0ef4x.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) container \"spark-worker\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvdo0ef4x.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) container \"spark-worker\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvdo0ef4x.yaml: (object: <no namespace>/spark-worker-controller /v1, Kind=ReplicationController) container \"spark-worker\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cockroachdb/cockroachdb-statefulset.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: cockroachdb\n  labels:\n    app: cockroachdb\nspec:\n  serviceName: cockroachdb\n  replicas: 3\n  selector:\n    matchLabels:\n      app: cockroachdb\n  template:\n    metadata:\n      labels:\n        app: cockroachdb\n    spec:\n      initContainers:\n      - name: bootstrap\n        image: cockroachdb/cockroach-k8s-init:0.2\n        imagePullPolicy: IfNotPresent\n        args:\n        - -on-start=/on-start.sh\n        - -service=cockroachdb\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: datadir\n          mountPath: /cockroach/cockroach-data\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - cockroachdb\n              topologyKey: kubernetes.io/hostname\n      containers:\n      - name: cockroachdb\n        image: cockroachdb/cockroach:v1.1.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 26257\n          name: grpc\n        - containerPort: 8080\n          name: http\n        volumeMounts:\n        - name: datadir\n          mountPath: /cockroach/cockroach-data\n        command:\n        - /bin/bash\n        - -ecx\n        - \"# The use of qualified `hostname -f` is crucial:\\n# Other nodes aren't\\\n          \\ able to look up the unqualified hostname.\\nCRARGS=(\\\"start\\\" \\\"--logtostderr\\\"\\\n          \\ \\\"--insecure\\\" \\\"--host\\\" \\\"$(hostname -f)\\\" \\\"--http-host\\\" \\\"0.0.0.0\\\"\\\n          )\\n# We only want to initialize a new cluster (by omitting the join flag)\\n\\\n          # if we're sure that we're the first node (i.e. index 0) and that\\n# there\\\n          \\ aren't any other nodes running as part of the cluster that\\n# this is\\\n          \\ supposed to be a part of (which indicates that a cluster\\n# already exists\\\n          \\ and we should make sure not to create a new one).\\n# It's fine to run\\\n          \\ without --join on a restart if there aren't any\\n# other nodes.\\nif [\\\n          \\ ! \\\"$(hostname)\\\" == \\\"cockroachdb-0\\\" ] || \\\\\\n   [ -e \\\"/cockroach/cockroach-data/cluster_exists_marker\\\"\\\n          \\ ]\\nthen\\n  # We don't join cockroachdb in order to avoid a node attempting\\n\\\n          \\  # to join itself, which currently doesn't work\\n  # (https://github.com/cockroachdb/cockroach/issues/9625).\\n\\\n          \\  CRARGS+=(\\\"--join\\\" \\\"cockroachdb-public\\\")\\nfi\\nexec /cockroach/cockroach\\\n          \\ ${CRARGS[*]}\\n\"\n        securityContext:\n          privileged: true\n      terminationGracePeriodSeconds: 60\n      volumes:\n      - name: datadir\n        persistentVolumeClaim:\n          claimName: datadir\n  volumeClaimTemplates:\n  - metadata:\n      name: datadir\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 1Gi\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb2nrdwrf.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"bootstrap\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb2nrdwrf.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb2nrdwrf.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb2nrdwrf.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb2nrdwrf.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"bootstrap\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb2nrdwrf.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb2nrdwrf.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"bootstrap\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb2nrdwrf.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb2nrdwrf.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"bootstrap\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpb2nrdwrf.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 10 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/cockroachdb/cockroachdb-statefulset.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: cockroachdb\n  labels:\n    app: cockroachdb\nspec:\n  serviceName: cockroachdb\n  replicas: 3\n  selector:\n    matchLabels:\n      app: cockroachdb\n  template:\n    metadata:\n      labels:\n        app: cockroachdb\n    spec:\n      initContainers:\n      - name: bootstrap\n        image: cockroachdb/cockroach-k8s-init:0.2\n        imagePullPolicy: IfNotPresent\n        args:\n        - -on-start=/on-start.sh\n        - -service=cockroachdb\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        volumeMounts:\n        - name: datadir\n          mountPath: /cockroach/cockroach-data\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - cockroachdb\n              topologyKey: kubernetes.io/hostname\n      containers:\n      - name: cockroachdb\n        image: cockroachdb/cockroach:v1.1.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 26257\n          name: grpc\n        - containerPort: 8080\n          name: http\n        volumeMounts:\n        - name: datadir\n          mountPath: /cockroach/cockroach-data\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-4hphy8\n        command:\n        - /bin/bash\n        - -ecx\n        - \"# The use of qualified `hostname -f` is crucial:\\n# Other nodes aren't\\\n          \\ able to look up the unqualified hostname.\\nCRARGS=(\\\"start\\\" \\\"--logtostderr\\\"\\\n          \\ \\\"--insecure\\\" \\\"--host\\\" \\\"$(hostname -f)\\\" \\\"--http-host\\\" \\\"0.0.0.0\\\"\\\n          )\\n# We only want to initialize a new cluster (by omitting the join flag)\\n\\\n          # if we're sure that we're the first node (i.e. index 0) and that\\n# there\\\n          \\ aren't any other nodes running as part of the cluster that\\n# this is\\\n          \\ supposed to be a part of (which indicates that a cluster\\n# already exists\\\n          \\ and we should make sure not to create a new one).\\n# It's fine to run\\\n          \\ without --join on a restart if there aren't any\\n# other nodes.\\nif [\\\n          \\ ! \\\"$(hostname)\\\" == \\\"cockroachdb-0\\\" ] || \\\\\\n   [ -e \\\"/cockroach/cockroach-data/cluster_exists_marker\\\"\\\n          \\ ]\\nthen\\n  # We don't join cockroachdb in order to avoid a node attempting\\n\\\n          \\  # to join itself, which currently doesn't work\\n  # (https://github.com/cockroachdb/cockroach/issues/9625).\\n\\\n          \\  CRARGS+=(\\\"--join\\\" \\\"cockroachdb-public\\\")\\nfi\\nexec /cockroach/cockroach\\\n          \\ ${CRARGS[*]}\\n\"\n      terminationGracePeriodSeconds: 60\n      volumes:\n      - name: datadir\n        persistentVolumeClaim:\n          claimName: datadir\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-3pybtf\n          type: DirectoryOrCreate\n  volumeClaimTemplates:\n  - metadata:\n      name: datadir\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 1Gi\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgmotoaid.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"bootstrap\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgmotoaid.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgmotoaid.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"bootstrap\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgmotoaid.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgmotoaid.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"bootstrap\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgmotoaid.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgmotoaid.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"bootstrap\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpgmotoaid.yaml: (object: <no namespace>/cockroachdb apps/v1, Kind=StatefulSet) container \"cockroachdb\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 8 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/elasticsearch/production_cluster/es-master-rc.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es-master\n  labels:\n    component: elasticsearch\n    role: master\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n        role: master\n    spec:\n      serviceAccount: elasticsearch\n      containers:\n      - name: es-master\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n          privileged: true\n        image: quay.io/pires/docker-elasticsearch-kubernetes:1.7.1-4\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: myesdb\n        - name: NODE_MASTER\n          value: 'true'\n        - name: NODE_DATA\n          value: 'false'\n        - name: HTTP_ENABLE\n          value: 'false'\n        ports:\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n      volumes:\n      - name: storage\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvdattl5h.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) serviceAccount is specified (elasticsearch), but this field is deprecated; use serviceAccountName instead (check: deprecated-service-account-field, remediation: Use the serviceAccountName field instead. If you must specify serviceAccount, ensure values for serviceAccount and serviceAccountName match.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvdattl5h.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvdattl5h.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvdattl5h.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) serviceAccount \"elasticsearch\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvdattl5h.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvdattl5h.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvdattl5h.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvdattl5h.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvdattl5h.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 9 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/elasticsearch/production_cluster/es-master-rc.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es-master\n  labels:\n    component: elasticsearch\n    role: master\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n        role: master\n    spec:\n      serviceAccount: elasticsearch\n      containers:\n      - name: es-master\n        securityContext:\n          capabilities:\n            add:\n            - IPC_LOCK\n        image: quay.io/pires/docker-elasticsearch-kubernetes:1.7.1-4\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: myesdb\n        - name: NODE_MASTER\n          value: 'true'\n        - name: NODE_DATA\n          value: 'false'\n        - name: HTTP_ENABLE\n          value: 'false'\n        ports:\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-159jho\n      volumes:\n      - name: storage\n        emptyDir: {}\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-eg5805\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmld3egzo.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) serviceAccount is specified (elasticsearch), but this field is deprecated; use serviceAccountName instead (check: deprecated-service-account-field, remediation: Use the serviceAccountName field instead. If you must specify serviceAccount, ensure values for serviceAccount and serviceAccountName match.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmld3egzo.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" has DROP capabilities: [], but does not drop capability \"NET_RAW\" which is required (check: drop-net-raw-capability, remediation: NET_RAW makes it so that an application within the container is able to craft raw packets, use raw sockets, and bind to any address. Remove this capability in the containers under containers security contexts.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmld3egzo.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmld3egzo.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) serviceAccount \"elasticsearch\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmld3egzo.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmld3egzo.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpmld3egzo.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/elasticsearch/production_cluster/es-master-rc.yaml",
    "modifications": [
      "remove_security_context"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: es-master\n  labels:\n    component: elasticsearch\n    role: master\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        component: elasticsearch\n        role: master\n    spec:\n      serviceAccount: elasticsearch\n      containers:\n      - name: es-master\n        image: quay.io/pires/docker-elasticsearch-kubernetes:1.7.1-4\n        env:\n        - name: KUBERNETES_CA_CERTIFICATE_FILE\n          value: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        - name: NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: CLUSTER_NAME\n          value: myesdb\n        - name: NODE_MASTER\n          value: 'true'\n        - name: NODE_DATA\n          value: 'false'\n        - name: HTTP_ENABLE\n          value: 'false'\n        ports:\n        - containerPort: 9300\n          name: transport\n          protocol: TCP\n        volumeMounts:\n        - mountPath: /data\n          name: storage\n      volumes:\n      - name: storage\n        emptyDir: {}\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphm85jov1.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) serviceAccount is specified (elasticsearch), but this field is deprecated; use serviceAccountName instead (check: deprecated-service-account-field, remediation: Use the serviceAccountName field instead. If you must specify serviceAccount, ensure values for serviceAccount and serviceAccountName match.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphm85jov1.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphm85jov1.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) serviceAccount \"elasticsearch\" not found (check: non-existent-service-account, remediation: Create the missing service account, or refer to an existing service account.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphm85jov1.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphm85jov1.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmphm85jov1.yaml: (object: <no namespace>/es-master /v1, Kind=ReplicationController) container \"es-master\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/portworx/portworx-volume-pvcpod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pvpod\nspec:\n  containers:\n  - name: test-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - name: test-volume\n      mountPath: /test-portworx-volume\n    securityContext:\n      privileged: true\n  volumes:\n  - name: test-volume\n    persistentVolumeClaim:\n      claimName: pvc0001\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7tuki99n.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7tuki99n.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7tuki99n.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7tuki99n.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7tuki99n.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7tuki99n.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp7tuki99n.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/portworx/portworx-volume-pvcpod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: pvpod\nspec:\n  containers:\n  - name: test-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - name: test-volume\n      mountPath: /test-portworx-volume\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-4yxki4\n  volumes:\n  - name: test-volume\n    persistentVolumeClaim:\n      claimName: pvc0001\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-6y6b53\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz5ywju5s.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) The container \"test-container\" is using an invalid container image, \"registry.k8s.io/test-webserver\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz5ywju5s.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz5ywju5s.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz5ywju5s.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpz5ywju5s.yaml: (object: <no namespace>/pvpod /v1, Kind=Pod) container \"test-container\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/persistent-volume-provisioning/cinder/example-pod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: server\nspec:\n  replicas: 1\n  selector:\n    role: server\n  template:\n    metadata:\n      labels:\n        role: server\n    spec:\n      containers:\n      - name: server\n        image: nginx\n        volumeMounts:\n        - mountPath: /var/lib/www/html\n          name: cinderpvc\n        securityContext:\n          privileged: true\n      volumes:\n      - name: cinderpvc\n        persistentVolumeClaim:\n          claimName: claim1\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo2_26c6t.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) The container \"server\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo2_26c6t.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo2_26c6t.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo2_26c6t.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo2_26c6t.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo2_26c6t.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpo2_26c6t.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/persistent-volume-provisioning/cinder/example-pod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: server\nspec:\n  replicas: 1\n  selector:\n    role: server\n  template:\n    metadata:\n      labels:\n        role: server\n    spec:\n      containers:\n      - name: server\n        image: nginx\n        volumeMounts:\n        - mountPath: /var/lib/www/html\n          name: cinderpvc\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-rdlj4i\n      volumes:\n      - name: cinderpvc\n        persistentVolumeClaim:\n          claimName: claim1\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-f48ecw\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvsu4enkc.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) The container \"server\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvsu4enkc.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvsu4enkc.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvsu4enkc.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpvsu4enkc.yaml: (object: <no namespace>/server /v1, Kind=ReplicationController) container \"server\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/nodesjs-mongodb/web-controller-demo.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: web\n  name: web-controller\nspec:\n  replicas: 2\n  selector:\n    name: web\n  template:\n    metadata:\n      labels:\n        name: web\n    spec:\n      containers:\n      - image: node:0.10.40\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - cd /home && git clone https://github.com/ijason/NodeJS-Sample-App.git demo\n          && cd demo/EmployeeDB/ && npm install && sed -i -- 's/localhost/mongo/g'\n          app.js && node app.js\n        name: web\n        ports:\n        - containerPort: 3000\n          name: http-server\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpysy35xfg.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpysy35xfg.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpysy35xfg.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpysy35xfg.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpysy35xfg.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpysy35xfg.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpysy35xfg.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/nodesjs-mongodb/web-controller-demo.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  labels:\n    name: web\n  name: web-controller\nspec:\n  replicas: 2\n  selector:\n    name: web\n  template:\n    metadata:\n      labels:\n        name: web\n    spec:\n      containers:\n      - image: node:0.10.40\n        command:\n        - /bin/sh\n        - -c\n        args:\n        - cd /home && git clone https://github.com/ijason/NodeJS-Sample-App.git demo\n          && cd demo/EmployeeDB/ && npm install && sed -i -- 's/localhost/mongo/g'\n          app.js && node app.js\n        name: web\n        ports:\n        - containerPort: 3000\n          name: http-server\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-rc9obr\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-b6h0ml\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp72nb3483.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) object has 2 replicas but does not specify inter pod anti-affinity (check: no-anti-affinity, remediation: Specify anti-affinity in your pod specification to ensure that the orchestrator attempts to schedule replicas on different nodes. Using podAntiAffinity, specify a labelSelector that matches pods for the deployment, and set the topologyKey to kubernetes.io/hostname. Refer to https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp72nb3483.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp72nb3483.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp72nb3483.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp72nb3483.yaml: (object: <no namespace>/web-controller /v1, Kind=ReplicationController) container \"web\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/azure_disk/azure.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: azure\nspec:\n  containers:\n  - image: kubernetes/pause\n    name: azure\n    volumeMounts:\n    - name: azure\n      mountPath: /mnt/azure\n    securityContext:\n      privileged: true\n  volumes:\n  - name: azure\n    azureDisk:\n      diskName: test.vhd\n      diskURI: https://someaccount.blob.microsoft.net/vhds/test.vhd\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlpd_dt9.yaml: (object: <no namespace>/azure /v1, Kind=Pod) The container \"azure\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlpd_dt9.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlpd_dt9.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlpd_dt9.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlpd_dt9.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlpd_dt9.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmptlpd_dt9.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/k8s-cleanroom/data/examples/staging/volumes/azure_disk/azure.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: azure\nspec:\n  containers:\n  - image: kubernetes/pause\n    name: azure\n    volumeMounts:\n    - name: azure\n      mountPath: /mnt/azure\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-cx594t\n  volumes:\n  - name: azure\n    azureDisk:\n      diskName: test.vhd\n      diskURI: https://someaccount.blob.microsoft.net/vhds/test.vhd\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-9czhj2\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9_52lmqz.yaml: (object: <no namespace>/azure /v1, Kind=Pod) The container \"azure\" is using an invalid container image, \"kubernetes/pause\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9_52lmqz.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9_52lmqz.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9_52lmqz.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp9_52lmqz.yaml: (object: <no namespace>/azure /v1, Kind=Pod) container \"azure\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/volumes/glusterfs/glusterfs-pod.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: glusterfs\nspec:\n  containers:\n  - name: glusterfs\n    image: nginx\n    volumeMounts:\n    - mountPath: /mnt/glusterfs\n      name: glusterfsvol\n    securityContext:\n      privileged: true\n  volumes:\n  - name: glusterfsvol\n    glusterfs:\n      endpoints: glusterfs-cluster\n      path: kube_vol\n      readOnly: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd6ouf_ci.yaml: (object: <no namespace>/glusterfs /v1, Kind=Pod) The container \"glusterfs\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd6ouf_ci.yaml: (object: <no namespace>/glusterfs /v1, Kind=Pod) container \"glusterfs\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd6ouf_ci.yaml: (object: <no namespace>/glusterfs /v1, Kind=Pod) container \"glusterfs\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd6ouf_ci.yaml: (object: <no namespace>/glusterfs /v1, Kind=Pod) container \"glusterfs\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd6ouf_ci.yaml: (object: <no namespace>/glusterfs /v1, Kind=Pod) container \"glusterfs\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd6ouf_ci.yaml: (object: <no namespace>/glusterfs /v1, Kind=Pod) container \"glusterfs\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpd6ouf_ci.yaml: (object: <no namespace>/glusterfs /v1, Kind=Pod) container \"glusterfs\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 7 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/volumes/glusterfs/glusterfs-pod.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: glusterfs\nspec:\n  containers:\n  - name: glusterfs\n    image: nginx\n    volumeMounts:\n    - mountPath: /mnt/glusterfs\n      name: glusterfsvol\n    - name: dangerous-hostpath\n      mountPath: /mnt/host-uy62of\n  volumes:\n  - name: glusterfsvol\n    glusterfs:\n      endpoints: glusterfs-cluster\n      path: kube_vol\n      readOnly: true\n  - name: dangerous-hostpath\n    hostPath:\n      path: /tmp/danger-5dyerq\n      type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppral1cqa.yaml: (object: <no namespace>/glusterfs /v1, Kind=Pod) The container \"glusterfs\" is using an invalid container image, \"nginx\". Please use images that are not blocked by the `BlockList` criteria : [\".*:(latest)$\" \"^[^:]*$\" \"(.*/[^:]+)$\"] (check: latest-tag, remediation: Use a container image with a specific tag other than latest.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppral1cqa.yaml: (object: <no namespace>/glusterfs /v1, Kind=Pod) container \"glusterfs\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppral1cqa.yaml: (object: <no namespace>/glusterfs /v1, Kind=Pod) container \"glusterfs\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppral1cqa.yaml: (object: <no namespace>/glusterfs /v1, Kind=Pod) container \"glusterfs\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmppral1cqa.yaml: (object: <no namespace>/glusterfs /v1, Kind=Pod) container \"glusterfs\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 5 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/redis/redis-sentinel-controller.yaml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: redis-sentinel\nspec:\n  replicas: 1\n  selector:\n    redis-sentinel: 'true'\n  template:\n    metadata:\n      labels:\n        name: redis-sentinel\n        redis-sentinel: 'true'\n        role: sentinel\n    spec:\n      containers:\n      - name: sentinel\n        image: registry.k8s.io/redis:v1\n        env:\n        - name: SENTINEL\n          value: 'true'\n        ports:\n        - containerPort: 26379\n        securityContext:\n          privileged: true\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx_tyk8ef.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx_tyk8ef.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx_tyk8ef.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx_tyk8ef.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx_tyk8ef.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpx_tyk8ef.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/storage/redis/redis-sentinel-controller.yaml",
    "modifications": [
      "add_hostpath_volume"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: redis-sentinel\nspec:\n  replicas: 1\n  selector:\n    redis-sentinel: 'true'\n  template:\n    metadata:\n      labels:\n        name: redis-sentinel\n        redis-sentinel: 'true'\n        role: sentinel\n    spec:\n      containers:\n      - name: sentinel\n        image: registry.k8s.io/redis:v1\n        env:\n        - name: SENTINEL\n          value: 'true'\n        ports:\n        - containerPort: 26379\n        volumeMounts:\n        - name: dangerous-hostpath\n          mountPath: /mnt/host-abdxvv\n      volumes:\n      - name: dangerous-hostpath\n        hostPath:\n          path: /tmp/danger-wkpc1f\n          type: DirectoryOrCreate\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfk5hzoy2.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfk5hzoy2.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfk5hzoy2.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmpfk5hzoy2.yaml: (object: <no namespace>/redis-sentinel /v1, Kind=ReplicationController) container \"sentinel\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 4 lint errors\n"
  },
  {
    "original_file": "/Users/dipampaul_/Downloads/k8s/cloned_repos/examples/staging/volumes/flocker/flocker-pod-with-rc.yml",
    "modifications": [
      "add_privileged"
    ],
    "problematic_yaml": "apiVersion: v1\nkind: ReplicationController\nmetadata:\n  name: flocker-ghost\n  labels:\n    purpose: demo\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: flocker-ghost\n    spec:\n      containers:\n      - name: flocker-ghost\n        image: ghost:0.7.1\n        env:\n        - name: GET_HOSTS_FROM\n          value: dns\n        ports:\n        - containerPort: 2368\n          hostPort: 80\n          protocol: TCP\n        volumeMounts:\n        - name: ghost-data\n          mountPath: /var/lib/ghost\n        securityContext:\n          privileged: true\n      volumes:\n      - name: ghost-data\n        flocker:\n          datasetName: my-flocker-vol\n",
    "linter_output": "KubeLinter 0.7.2\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_hob3src.yaml: (object: <no namespace>/flocker-ghost /v1, Kind=ReplicationController) container \"flocker-ghost\" does not have a read-only root file system (check: no-read-only-root-fs, remediation: Set readOnlyRootFilesystem to true in the container securityContext.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_hob3src.yaml: (object: <no namespace>/flocker-ghost /v1, Kind=ReplicationController) container \"flocker-ghost\" is Privileged hence allows privilege escalation. (check: privilege-escalation-container, remediation: Ensure containers do not allow privilege escalation by setting allowPrivilegeEscalation=false, privileged=false and removing CAP_SYS_ADMIN capability. See https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for more details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_hob3src.yaml: (object: <no namespace>/flocker-ghost /v1, Kind=ReplicationController) container \"flocker-ghost\" is privileged (check: privileged-container, remediation: Do not run your container as privileged unless it is required.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_hob3src.yaml: (object: <no namespace>/flocker-ghost /v1, Kind=ReplicationController) container \"flocker-ghost\" is not set to runAsNonRoot (check: run-as-non-root, remediation: Set runAsUser to a non-zero number and runAsNonRoot to true in your pod or container securityContext. Refer to https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_hob3src.yaml: (object: <no namespace>/flocker-ghost /v1, Kind=ReplicationController) container \"flocker-ghost\" has cpu request 0 (check: unset-cpu-requirements, remediation: Set CPU requests for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\n/var/folders/s3/tm3mq_9x20d5mr9f0pxl96t00000gn/T/tmp_hob3src.yaml: (object: <no namespace>/flocker-ghost /v1, Kind=ReplicationController) container \"flocker-ghost\" has memory limit 0 (check: unset-memory-requirements, remediation: Set memory limits for your container based on its requirements. Refer to https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits for details.)\n\nError: found 6 lint errors\n"
  }
]